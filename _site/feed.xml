<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-11-02T21:08:04+08:00</updated><id>http://localhost:4000/feed.xml</id><entry><title type="html">Flashback TiKV</title><link href="http://localhost:4000/distributed/2023/10/25/Flashback-in-TiKV-en.html" rel="alternate" type="text/html" title="Flashback TiKV" /><published>2023-10-25T19:43:28+08:00</published><updated>2023-10-25T19:43:28+08:00</updated><id>http://localhost:4000/distributed/2023/10/25/Flashback-in-TiKV-en</id><content type="html" xml:base="http://localhost:4000/distributed/2023/10/25/Flashback-in-TiKV-en.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#background-introduction" id="markdown-toc-background-introduction">Background Introduction</a>    <ul>
      <li><a href="#execution-and-effect" id="markdown-toc-execution-and-effect">Execution and effect</a></li>
      <li><a href="#specific-implementation" id="markdown-toc-specific-implementation">Specific Implementation</a>        <ul>
          <li><a href="#adopting-region-lock-to-halt-readwrite-scheduling" id="markdown-toc-adopting-region-lock-to-halt-readwrite-scheduling">Adopting Region Lock to Halt Read/Write Scheduling</a></li>
          <li><a href="#general-process" id="markdown-toc-general-process">General Process</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#code-analysis" id="markdown-toc-code-analysis">Code Analysis</a>    <ul>
      <li><a href="#overview-of-the-process" id="markdown-toc-overview-of-the-process">Overview of the Process</a></li>
      <li><a href="#phase-1-1-prepare" id="markdown-toc-phase-1-1-prepare">Phase 1-1: Prepare</a>        <ul>
          <li><a href="#prepare-flashback" id="markdown-toc-prepare-flashback">Prepare Flashback</a></li>
          <li><a href="#halting-reads" id="markdown-toc-halting-reads">Halting Reads</a></li>
          <li><a href="#readlocal--staleread" id="markdown-toc-readlocal--staleread">ReadLocal &amp; StaleRead</a></li>
          <li><a href="#halting-write" id="markdown-toc-halting-write">Halting Write</a></li>
        </ul>
      </li>
      <li><a href="#phase1-2-prewrite" id="markdown-toc-phase1-2-prewrite">Phase1-2: Prewrite</a></li>
      <li><a href="#halting-the-advancement-of-resolved_ts" id="markdown-toc-halting-the-advancement-of-resolved_ts">Halting the Advancement of resolved_ts</a>        <ul>
          <li><a href="#introduction-to-the-read-and-write-phase" id="markdown-toc-introduction-to-the-read-and-write-phase">Introduction to the Read and Write Phase</a></li>
        </ul>
      </li>
      <li><a href="#phase2-1-exec--commit" id="markdown-toc-phase2-1-exec--commit">Phase2-1: Exec &amp; Commit</a></li>
      <li><a href="#phase2-2-finish" id="markdown-toc-phase2-2-finish">Phase2-2: Finish</a></li>
    </ul>
  </li>
  <li><a href="#appendix" id="markdown-toc-appendix">Appendix</a>    <ul>
      <li><a href="#some-potholes" id="markdown-toc-some-potholes">Some potholes</a></li>
      <li><a href="#improvement-points" id="markdown-toc-improvement-points">Improvement points</a></li>
      <li><a href="#reference" id="markdown-toc-reference">Reference</a></li>
    </ul>
  </li>
</ul>

<p>This is an article originally intended as a product introduction, but was shelved for various reasons. Recently, as we have been improving related features, we decided to refine it and release it. Very excited to implement this with <a href="https://ipotato.me/">JmPotato</a>~</p>

<p>For the code, please see: <a href="https://github.com/pingcap/tidb/issues/37197">roadmap</a> &amp; <a href="https://github.com/tikv/tikv/issues/13303">TiKV tracking issue</a></p>

<h2 id="background-introduction">Background Introduction</h2>

<p>Flashback (usually referring to Oracle Flashback) is a feature used to quickly revert to a previous version in case of user errors, to avoid significant losses.</p>

<p>In the gaming industry, issues like version errors occur from time to time, and regular backups can only revert to the backup point in time, which is also a waste of resources. <a href="https://docs.pingcap.com/tidb/stable/release-6.4.0">TiDB v6.4.0</a> introduced the <code class="language-plaintext highlighter-rouge">FLASHBACK CLUSTER TO TIMESTAMP</code> syntax, which allows the data of a cluster, database, or data table to be restored to a specific point in time.</p>

<p>In TiDB, there are some related features:</p>

<ul>
  <li>MVCC &amp; GC: Data updates or deletions are adding new versions, and the historical versions are cleared through the GC mechanism. The storage engine maintains historical records for a certain period, which makes various data recovery functions possible later.</li>
  <li>Reading historical data through the system variable tidb_snapshot: Specify a ts (cannot be earlier than the GC safepoint) to read the data at that time point, and ensure the data is consistent.</li>
  <li>FLASHBACK TABLE: Restores tables and data that have been dropped or truncated.
Ultimately, we adopted the approach of using Multiversion Concurrency Control (MVCC) to take the latest timestamp data before TIMESTAMP and overwrite the current data.</li>
</ul>

<h3 id="execution-and-effect">Execution and effect</h3>

<p>「For details, please refer to <a href="https://docs.pingcap.com/zh/tidb/dev/sql-statement-flashback-to-timestamp">User documentation</a>.」</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mysql</span><span class="o">&gt;</span> <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">t</span><span class="p">(</span><span class="n">a</span> <span class="nb">INT</span><span class="p">);</span>
<span class="n">Query</span> <span class="n">OK</span><span class="p">,</span> <span class="mi">0</span> <span class="k">rows</span> <span class="n">affected</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">09</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">t</span><span class="p">;</span>
<span class="n">Empty</span> <span class="k">set</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">01</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="n">now</span><span class="p">();</span>
<span class="o">+</span><span class="c1">---------------------+</span>
<span class="o">|</span> <span class="n">now</span><span class="p">()</span>               <span class="o">|</span>
<span class="o">+</span><span class="c1">---------------------+</span>
<span class="o">|</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">16</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">---------------------+</span>
<span class="mi">1</span> <span class="k">row</span> <span class="k">in</span> <span class="k">set</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">02</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">t</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="n">Query</span> <span class="n">OK</span><span class="p">,</span> <span class="mi">1</span> <span class="k">row</span> <span class="n">affected</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">02</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">t</span><span class="p">;</span>
<span class="o">+</span><span class="c1">------+</span>
<span class="o">|</span> <span class="n">a</span>    <span class="o">|</span>
<span class="o">+</span><span class="c1">------+</span>
<span class="o">|</span>    <span class="mi">1</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">------+</span>
<span class="mi">1</span> <span class="k">row</span> <span class="k">in</span> <span class="k">set</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">01</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="n">FLASHBACK</span> <span class="k">CLUSTER</span> <span class="k">TO</span> <span class="nb">TIMESTAMP</span> <span class="s1">'2022-09-28 17:24:16'</span><span class="p">;</span>
<span class="n">Query</span> <span class="n">OK</span><span class="p">,</span> <span class="mi">0</span> <span class="k">rows</span> <span class="n">affected</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">20</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">t</span><span class="p">;</span>
<span class="n">Empty</span> <span class="k">set</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">00</span> <span class="n">sec</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="specific-implementation">Specific Implementation</h3>

<h4 id="adopting-region-lock-to-halt-readwrite-scheduling">Adopting Region Lock to Halt Read/Write Scheduling</h4>

<p>In Flashback, we use Region locks to block all read/write operations and scheduling during the Flashback process to avoid any external factors that might cause data inconsistencies.</p>

<p><strong>By locking the Region before performing Flashback, we can gain the following benefits:</strong></p>

<ul>
  <li>Blocking any read/write operations and scheduling during the Flashback process, avoiding any potential external factors that could cause data inconsistencies;</li>
  <li>Since locked Regions will not produce additional data writes, it is convenient for Flashback to freely write and retry;</li>
  <li>Since locked Regions will not produce additional data writes, there is no need to maintain the Flashback success or failure status of different Stores and Regions within the cluster, simply retrying until successful is sufficient;</li>
  <li>Region-level operations are more in line with the granularity of TiKV’s internal data management.</li>
</ul>

<h4 id="general-process">General Process</h4>

<p>First, TiDB will determine:</p>

<ul>
  <li>FlashbackTS: Whether it is a future time point, whether it is greater than minSafeTS, and whether it is within the GC Safe time</li>
  <li>Whether any non-Flashback ddl jobs have been executed within the time range</li>
  <li>Whether any DDL tasks are currently being executed</li>
  <li>Close GC, PD scheduling, and auto analyze, then start calling TiKV’s two-phase process</li>
  <li><strong>First Phase (Region Locking)</strong>
    <ol>
      <li>TiDB determines the key range for the Flashback request;</li>
      <li>TiDB sends a kv_prepare_flashback_to_version request to different regions on a per-region basis, blocking reads, writes, and scheduling;</li>
      <li>Call the PD interface to get the latest TSO as the startTS for executing Flashback. TiDB will persist this startTS to ensure that it can use the same TS after a failure and restart;</li>
      <li>Use Region locks to independently handle each Region’s Flashback progress
        <ul>
          <li>Scan all MVCC Locks and perform rollbacks;</li>
          <li>TiKV will select the latest user key in CF_WRITE and prewrite a previous lock with the aforementioned startTS to halt the advancement of resolved_ts, which will be committed in the second phase;</li>
        </ul>
      </li>
      <li>TiDB checks if all requests have returned successfully and retries failed requests until the entire locking phase is completed.</li>
    </ol>
  </li>
  <li><strong>Second Phase (Executing Flashback)</strong>
    <ol>
      <li>TiDB takes the aforementioned startTS and obtains the latest TSO from PD as the commitTS. TiDB will also persist this commitTS and send kv_flashback_to_version requests to different regions;</li>
      <li>Each Region independently processes its own Flashback progress
        <ul>
          <li>Scan for keys that have had version changes after the point in time to which you want to Flashback and write the old MVCC version for the scanned keys;</li>
          <li>Commit the locks written in the prewrite phase of the first stage and remove the Region locks after completion;</li>
        </ul>
      </li>
      <li>TiDB checks if all requests have been successfully returned and retries the failed requests with the same startTS and commitTS until the entire Flashback execution is completed.</li>
    </ol>
  </li>
</ul>

<h2 id="code-analysis">Code Analysis</h2>

<p>Let’s start from the beginning of TiKV startup. :)</p>

<p>Beginning with cmd/tikv-server/main.rs, after TiKV finishes configuring a series of parameters, the main function culminates with server::run_tikv(config) to run the TiKV server. The main function selects the corresponding Engine based on the configured parameters and calls the run_impl function. Inside run_server, it performs binding and initiates the grpc_server.start(); service. You can view the specific binding and startup process in this <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-7">document</a>.</p>

<p>The focus of this article, Flashback, is located at the following place in kvproto:</p>

<div class="language-protobuf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">rpc</span> <span class="n">KvPrepareFlashbackToVersion</span><span class="p">(</span><span class="n">kvrpcpb.PrepareFlashbackToVersionRequest</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">kvrpcpb.PrepareFlashbackToVersionResponse</span><span class="p">)</span> <span class="p">{}</span>
<span class="k">rpc</span> <span class="n">KvFlashbackToVersion</span><span class="p">(</span><span class="n">kvrpcpb.FlashbackToVersionRequest</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">kvrpcpb.FlashbackToVersionResponse</span><span class="p">)</span> <span class="p">{}</span>
</code></pre></div></div>

<p>Returning to the TiKV code, TiKV includes multiple gRPC services. One of the most important is the KvService, located in the src/server/service/kv.rs file. It includes the APIs for transaction operations in TiKV, such as kv_get, kv_scan, kv_prewrite, kv_commit, etc. The Flashback feature in this article, since it uses the transaction model, is quite naturally placed in this file.</p>

<h3 id="overview-of-the-process">Overview of the Process</h3>
<p>Before we delve deeper into the specific code, let’s take a broad look at the overall Flashback process. We can distill it into four main steps based on the key code components:</p>

<ol>
  <li>Preparation: Before starting the actual overwrite operations, an Admin PrepareFlashback command is sent via the raft_router. This step accomplishes the persistence of region metadata.</li>
  <li>Locking: After a region is marked for Flashback, the first prewrite is done on a user_key to prevent the advancement of resolved_ts.</li>
  <li>Execution: Perform the Flashback and commit the key that was written in step 2.</li>
  <li>Completion: After the execution of Flashback, a FinishFlashback command is sent through the raft_router to clean up the data.</li>
</ol>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// First Phase</span>
<span class="k">fn</span> <span class="nf">future_prepare_flashback_to_version</span><span class="p">()</span> <span class="p">{</span>
 <span class="c1">// 1. prepare the raftstore for the later flashback.</span>
 <span class="nf">send_flashback_msg</span><span class="p">(</span><span class="o">..</span><span class="p">,</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span><span class="p">);</span>
 <span class="c1">// 2.prewrite the first user key to prevent `resolved_ts` from advancing.</span>
 <span class="k">let</span> <span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="o">=</span> <span class="nf">paired_future_callback</span><span class="p">();</span>
 <span class="n">res</span> <span class="o">=</span> <span class="n">storage</span><span class="nf">.sched_txn_command</span><span class="p">(</span><span class="n">req</span><span class="nf">.clone</span><span class="p">()</span><span class="nf">.into</span><span class="p">(),</span> <span class="n">cb</span><span class="p">);</span>
<span class="p">}</span>
<span class="c1">// Second Phase</span>
<span class="k">fn</span> <span class="nf">future_flashback_to_version</span><span class="p">()</span> <span class="p">{</span>
 <span class="c1">// 3. execute overwrite and commit the first user key.</span>
 <span class="k">let</span> <span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="o">=</span> <span class="nf">paired_future_callback</span><span class="p">();</span>
 <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="n">storage_clone</span><span class="nf">.sched_txn_command</span><span class="p">(</span><span class="n">req</span><span class="nf">.into</span><span class="p">(),</span> <span class="n">cb</span><span class="p">);</span>
 <span class="c1">// 4. notify raftstore flashback has been finished.</span>
 <span class="nf">send_flashback_msg</span><span class="p">(</span><span class="o">..</span><span class="p">,</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">FinishFlashback</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Entering the first phase of Flashback operation, the preparation module is critical.</p>

<h3 id="phase-1-1-prepare">Phase 1-1: Prepare</h3>

<p>The primary goal of the Prepare function is to halt reads and writes, prevent scheduling, and persist the Flashback state, as well as stop the advancement of resolved_ts.</p>

<p>In the “Preparation” phase, the necessity of stopping all reads, writes, and scheduling operations has already been explained in the Background Introduction section. To achieve this, one would intuitively block these operations at the point of execution. With TiKV using the Raft consensus protocol, the operations eventually go through a Propose, Commit, then Apply process, so it makes sense to intercept reads and writes before Propose.</p>

<blockquote>
  <p>Spoiler Alert for Flashback Implementation: The interception is done quickly at the Propose to block other reads and writes during the Flashback process, with the Apply step acting as a safety net.</p>
</blockquote>

<p>To understand the process of handling a proposal in TiKV, you can refer to this <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-18">article</a>.</p>

<p>In short, TiKV utilizes two thread pools to handle proposals, and a Raft peer is divided into two parts: PeerFsm and ApplyFsm. During the proposal processing, PeerFsm fetches logs and drives the internal state machine of Raft, while ApplyFsm updates the state machine according to the committed logs, which includes both region information and user data.</p>

<blockquote>
  <p>For more details on PeerFsm and ApplyFsm, you can refer to this <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-17">article</a></p>
</blockquote>

<p>During the process where “PeerFsm fetches logs and drives the internal state machine of Raft” it encounters the following function:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">propose_raft_command_internal</span><span class="p">()</span> <span class="p">{</span>
 <span class="k">match</span> <span class="k">self</span><span class="nf">.pre_propose_raft_command</span><span class="p">(</span><span class="o">&amp;</span><span class="n">msg</span><span class="p">)</span> <span class="p">{</span> <span class="o">..</span> <span class="p">}</span>

 <span class="k">if</span> <span class="k">self</span><span class="py">.fsm.peer</span><span class="nf">.propose</span><span class="p">(</span><span class="k">self</span><span class="py">.ctx</span><span class="p">,</span> <span class="n">cb</span><span class="p">,</span> <span class="n">msg</span><span class="p">,</span> <span class="n">resp</span><span class="p">,</span> <span class="n">diskfullopt</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">self</span><span class="py">.fsm.has_ready</span> <span class="o">=</span> <span class="k">true</span><span class="p">;</span>
 <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Upon examining the codebase, we find that the PeerFsmDelegate::pre_propose_raft_command function is indeed the checkpoint where a request is examined before a propose is allowed to proceed.</p>

<p>It’s logical to place the check to determine if the current request is related to Flashback right at this stage.</p>

<p><strong>Key Consideration:</strong></p>

<p>However, we cannot block all operations indiscriminately. Flashback operations themselves need to pass through the Raft process without hindrance. Thus, we should issue a sort of ‘pass’ for them.</p>

<p>Utilizing flags in RaftCmdRequest Header:</p>

<p>We then notice that the RaftCmdRequest structure has a header field that includes flags. This is a suitable place to set flags that can be used as a ‘pass’ for Flashback-related commands, allowing them to be distinguished from regular operations.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">fn</span> <span class="nf">pre_propose_raft_command</span><span class="p">(</span>
     <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span>
     <span class="n">req</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">RaftCmdRequest</span><span class="p">,</span>
 <span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;</span><span class="n">RaftCmdResponse</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
     <span class="c1">// When in the flashback state, we should not allow any other request to be proposed.</span>
     <span class="k">if</span> <span class="k">self</span><span class="nf">.region</span><span class="p">()</span><span class="py">.is_in_flashback</span> <span class="p">{</span>
         <span class="k">let</span> <span class="n">flags</span> <span class="o">=</span> <span class="n">req</span><span class="nf">.get_header</span><span class="p">()</span><span class="nf">.get_flags</span><span class="p">();</span>
         <span class="k">if</span> <span class="o">!</span><span class="n">flags</span><span class="nf">.contains</span><span class="p">(</span><span class="n">FLASHBACK</span><span class="p">)</span> <span class="p">{</span>
             <span class="k">return</span> <span class="nb">Err</span><span class="p">;</span>
         <span class="p">}</span>
     <span class="p">}</span>
 <span class="p">}</span>
</code></pre></div></div>

<h4 id="prepare-flashback">Prepare Flashback</h4>

<p>After implementing the “block points” to prevent non-Flashback operations, to ensure that Flashback-related operations proceed smoothly and are not blocked, we add a flag to the header.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// First Phase</span>
<span class="k">fn</span> <span class="n">future_prepare_flashback_to_version</span><span class="p">{</span>
 <span class="c1">// 1. prepare the raftstore for the later flashback. </span>
 <span class="nf">send_flashback_msg</span><span class="p">(</span><span class="o">..</span><span class="p">,</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The functions start_flashback/end_flashback that are invoked will send an admin request after the flag is added.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">fn</span> <span class="n">start_flashback</span><span class="o">/</span><span class="n">end_flashback</span> <span class="p">{</span>
 <span class="o">...</span>
 <span class="n">req</span><span class="nf">.mut_header</span><span class="p">()</span>
     <span class="nf">.set_flags</span><span class="p">(</span><span class="nn">WriteBatchFlags</span><span class="p">::</span><span class="n">FLASHBACK</span><span class="nf">.bits</span><span class="p">());</span>
 <span class="c1">// call admin request directly</span>
 <span class="k">let</span> <span class="n">raft_router</span> <span class="o">=</span> <span class="n">raft_router</span><span class="nf">.lock</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
 <span class="n">raft_router</span><span class="nf">.send_command</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">cb</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
 <span class="o">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The Admin request is formed into a RaftCommand via the RaftStoreRouter and sent along. It goes through the proposing process, passing through the pre_propose check, and arrives at PeerFsmDelegate.fsm.peer.propose to complete the proposal of a Raft log.</p>

<p>Subsequently, the PeerFsm will send the Proposal and committed logs to the corresponding ApplyFsm for the apply process.</p>

<p>The ApplyFsm will, for these logs (see ApplyFsm::handle_apply):</p>

<ol>
  <li>Ensure the data is durably stored.</li>
  <li>Communicate ApplyRes to PeerFsm, which is necessary for updating the Region’s status within PeerFsm.
 In the execution of exec_raft_cmd, a check_flashback_state is incorporated to verify the persistence of the Flashback state. Here, the region is configured in the subsequent exec function, and due to the serial nature of apply operations, the region’s details are established before the arrival of the following command.</li>
</ol>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">check_flashback_state</span><span class="p">(</span><span class="k">self</span><span class="py">.region</span><span class="nf">.get_is_in_flashback</span><span class="p">());</span>

<span class="k">pub</span> <span class="k">fn</span> <span class="nf">check_flashback_state</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="c1">// The admin flashback cmd could be proposed/applied under any state.</span>
    <span class="k">if</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span> <span class="p">||</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">FinishFlashback</span> <span class="p">{</span>
        <span class="k">return</span> <span class="nf">Ok</span><span class="p">(());</span>
    <span class="p">}</span>
    <span class="k">let</span> <span class="n">is_flashback_request</span> <span class="o">=</span> <span class="n">req</span><span class="nf">.get_header</span><span class="p">()</span><span class="nf">.get_flags</span><span class="p">()</span>
                            <span class="nf">.contains</span><span class="p">(</span><span class="n">FLASHBACK</span><span class="p">);</span>
    <span class="o">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>After the checks are passed, the process executes ApplyDelegate::exec_admin_cmd, which ultimately recognizes the Flashback identifier and reaches our target function exec_flashback.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span> <span class="p">|</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">FinishFlashback</span> <span class="k">=&gt;</span> 
    <span class="k">self</span><span class="nf">.exec_flashback</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">request</span><span class="p">),</span>
</code></pre></div></div>

<p>When the exec_flashback function is invoked, it performs the necessary operations to alter the Region’s metadata to reflect the state of the system as it should be after the Flashback process. This usually involves the following steps:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">exec_flashback</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">is_in_flashback</span> <span class="o">=</span> <span class="n">req</span><span class="nf">.get_cmd_type</span><span class="p">()</span> <span class="o">==</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span><span class="p">;</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">region</span> <span class="o">=</span> <span class="k">self</span><span class="py">.region</span><span class="nf">.clone</span><span class="p">();</span>
    <span class="n">region</span><span class="nf">.set_is_in_flashback</span><span class="p">(</span><span class="n">is_in_flashback</span><span class="p">);</span>


    <span class="nf">put_msg_cf</span><span class="p">(</span><span class="n">CF_RAFT</span><span class="p">,</span> <span class="o">&amp;</span><span class="nn">keys</span><span class="p">::</span><span class="nf">region_state_key</span><span class="p">(</span><span class="n">region_id</span><span class="p">),</span> <span class="o">&amp;</span><span class="n">old_state</span><span class="p">)</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="nn">ApplyResult</span><span class="p">::</span><span class="nf">Res</span><span class="p">(</span><span class="nn">ExecResult</span><span class="p">::</span><span class="n">SetFlashbackState</span> <span class="p">{</span> <span class="n">region</span> <span class="p">}</span> <span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>After the ApplyFsm applies a series of Raft logs, it generates an ApplyRes message that encapsulates the outcomes of this apply process. This message is dispatched to the corresponding PeerFsm.</p>

<p>Once received, the PeerFsm processes the message through the PeerFsmDelegate::handle_msgs function, specifically within the PeerMsg::ApplyRes { res } case. It is here that PeerFsmDelegate::on_apply_res is invoked, thereby updating the durable state to reflect the effects of the Flashback operation, ensuring that the persistent view of the region’s state is consistent with the Flashback’s target historical state.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">fn</span> <span class="nf">on_set_flashback_state</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">is_in_flashback</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// update flashback state</span>
        <span class="k">self</span><span class="nf">.update_region</span><span class="p">();</span>
        <span class="c1">// 此行代码在做的事将在「停读 - ReadLocal &amp; StaleRead 」小节解释</span>
        <span class="k">self</span><span class="py">.fsm.peer</span><span class="nf">.leader_lease_mut</span><span class="p">()</span><span class="nf">.expire_remote_lease</span><span class="p">();</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>After a comprehensive analysis, we observe that there are two critical blocks that act as barriers to non-Flashback operations, located at the propose and apply stages, respectively.</p>

<p>This leads to the ensuing inquiry: where should we integrate the ‘pass’ that permits Flashback requests to proceed unhindered?</p>

<p>Considering that Flashback is conceptually an operation built upon Multi-Version Concurrency Control (MVCC) mechanisms, it inherently requires traversal through the established read-write interfaces of MVCC. By retracing the MVCC read-write process, we can better ascertain the strategic location to embed this ‘pass’, ensuring that Flashback requests are granted seamless continuity through the system.</p>

<h4 id="halting-reads">Halting Reads</h4>

<p>Firstly, let’s comb through the read process, which can be studied in detail in conjunction with <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-read">TiKV Source Code Reading Part Two: The Read Process</a>.</p>

<p>When LocalReader::propose_raft_command is invoked, it’s discerned that the request is judged through LocalReader::pre_propose_raft_command.</p>

<p>Specific logic is applied to ReadLocal and StaleRead, while other requests are forwarded to RaftStore for execution. This forwarding is done via ProposalRouter::send, after which the process enters the Propose flow we previously mentioned.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">propose_raft_command</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">match</span> <span class="k">self</span><span class="nf">.pre_propose_raft_command</span><span class="p">(</span><span class="o">&amp;</span><span class="n">req</span><span class="p">)</span> <span class="p">{</span> 
        <span class="nn">RequestPolicy</span><span class="p">::</span><span class="n">ReadLocal</span> <span class="k">=&gt;</span> <span class="o">..</span>
        <span class="nn">RequestPolicy</span><span class="p">::</span><span class="n">StaleRead</span> <span class="k">=&gt;</span> <span class="o">..</span>
        <span class="c1">// Forward to raftstore.</span>
        <span class="n">_</span> <span class="k">=&gt;</span> <span class="k">self</span><span class="nf">.redirect</span><span class="p">(</span><span class="nn">RaftCommand</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">cb</span><span class="p">)),</span>     
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Thus, for requests other than ReadLocal and StaleRead, the following interruption can be naturally implemented:</p>

<p>Before entering the read process, check whether the request contains the Flashback flag. This achieves the goal that after Flashback is initiated, only read commands related to Flashback are allowed to pass through.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">exec_snapshot</span><span class="p">()</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="py">.for_flashback</span> <span class="p">{</span>
        <span class="n">flags</span> <span class="p">|</span><span class="o">=</span> <span class="nn">WriteBatchFlags</span><span class="p">::</span><span class="n">FLASHBACK</span><span class="nf">.bits</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">header</span><span class="nf">.set_flags</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
    <span class="o">...</span>
    <span class="k">self</span><span class="py">.router</span><span class="nf">.read</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>When Flashback is executed, the exec_snapshot is set with ctx.for_flashback, where for_flashback is obtained will be explained in the following section 「Phase2-1: Exec - Read Stage」.</p>

<h4 id="readlocal--staleread">ReadLocal &amp; StaleRead</h4>

<p>As mentioned in the previous section, ReadLocal and StaleRead have specific logic that can be understood further through the reading materials about <a href="https://cn.pingcap.com/blog/lease-read">TiKV’s Lease Read feature</a> &amp;&amp; <a href="https://docs.pingcap.com/zh/tidb/dev/stale-read">use cases for Stale Read functionality</a>.</p>

<p>The special handling for ReadLocal involves checking the leader_lease in the Peer. If it is found to be outside of the lease period, it will be forwarded to the regular Propose process.</p>

<p>Therefore, our approach is: during the preparation of Flashback, to manually set the lease to expire to ensure that local reads will not execute.</p>

<p>This is what is done simultaneously with the lease update after completing the apply res and updating the region.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">fn</span> <span class="nf">on_set_flashback_state</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">is_in_flashback</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Update the region meta.</span>
        <span class="k">self</span><span class="nf">.update_region</span><span class="p">()</span>
        <span class="c1">// Let the leader lease to None to ensure that local reads are not executed.</span>
        <span class="k">self</span><span class="py">.fsm.peer</span><span class="nf">.leader_lease_mut</span><span class="p">()</span><span class="nf">.expire_remote_lease</span><span class="p">();</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>Regarding StaleRead, its prerequisite for operation is the continuous advancement of safe ts (also known as resolved_ts). This check is performed in TiDB to ensure that the version used by Flashback will not exceed resolved_ts, therefore providing a cutoff.</p>

<p>With this, the explanation for the interruption of read operations during Flashback is complete.</p>

<h4 id="halting-write">Halting Write</h4>

<p>For further details on the execution process of write requests in TiKV, one can refer to <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-write">TiKV Source Code Reading (Part III) Write Process</a>.</p>

<p>During the write process, the RaftKv::exec_write_requests internally moves towards the router to initiate the Propose process. Therefore, similar to the “read request” discussed previously, a checkpoint is added at this stage to only allow Flashback-related write commands to pass through.</p>

<p>This ensures that during the execution of Flashback, only write operations associated with it can proceed, and all other write requests are effectively halted, preserving the integrity of the Flashback operation.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">exec_write_requests</span><span class="p">()</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="n">txn_extra</span><span class="py">.for_flashback</span> <span class="p">{</span>
        <span class="n">flags</span> <span class="p">|</span><span class="o">=</span> <span class="nn">WriteBatchFlags</span><span class="p">::</span><span class="n">FLASHBACK</span><span class="nf">.bits</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">header</span><span class="nf">.set_flags</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
    <span class="o">...</span>
    <span class="k">self</span><span class="py">.router</span><span class="nf">.send_command</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">cb</span><span class="p">,</span> <span class="n">extra_opts</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="phase1-2-prewrite">Phase1-2: Prewrite</h3>

<p>After halting read and write operations, we are faced with a new issue: the continuously advancing resolved timestamp (resolved_ts) could cause a panic in Change Data Capture (CDC).</p>

<h3 id="halting-the-advancement-of-resolved_ts">Halting the Advancement of resolved_ts</h3>

<p>In short, resolved_ts is an internal mechanism of TiKV (TODO: introduce resolved_ts). It’s maintained due to the following reasons:</p>

<ul>
  <li>
    <p>The Resolved TS component maintains a minimum heap of StartTS by observing changes in the LockCF, with the rule ResolvedTS = max(ResolvedTS, min(StartTS)).</p>
  </li>
  <li>
    <p>Flashback will remove all locks at the granularity of a Region.</p>
  </li>
  <li>
    <p>For a Region undergoing Flashback, there will no longer be any locks, meaning the ResolvedTS will continue to advance as normal, regardless of whether data is being written.</p>
  </li>
</ul>

<p>This would lead to a scenario where the CommitTS of the changes is less than the ResolvedTS (since Flashback uses the same CommitTS for all changes, and eventually, the ResolvedTS would surpass it).</p>

<p>To prevent resolved_ts from advancing before we execute Flashback, we employ the following strategy: TiDB includes a start_ts with its requests, and TiKV selects the latest user key in the CF_WRITE. A lock is prewritten with this start_ts, which will be committed and cleared after Flashback execution is complete.</p>

<h4 id="introduction-to-the-read-and-write-phase">Introduction to the Read and Write Phase</h4>

<p>Returning to the initial future_prepare_flashback_to_version function, it begins by internally converting the request using req.into.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// First Phase</span>
<span class="k">fn</span> <span class="n">future_prepare_flashback_to_version</span><span class="p">{</span>
    <span class="o">...</span>
    <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="n">storage_clone</span><span class="nf">.sched_txn_command</span><span class="p">(</span><span class="n">req</span><span class="nf">.into</span><span class="p">(),</span> <span class="n">cb</span><span class="p">);</span>
    <span class="o">...</span> 
<span class="p">}</span>
</code></pre></div></div>

<p>The from of PrepareFlashbackToVersionRequest to FlashbackToVersionReadPhase is implemented here.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span> <span class="nb">From</span><span class="o">&lt;</span><span class="n">PrepareFlashbackToVersionRequest</span><span class="o">&gt;</span> <span class="k">for</span> <span class="n">TypedCommand</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">from</span><span class="p">(</span><span class="k">mut</span> <span class="n">req</span><span class="p">:</span> <span class="n">PrepareFlashbackToVersionRequest</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
        <span class="n">FlashbackToVersionReadPhase</span> <span class="p">{</span> <span class="o">..</span> <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Therefore, what is actually being scheduled here is FlashbackToVersionReadPhase, which means that for sched_txn_command, the process will proceed to the process_read provided by FlashbackToVersionReadPhase. After this function is executed, it will trigger the process_write of FlashbackToVersion.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">process_read</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">snapshot</span><span class="p">:</span> <span class="n">S</span><span class="p">,</span> <span class="n">statistics</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Statistics</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">ProcessResult</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="k">let</span> <span class="n">next_cmd</span> <span class="o">=</span> <span class="n">FlashbackToVersion</span> <span class="p">{</span>
        <span class="o">...</span>
    <span class="p">}</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="nn">ProcessResult</span><span class="p">::</span><span class="n">NextCommand</span> <span class="p">{</span>
        <span class="n">cmd</span><span class="p">:</span> <span class="nn">Command</span><span class="p">::</span><span class="nf">FlashbackToVersion</span><span class="p">(</span><span class="n">next_cmd</span><span class="p">),</span>
    <span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The general process follows a repetitive read-write-read-write sequence until there are no more reads to perform.</p>

<p>Since all these operations are part of the Flashback process, they must be marked with a “pass” to be executed by raftstore.</p>

<p>Therefore, it is also quite reasonable to add a Write “pass” during the process_write.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">process_write</span><span class="p">(</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">snapshot</span><span class="p">:</span> <span class="n">S</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">WriteContext</span><span class="o">&lt;</span><span class="nv">'_</span><span class="p">,</span> <span class="n">L</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">WriteResult</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="n">write_data</span><span class="py">.extra.for_flashback</span> <span class="o">=</span> <span class="k">true</span><span class="p">;</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="n">next_lock_key</span><span class="nf">.is_none</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="n">next_write_key</span><span class="nf">.is_none</span><span class="p">()</span> <span class="p">{</span>    
        <span class="o">...</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">next_cmd</span> <span class="o">=</span> <span class="n">FlashbackToVersionReadPhase</span> <span class="p">{</span>
            <span class="o">...</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>For process_read, since it is reading from a snapshot, a Read pass is added when reading the snapshot.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">exec_snapshot</span><span class="p">()</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="py">.for_flashback</span> <span class="p">{</span>
        <span class="n">flags</span> <span class="p">|</span><span class="o">=</span> <span class="nn">WriteBatchFlags</span><span class="p">::</span><span class="n">FLASHBACK</span><span class="nf">.bits</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="o">...</span>
    <span class="k">self</span><span class="py">.router</span><span class="nf">.read</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This also ensures that after the “read and write suspension,” Flashback-related operations can be smoothly executed.</p>

<p>Specifically, the process of repetitive reading and writing’s code is here. To make the process clearer, we have marked the current status:</p>

<ol>
  <li><strong>RollbackLock</strong>: It is necessary to delete all lock records where the start_ts is greater than the Flashback version;
    <ul>
      <li>Since Flashback will clear pessimistic locks, but the transaction commit will still succeed after that, one way to prevent this is to write a Rollback at the same place where the lock is deleted during Flashback;</li>
      <li>Rollback lock: Use the lock’s start_ts to write a Rollback record, ensuring the timestamp is before Flashback.</li>
    </ul>
  </li>
  <li><strong>Prewrite</strong>:
    <ul>
      <li>The TiDB request will carry a start_ts, and TiKV will choose the first key that needs Flashback, writing a lock with this start_ts to prevent the resolved_ts from being advanced before we perform Flashback.</li>
    </ul>
  </li>
  <li><strong>FlashbackWrite</strong>:
    <ul>
      <li>The method of accumulating a whole batch to scan a batch(256) of CF_WRITE;</li>
      <li>To Flashback the data, we need to scan each latest and unique key from CF_WRITE to obtain the old MVCC write record corresponding to the Flashback timestamp. The specific code is here;</li>
      <li>It is necessary to overwrite a copy of the MvccTxn object’s Modify record, taking out the data from the reading stage for judgment:
        <ul>
          <li>If the key does not have a corresponding version, a Delete flag will be placed;</li>
          <li>If the key has a corresponding version, and if “it does not use short_val, and is of LockType::Put”, then it will:
            <ul>
              <li>Obtain the old version value through load_data, build Modify with start_ts, and place it in CF_DEFAULT;</li>
              <li>Build Modify with commit_ts, and place it in CF_WRITE.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Commit</strong>:
    <ul>
      <li>When it is found that all Writes have been written, enter the Commit phase, commit the first user key through commit_flashback_key.</li>
    </ul>
  </li>
</ol>

<h3 id="phase2-1-exec--commit">Phase2-1: Exec &amp; Commit</h3>

<p>Just as described in the section 「Halting the Advancement of resolved_ts」 the general process is as follows:</p>

<ol>
  <li>During Flashback Preparation:
    <ol>
      <li>Scan &amp; Rollback all locks.</li>
      <li>A start_ts is included in the TiDB request, and TiKV selects the first key that needs Flashback, writing a lock with this start_ts to prevent the advancement of resolved_ts before Flashback is performed.</li>
    </ol>
  </li>
  <li>During Flashback Execution:
    <ol>
      <li>Scan &amp; Flashback the writes.
        <ul>
          <li>Modifications in this part will carry a 1PC flag, making tools such as CDC treat it as a modification of a one-phase commit transaction.</li>
        </ul>
      </li>
      <li>Commit the lock written in 1.b to complete the Flashback.</li>
    </ol>
  </li>
</ol>

<p>Returning to the initial future_flashback_to_version, the process also internally goes through req.into and proceeds to FlashbackToVersionReadPhase and FlashbackToVersion for reading and writing. The detailed process has been introduced in the section 「Introduction to the Read and Write Phase」 so it is not repeated here.</p>

<h3 id="phase2-2-finish">Phase2-2: Finish</h3>

<p>After the Flashback is executed, the last thing we need to do is to unset all the configurations for the Flashback service. This brings us back to the classic future_flashback_to_version function.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">future_flashback_to_version</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="k">impl</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">Output</span> <span class="o">=</span> <span class="n">ServerResult</span><span class="o">&lt;</span><span class="n">FlashbackToVersionResponse</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="c1">// 3. notify raftstore the flashback has been finished</span>
    <span class="n">raft_router_clone</span><span class="nf">.significant_send</span><span class="p">(</span><span class="n">region_id</span><span class="p">,</span> <span class="nn">SignificantMsg</span><span class="p">::</span><span class="n">FinishFlashback</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The process is similar to that of Prepare, and the Admin command is sent to complete the persistence takedown.</p>

<p>At this point, the entire Flashback is complete!</p>

<h2 id="appendix">Appendix</h2>

<h3 id="some-potholes">Some potholes</h3>

<p><code class="language-plaintext highlighter-rouge">TODO</code></p>

<h3 id="improvement-points">Improvement points</h3>

<p>The existing mechanism has some shortcomings in terms of usability and ease of use:</p>

<ul>
  <li>The operations are limited to the time before the data is recovered by GC, which may be a small window, and once the safepoint has been updated, it will not be usable.</li>
  <li>If the GC lifetime is extended, historical data will take up a lot of storage space.</li>
  <li>GC lifetime is a global configuration and cannot be adjusted for certain database or table.</li>
</ul>

<h3 id="reference">Reference</h3>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-read">TiKV Source Code reading</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-write">TiKV Source Code writing</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-7">TiKV Source Code startup grpc</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-12/">TiKV Source Code distributed transaction</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-13">TiKV Source Code MVCC</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-17">TiKV Source Code raftstore</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-18">TiKV Source Code raft propose apply&amp;commit</a></p>]]></content><author><name></name></author><category term="distributed" /></entry><entry><title type="html">Flashback TiKV Chinese</title><link href="http://localhost:4000/distributed/2023/05/20/Flashback-in-TiKV.html" rel="alternate" type="text/html" title="Flashback TiKV Chinese" /><published>2023-05-20T17:43:28+08:00</published><updated>2023-05-20T17:43:28+08:00</updated><id>http://localhost:4000/distributed/2023/05/20/Flashback-in-TiKV</id><content type="html" xml:base="http://localhost:4000/distributed/2023/05/20/Flashback-in-TiKV.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#背景介绍" id="markdown-toc-背景介绍">背景介绍</a>    <ul>
      <li><a href="#执行与效果" id="markdown-toc-执行与效果">执行与效果</a></li>
      <li><a href="#具体实现" id="markdown-toc-具体实现">具体实现</a>        <ul>
          <li><a href="#采用-region-锁停读写调度" id="markdown-toc-采用-region-锁停读写调度">采用 Region 锁停读写调度</a></li>
          <li><a href="#大致流程" id="markdown-toc-大致流程">大致流程</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#代码分析" id="markdown-toc-代码分析">代码分析</a>    <ul>
      <li><a href="#流程概览" id="markdown-toc-流程概览">流程概览</a></li>
      <li><a href="#phase1-1-prepare" id="markdown-toc-phase1-1-prepare">Phase1-1: Prepare</a>        <ul>
          <li><a href="#prepare-flashback" id="markdown-toc-prepare-flashback">Prepare Flashback</a></li>
          <li><a href="#停读" id="markdown-toc-停读">停读</a></li>
          <li><a href="#readlocal--staleread" id="markdown-toc-readlocal--staleread">ReadLocal &amp; StaleRead</a></li>
          <li><a href="#停写" id="markdown-toc-停写">停写</a></li>
        </ul>
      </li>
      <li><a href="#phase1-2-prewrite" id="markdown-toc-phase1-2-prewrite">Phase1-2: Prewrite</a>        <ul>
          <li><a href="#停止-resolved-_ts-的推进" id="markdown-toc-停止-resolved-_ts-的推进">停止 resolved _ts 的推进</a></li>
          <li><a href="#读写阶段介绍" id="markdown-toc-读写阶段介绍">读写阶段介绍</a></li>
        </ul>
      </li>
      <li><a href="#phase2-1-exec--commit" id="markdown-toc-phase2-1-exec--commit">Phase2-1: Exec &amp; Commit</a></li>
      <li><a href="#phase2-2-finish" id="markdown-toc-phase2-2-finish">Phase2-2: Finish</a></li>
    </ul>
  </li>
  <li><a href="#appendix" id="markdown-toc-appendix">Appendix</a>    <ul>
      <li><a href="#一些踩过的坑" id="markdown-toc-一些踩过的坑">一些踩过的坑</a></li>
      <li><a href="#改进点" id="markdown-toc-改进点">改进点</a></li>
      <li><a href="#参考文档" id="markdown-toc-参考文档">参考文档</a></li>
    </ul>
  </li>
</ul>

<p>这是一篇原本要作为产品介绍的文章，但种种原因搁置了，最近又在完善相关功能，索性就完善一下发出来。感恩 <a href="https://ipotato.me/">JmPotato</a> 哥哥的带飞~</p>

<p>代码请见：<a href="https://github.com/pingcap/tidb/issues/37197">roadmap</a> &amp; <a href="https://github.com/tikv/tikv/issues/13303">TiKV tracking issue</a></p>

<h2 id="背景介绍">背景介绍</h2>

<p>Flashback（通常指 Oracle Flashback）是用于在用户发生误操作的时候，快速回滚至原先版本，避免产生重大损失的特性。</p>

<p>游戏行业中会不时出现版本错误等问题，定期的备份只能回滚到备份时间点，且浪费资源。TiDB v6.4.0 引入了 FLASHBACK CLUSTER TO TIMESTAMP 语法，其功能是将集群、数据库、数据表的数据恢复到特定的时间点。</p>

<p>在 TiDB 中，存在一些相关的功能：</p>

<ul>
  <li>MVCC &amp; GC：数据更新或删除都是增加新版本，历史版本通过 GC 机制进行清理。存储引擎中保存有一定时间内的历史记录，这为之后的各种恢复数据功能提供了可能。</li>
  <li>通过系统变量 tidb_snapshot 读取历史数据：指定一个 ts（不能早于 GC safepoint），读取对应时间点的数据，并且保证数据是一致的。</li>
  <li>FLASHBACK TABLE：恢复被 DROP 或 TRUNCATE 删除的表以及数据。</li>
</ul>

<p>我们最终采用在多版本并发控制（MVCC）的基础上，取出 TIMESTAMP 之前的最新时间戳数据来覆盖当前的数据。</p>

<h3 id="执行与效果">执行与效果</h3>

<p>『详细操作请参考 <a href="https://docs.pingcap.com/zh/tidb/dev/sql-statement-flashback-to-timestamp">用户文档</a>』</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mysql</span><span class="o">&gt;</span> <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">t</span><span class="p">(</span><span class="n">a</span> <span class="nb">INT</span><span class="p">);</span>
<span class="n">Query</span> <span class="n">OK</span><span class="p">,</span> <span class="mi">0</span> <span class="k">rows</span> <span class="n">affected</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">09</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">t</span><span class="p">;</span>
<span class="n">Empty</span> <span class="k">set</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">01</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="n">now</span><span class="p">();</span>
<span class="o">+</span><span class="c1">---------------------+</span>
<span class="o">|</span> <span class="n">now</span><span class="p">()</span>               <span class="o">|</span>
<span class="o">+</span><span class="c1">---------------------+</span>
<span class="o">|</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">16</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">---------------------+</span>
<span class="mi">1</span> <span class="k">row</span> <span class="k">in</span> <span class="k">set</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">02</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">t</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="n">Query</span> <span class="n">OK</span><span class="p">,</span> <span class="mi">1</span> <span class="k">row</span> <span class="n">affected</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">02</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">t</span><span class="p">;</span>
<span class="o">+</span><span class="c1">------+</span>
<span class="o">|</span> <span class="n">a</span>    <span class="o">|</span>
<span class="o">+</span><span class="c1">------+</span>
<span class="o">|</span>    <span class="mi">1</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">------+</span>
<span class="mi">1</span> <span class="k">row</span> <span class="k">in</span> <span class="k">set</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">01</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="n">FLASHBACK</span> <span class="k">CLUSTER</span> <span class="k">TO</span> <span class="nb">TIMESTAMP</span> <span class="s1">'2022-09-28 17:24:16'</span><span class="p">;</span>
<span class="n">Query</span> <span class="n">OK</span><span class="p">,</span> <span class="mi">0</span> <span class="k">rows</span> <span class="n">affected</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">20</span> <span class="n">sec</span><span class="p">)</span>

<span class="n">mysql</span><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">t</span><span class="p">;</span>
<span class="n">Empty</span> <span class="k">set</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">00</span> <span class="n">sec</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="具体实现">具体实现</h3>

<h4 id="采用-region-锁停读写调度">采用 Region 锁停读写调度</h4>

<p>我们在 Flashback 中采用 Region 锁来阻断 Flashback 过程中的所有读写以及调度，避免产生任何可能导致数据不一致的外部因素。</p>

<p><strong>通过给 Region 先上锁再 Flashback，我们可以获得以下好处：</strong></p>

<ul>
  <li>阻断任何 Flashback 过程中的读写以及调度，避免产生任何可能导致数据不一致的外部因素；</li>
  <li>由于上锁后的 Region 不会产生额外的数据写入，便于 Flashback 自由地写入和重试；</li>
  <li>由于上锁后的 Region 不会产生额外的数据写入，不再需要额外维护集群内不同 Store 和不同 Region 当前的 Flashback 成功失败状态，只需要无脑重试直到成功即可；</li>
  <li>Region 级别更符合 TiKV 内部数据管理的粒度。</li>
</ul>

<h4 id="大致流程">大致流程</h4>

<p>TiDB 首先会去判断：</p>

<ul>
  <li>FlashbackTS：是否是未来时间点，是否大于 minSafeTS，是否在 GC Safe time 内</li>
  <li>是否有非 Flashback ddl job 在时间范围内执行过</li>
  <li>是否有 DDL 任务正在执行</li>
  <li>关闭 GC，PD 调度和 auto analyze 然后开始调用 TiKV 的两阶段</li>
  <li><strong>第一阶段（Region 锁定）</strong>
    <ol>
      <li>TiDB 来确定执行 Flashback 请求的 key range；</li>
      <li>TiDB 以 region 为单位，向不同 region 发送 kv_prepare_flashback_to_version 请求，阻止读、写和调度；</li>
      <li>调用 PD 接口去拿最新的 TSO，作为执行 Flashback 的 startTS。TiDB 会持久化该 startTS，来保证 TiDB 在失败重启后也能使用相同 TS；</li>
      <li>用 Region 锁来让每个 Region 独立处理自己的 Flashback 进度
        <ul>
          <li>扫描所有的 MVCC Lock 并进行 rollback；</li>
          <li>TiKV 会在 CF_WRITE 中选择最新的 user key，并以上面提到的 startTS 先 Prewrite 上一个锁，停止 resolved_ts 的推进，将在第二阶段 Commit 上；</li>
        </ul>
      </li>
      <li>TiDB 检查所有请求是否成功返回，并重试失败请求，直到整个锁定阶段完成。</li>
    </ol>
  </li>
  <li><strong>第二阶段（执行 Flashback）</strong>
    <ol>
      <li>TiDB 取上面提到的 startTS，以及去 PD 拿最新的 TSO 作为 commitTS，TiDB 同样会持久化该 startTS，并向不同 region 发送 kv_flashback_to_version 请求 ；</li>
      <li>每个 Region 独立处理自己的 Flashback 进度
        <ul>
          <li>扫描出需要 Flashback 到的时间点以后有版本变化的键，为扫描出的键写上旧的 MVCC 版本；</li>
          <li>Commit 第一阶段中 Prewrite 写入的锁，并在完成后摘掉 Region 锁；</li>
        </ul>
      </li>
      <li>TiDB 检查所有请求是否成功返回，并以相同的 startTS 和 commitTS 重试那些失败的请求，直到整个 Flashback 执行完成。</li>
    </ol>
  </li>
</ul>

<h2 id="代码分析">代码分析</h2>

<p>让我们从 TiKV 启动开始说起 :)</p>

<p>从 cmd/tikv-server/main.rs 开始，TiKV 完成配置一系列参数后，main 函数末尾走到 server::run_tikv(config) 运行 TiKV server，通过 main 中所配置的参数选择对应 Engine，调用 run_impl 函数，在 run_server 中进行绑定，并启动 grpc_server.start(); 服务。具体的绑定启动流程可以查看<a href="https://cn.pingcap.com/blog/tikv-source-code-reading-7">此文档</a>。</p>

<p>本文关注的 Flashback 位于 <a href="https://github.com/pingcap/kvproto/blob/master/proto/tikvpb.proto#L20">kvproto</a> 对应的此处</p>

<div class="language-protobuf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">rpc</span> <span class="n">KvPrepareFlashbackToVersion</span><span class="p">(</span><span class="n">kvrpcpb.PrepareFlashbackToVersionRequest</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">kvrpcpb.PrepareFlashbackToVersionResponse</span><span class="p">)</span> <span class="p">{}</span>
<span class="k">rpc</span> <span class="n">KvFlashbackToVersion</span><span class="p">(</span><span class="n">kvrpcpb.FlashbackToVersionRequest</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">kvrpcpb.FlashbackToVersionResponse</span><span class="p">)</span> <span class="p">{}</span>
</code></pre></div></div>

<p>回到 TiKV 代码，TiKV 包含多个 gRPC service。其中最重要的一个是 KvService，位于 src/server/service/kv.rs 文件中。包括 TiKV 的 kv_get，kv_scan，kv_prewrite，kv_commit 等事务操作的 API。本文 Flashback 由于采用事务模型，很自然地放在此文件中。</p>

<h3 id="流程概览">流程概览</h3>

<p>让我们先来纵览一下 Flashback 整体流程，抽出主要代码大致可以看出主要就是四步：</p>

<ol>
  <li>在开始正式的覆盖写等操作之前，先通过 raft_router 发送一个 Admin 的 PrepareFlashback 指令，完成 region meta 的持久化；</li>
  <li>在 region 被标识为 Flashback 状态后，prewrite 第一个 user_key 来阻止 resolved_ts 的推进；</li>
  <li>执行 Flashback并 commit 第 2 步写入的 key；</li>
  <li>Flashback 执行结束后通过 raft_router 发送一个 FinishFlashback 指令，进行数据清理。</li>
</ol>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// First Phase</span>
<span class="k">fn</span> <span class="nf">future_prepare_flashback_to_version</span><span class="p">()</span> <span class="p">{</span>
 <span class="c1">// 1. prepare the raftstore for the later flashback.</span>
 <span class="nf">send_flashback_msg</span><span class="p">(</span><span class="o">..</span><span class="p">,</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span><span class="p">);</span>
 <span class="c1">// 2.prewrite the first user key to prevent `resolved_ts` from advancing.</span>
 <span class="k">let</span> <span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="o">=</span> <span class="nf">paired_future_callback</span><span class="p">();</span>
 <span class="n">res</span> <span class="o">=</span> <span class="n">storage</span><span class="nf">.sched_txn_command</span><span class="p">(</span><span class="n">req</span><span class="nf">.clone</span><span class="p">()</span><span class="nf">.into</span><span class="p">(),</span> <span class="n">cb</span><span class="p">);</span>
<span class="p">}</span>
<span class="c1">// Second Phase</span>
<span class="k">fn</span> <span class="nf">future_flashback_to_version</span><span class="p">()</span> <span class="p">{</span>
 <span class="c1">// 3. execute overwrite and commit the first user key.</span>
 <span class="k">let</span> <span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="o">=</span> <span class="nf">paired_future_callback</span><span class="p">();</span>
 <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="n">storage_clone</span><span class="nf">.sched_txn_command</span><span class="p">(</span><span class="n">req</span><span class="nf">.into</span><span class="p">(),</span> <span class="n">cb</span><span class="p">);</span>
 <span class="c1">// 4. notify raftstore flashback has been finished.</span>
 <span class="nf">send_flashback_msg</span><span class="p">(</span><span class="o">..</span><span class="p">,</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">FinishFlashback</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>那就让我们首先进入第一阶段：prepare 模块！</p>

<h3 id="phase1-1-prepare">Phase1-1: Prepare</h3>

<p>Prepare 函数的目的可以概况为：停读停写停调度，持久化 Flashback 状态，停止 resolved_ts 的推进。</p>

<p>首先介绍“停读写停调度”，具体原因已经在背景介绍小节中解释过。为了实现这个目的，直觉上是在所有读写调度任务执行处进行隔断。由于 TiKV 底层采用 Raft 协议，最终会进行 Propose，Commit 然后 Apply 的流程，那么很自然地在进行 Propose 前隔断掉读写调度。</p>

<blockquote>
  <p>此处剧透 Flashback 实现为：在 Propose 处快速隔断掉 Flashback 过程中的其他读写，在 Apply 处隔断进行兜底。</p>
</blockquote>

<p>通过此文章可以了解到在 TiKV 处理 Proposal 的大致流程 <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-18">TiKV 源码解析系列文章（十八）Raft Propose 的 Commit 和 Apply 情景分析</a></p>

<p>一言以蔽之：TiKV 使用了两个线程池来处理 Proposal，并且将一个 Raft Peer 分成了两部分：PeerFsm和 ApplyFsm。在处理 Proposal 的过程中，首先由 PeerFsm获取日志并驱动 Raft 内部的状态机，由 ApplyFsm根据已提交日志修改对应数据的状态机（region 信息和用户数据）。</p>

<blockquote>
  <p>可通过此文章了解 PeerFsm 和  ApplyFsm <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-17">TiKV 源码解析系列文章（十七）raftstore 概览</a></p>
</blockquote>

<p>在 “PeerFsm获取日志并驱动 Raft 内部的状态机”时，会走到下面函数：</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">propose_raft_command_internal</span><span class="p">()</span> <span class="p">{</span>
 <span class="k">match</span> <span class="k">self</span><span class="nf">.pre_propose_raft_command</span><span class="p">(</span><span class="o">&amp;</span><span class="n">msg</span><span class="p">)</span> <span class="p">{</span> <span class="o">..</span> <span class="p">}</span>

 <span class="k">if</span> <span class="k">self</span><span class="py">.fsm.peer</span><span class="nf">.propose</span><span class="p">(</span><span class="k">self</span><span class="py">.ctx</span><span class="p">,</span> <span class="n">cb</span><span class="p">,</span> <span class="n">msg</span><span class="p">,</span> <span class="n">resp</span><span class="p">,</span> <span class="n">diskfullopt</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">self</span><span class="py">.fsm.has_ready</span> <span class="o">=</span> <span class="k">true</span><span class="p">;</span>
 <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>我们发现 PeerFsmDelegate::pre_propose_raft_command 函数会在 propose request 前进行检查。</p>

<p>那么很自然地将判断当前 request 是否为 Flashback 的检查放在此处。</p>

<p>需要关注的一个地方是：</p>

<p>当然不能全盘隔断，Flashback 也需要走 raft 流程，应当给予通行证。</p>

<p>随之我们发现在 RaftCmdRequest 中的 header 里面有个 flags，可以将通行证放在此处。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">fn</span> <span class="nf">pre_propose_raft_command</span><span class="p">(</span>
     <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span>
     <span class="n">req</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">RaftCmdRequest</span><span class="p">,</span>
 <span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;</span><span class="n">RaftCmdResponse</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
     <span class="c1">// When in the flashback state, we should not allow any other request to be proposed.</span>
     <span class="k">if</span> <span class="k">self</span><span class="nf">.region</span><span class="p">()</span><span class="py">.is_in_flashback</span> <span class="p">{</span>
         <span class="k">let</span> <span class="n">flags</span> <span class="o">=</span> <span class="n">req</span><span class="nf">.get_header</span><span class="p">()</span><span class="nf">.get_flags</span><span class="p">();</span>
         <span class="k">if</span> <span class="o">!</span><span class="n">flags</span><span class="nf">.contains</span><span class="p">(</span><span class="n">FLASHBACK</span><span class="p">)</span> <span class="p">{</span>
             <span class="k">return</span> <span class="nb">Err</span><span class="p">;</span>
         <span class="p">}</span>
     <span class="p">}</span>
 <span class="p">}</span>
</code></pre></div></div>

<h4 id="prepare-flashback">Prepare Flashback</h4>

<p>在完成“隔断点”的安插后，为了让 Flashback 相关操作不受隔断顺利通行，我们会在 header 处加上 flag。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// First Phase</span>
<span class="k">fn</span> <span class="n">future_prepare_flashback_to_version</span><span class="p">{</span>
 <span class="c1">// 1. prepare the raftstore for the later flashback. </span>
 <span class="nf">send_flashback_msg</span><span class="p">(</span><span class="o">..</span><span class="p">,</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>所调用的 start_flashback/end_flashback 函数在加上 flag 后发送 admin req.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">fn</span> <span class="n">start_flashback</span><span class="o">/</span><span class="n">end_flashback</span> <span class="p">{</span>
 <span class="o">...</span>
 <span class="n">req</span><span class="nf">.mut_header</span><span class="p">()</span>
     <span class="nf">.set_flags</span><span class="p">(</span><span class="nn">WriteBatchFlags</span><span class="p">::</span><span class="n">FLASHBACK</span><span class="nf">.bits</span><span class="p">());</span>
 <span class="c1">// call admin request directly</span>
 <span class="k">let</span> <span class="n">raft_router</span> <span class="o">=</span> <span class="n">raft_router</span><span class="nf">.lock</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
 <span class="n">raft_router</span><span class="nf">.send_command</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">cb</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
 <span class="o">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Admin request 通过 RaftStoreRouter 构成一条 RaftCommand 发送，会按照 Propose 流程，通过 pre_propose 的检查后到 PeerFsmDelegate.fsm.peer.propose 完成 Propose 一条 Raft Log。</p>

<p>之后 PeerFsm 会将 Proposal 以及已提交日志发送给对应的 ApplyFsm 来到 apply 流程。</p>

<p>ApplyFsm 会针对这些日志进行（见 ApplyFsm::handle_apply）：</p>

<ol>
  <li>完成数据的持久化。</li>
  <li>向 PeerFsm发送 ApplyRes，用于更新 PeerFsm中的 Region 状态。
 在 exec_raft_cmd 会加上 check_flashback_state，进行 Flashback 持久态的判断。此处 region 将在下面的 exec 函数中设置上，由于为串行 apply，因此在下条 cmd 来之前，便会设置好 region 信息。</li>
</ol>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">check_flashback_state</span><span class="p">(</span><span class="k">self</span><span class="py">.region</span><span class="nf">.get_is_in_flashback</span><span class="p">());</span>

<span class="k">pub</span> <span class="k">fn</span> <span class="nf">check_flashback_state</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="c1">// The admin flashback cmd could be proposed/applied under any state.</span>
    <span class="k">if</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span> <span class="p">||</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">FinishFlashback</span> <span class="p">{</span>
        <span class="k">return</span> <span class="nf">Ok</span><span class="p">(());</span>
    <span class="p">}</span>
    <span class="k">let</span> <span class="n">is_flashback_request</span> <span class="o">=</span> <span class="n">req</span><span class="nf">.get_header</span><span class="p">()</span><span class="nf">.get_flags</span><span class="p">()</span>
                            <span class="nf">.contains</span><span class="p">(</span><span class="n">FLASHBACK</span><span class="p">);</span>
    <span class="o">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>完成 check 后执行 ApplyDelegate::exec_admin_cmd ，最终识别 Flashback 标识，到达我们的目的地 exec_flashback 函数。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span> <span class="p">|</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">FinishFlashback</span> <span class="k">=&gt;</span> 
    <span class="k">self</span><span class="nf">.exec_flashback</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">request</span><span class="p">),</span>
</code></pre></div></div>

<p>exec_flashback 放入 region 的元信息中，并完成持久态 RegionLocalState 的更新。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">exec_flashback</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">is_in_flashback</span> <span class="o">=</span> <span class="n">req</span><span class="nf">.get_cmd_type</span><span class="p">()</span> <span class="o">==</span> <span class="nn">AdminCmdType</span><span class="p">::</span><span class="n">PrepareFlashback</span><span class="p">;</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">region</span> <span class="o">=</span> <span class="k">self</span><span class="py">.region</span><span class="nf">.clone</span><span class="p">();</span>
    <span class="n">region</span><span class="nf">.set_is_in_flashback</span><span class="p">(</span><span class="n">is_in_flashback</span><span class="p">);</span>


    <span class="nf">put_msg_cf</span><span class="p">(</span><span class="n">CF_RAFT</span><span class="p">,</span> <span class="o">&amp;</span><span class="nn">keys</span><span class="p">::</span><span class="nf">region_state_key</span><span class="p">(</span><span class="n">region_id</span><span class="p">),</span> <span class="o">&amp;</span><span class="n">old_state</span><span class="p">)</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="nn">ApplyResult</span><span class="p">::</span><span class="nf">Res</span><span class="p">(</span><span class="nn">ExecResult</span><span class="p">::</span><span class="n">SetFlashbackState</span> <span class="p">{</span> <span class="n">region</span> <span class="p">}</span> <span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>ApplyFSM 在应用一批日志之后会发送一条 ApplyRes 的消息到 PeerFsm。</p>

<p>最终又回到 PeerFsm 的PeerFsmDelegate::handle_msgs 函数，走到 PeerMsg::ApplyRes { res } 分支，调用 PeerFsmDelegate::on_apply_res 完成对 Flashback 的持久态更新。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">fn</span> <span class="nf">on_set_flashback_state</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">is_in_flashback</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// update flashback state</span>
        <span class="k">self</span><span class="nf">.update_region</span><span class="p">();</span>
        <span class="c1">// 此行代码在做的事将在「停读 - ReadLocal &amp; StaleRead 」小节解释</span>
        <span class="k">self</span><span class="py">.fsm.peer</span><span class="nf">.leader_lease_mut</span><span class="p">()</span><span class="nf">.expire_remote_lease</span><span class="p">();</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>梳理完后，很清晰的看到存在两个对非 Flashback 操作的隔断位置，分别位于 propose 和 apply 处。</p>

<p>那么随之而来的问题便是：在何处加入对 Flashback req 的“通行证”呢？</p>

<p>Flashback 既然可以理解为基于 MVCC 进行实现，那么便也需要通过 MVCC 的读写接口流程。因此溯源一下 MVCC 的读写流程，便能更好地找到“通行证”的放置位置。</p>

<h4 id="停读">停读</h4>

<p>让我们首先来梳理一下读流程，可结合 <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-read">TiKV 源码阅读三部曲（二）读流程 来阅读详细读过程</a>。</p>

<p>在调用到 LocalReader::propose_raft_command 时，发现是通过 LocalReader::pre_propose_raft_command 进行判断 req。</p>

<p>会对 ReadLocal 和 StaleRead 进行特定逻辑处理，其余信息将转发给 RaftStore 来执行，即由 ProposalRouter::send 转发后走到我们之前所提到的 Propose 流程。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">propose_raft_command</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">match</span> <span class="k">self</span><span class="nf">.pre_propose_raft_command</span><span class="p">(</span><span class="o">&amp;</span><span class="n">req</span><span class="p">)</span> <span class="p">{</span> 
        <span class="nn">RequestPolicy</span><span class="p">::</span><span class="n">ReadLocal</span> <span class="k">=&gt;</span> <span class="o">..</span>
        <span class="nn">RequestPolicy</span><span class="p">::</span><span class="n">StaleRead</span> <span class="k">=&gt;</span> <span class="o">..</span>
        <span class="c1">// Forward to raftstore.</span>
        <span class="n">_</span> <span class="k">=&gt;</span> <span class="k">self</span><span class="nf">.redirect</span><span class="p">(</span><span class="nn">RaftCommand</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">cb</span><span class="p">)),</span>     
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>这样很自然地对于除 ReadLocal 和 StaleRead 外的 req，都可以做出以下隔断：</p>

<p>在进入 read 之前，判断一下 req 中是否有 Flashback flag，便实现了在开启 Flashback 之后，只能让 Flashback 相关的读指令通行。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">exec_snapshot</span><span class="p">()</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="py">.for_flashback</span> <span class="p">{</span>
        <span class="n">flags</span> <span class="p">|</span><span class="o">=</span> <span class="nn">WriteBatchFlags</span><span class="p">::</span><span class="n">FLASHBACK</span><span class="nf">.bits</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">header</span><span class="nf">.set_flags</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
    <span class="o">...</span>
    <span class="k">self</span><span class="py">.router</span><span class="nf">.read</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Flashback 执行时将对 exec_snapshot 进行 ctx.for_flashback 的设置，其中 for_flashback 从哪获取的将在下文 「Phase2-1: Exec - 读取阶段」 解释。</p>

<h4 id="readlocal--staleread">ReadLocal &amp; StaleRead</h4>

<p>正如上小节提到会对 ReadLocal 和 StaleRead 存在着特定逻辑处理，可以作为扩展阅读资料了解 <a href="https://cn.pingcap.com/blog/lease-read">TiKV 功能介绍 - Lease Read</a> &amp;&amp; <a href="https://docs.pingcap.com/zh/tidb/dev/stale-read">Stale Read 功能的使用场景</a>。</p>

<p>首先看看ReadLocal 的特殊处理即对 Peer 中的 leader_lease 进行检查。当发现不在租期内时，便会转发到正常 Propose 流程中。</p>

<p>因此我们采取：在 prepare Flashback 时，对 lease 手动设置超时，来确保 local read 不会执行。</p>

<p>这便是对之前完成 apply res 之后与更新 region 同时所做的事。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">fn</span> <span class="nf">on_set_flashback_state</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">is_in_flashback</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Update the region meta.</span>
        <span class="k">self</span><span class="nf">.update_region</span><span class="p">()</span>
        <span class="c1">// Let the leader lease to None to ensure that local reads are not executed.</span>
        <span class="k">self</span><span class="py">.fsm.peer</span><span class="nf">.leader_lease_mut</span><span class="p">()</span><span class="nf">.expire_remote_lease</span><span class="p">();</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>而对于 StaleRead 的运行前提是需要不停推进 safe ts（即 resolved_ts）。会在 TiDB 检查 resolved_ts，保证 Flashback 的版本不会超过 resolved_ts，因此也完成隔断。</p>

<p>至此对于读的隔断介绍完毕。</p>

<h4 id="停写">停写</h4>

<p>可参考 <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-write">TiKV 源码阅读三部曲（三）写流程</a> 阅读写请求全链路的执行流程。</p>

<p>在写的过程中 RaftKv::exec_write_requests 内部将会走向 router 进行 Propose 流程，因此在此处加上类似上文「读请求」的判断，只能让 Flashback 相关的写指令通行。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">exec_write_requests</span><span class="p">()</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="n">txn_extra</span><span class="py">.for_flashback</span> <span class="p">{</span>
        <span class="n">flags</span> <span class="p">|</span><span class="o">=</span> <span class="nn">WriteBatchFlags</span><span class="p">::</span><span class="n">FLASHBACK</span><span class="nf">.bits</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">header</span><span class="nf">.set_flags</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
    <span class="o">...</span>
    <span class="k">self</span><span class="py">.router</span><span class="nf">.send_command</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">cb</span><span class="p">,</span> <span class="n">extra_opts</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="phase1-2-prewrite">Phase1-2: Prewrite</h3>

<p>完成停读写调度后，我们遇到了一个新的问题，那就是持续推进的 resolved ts 会导致 CDC 的 Panic.</p>

<h4 id="停止-resolved-_ts-的推进">停止 resolved _ts 的推进</h4>

<p>一言蔽之 Resolved TS（TODO: 介绍 Resolved TS），由于以下原因：</p>

<ul>
  <li>
    <p>Resolved TS 组件通过观察 LockCF 的修改，维护一个 StartTS 的最小堆，有 ResolvedTS = max(ResolvedTS, min(StartTS))；</p>
  </li>
  <li>
    <p>Flashback 将以 Region 为单位移除掉所有的锁；</p>
  </li>
  <li>
    <p>正在进行 Flashback 的 Region 上将不再存在任何的锁，此时 ResolvedTS 将会正常向前推进，无论是否有数据写入。</p>
  </li>
</ul>

<p>那么将会带来：改动的 CommitTS &lt;  ResolvedTS 的情况（Flashback 的改动自始至终都使用同一个 CommitTS，ResolvedTS 随着推进迟早会超过它）。</p>

<p>为防止 resolved_ts 在我们后续执行 Flashback 前被推进，我们采用：TiDB 请求中带上一个 start_ts，TiKV 会在 CF_WRITE 中选择最新的 user key，以此 start_ts prewrite 上一个锁，将在执行完 Flashback 后 commit 清除掉。</p>

<h4 id="读写阶段介绍">读写阶段介绍</h4>

<p>回到最开始的 future_prepare_flashback_to_version 中，首先内部将 req.into。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// First Phase</span>
<span class="k">fn</span> <span class="n">future_prepare_flashback_to_version</span><span class="p">{</span>
    <span class="o">...</span>
    <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="n">storage_clone</span><span class="nf">.sched_txn_command</span><span class="p">(</span><span class="n">req</span><span class="nf">.into</span><span class="p">(),</span> <span class="n">cb</span><span class="p">);</span>
    <span class="o">...</span> 
<span class="p">}</span>
</code></pre></div></div>

<p>在此文件中实现了 PrepareFlashbackToVersionRequest 到 FlashbackToVersionReadPhase 的 from。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span> <span class="nb">From</span><span class="o">&lt;</span><span class="n">PrepareFlashbackToVersionRequest</span><span class="o">&gt;</span> <span class="k">for</span> <span class="n">TypedCommand</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">from</span><span class="p">(</span><span class="k">mut</span> <span class="n">req</span><span class="p">:</span> <span class="n">PrepareFlashbackToVersionRequest</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
        <span class="n">FlashbackToVersionReadPhase</span> <span class="p">{</span> <span class="o">..</span> <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>因此此处调度的实则是 FlashbackToVersionReadPhase，也即对于 sched_txn_command 将会走到由 FlashbackToVersionReadPhase 提供的 process_read 处，在执行完该函数后会触发 FlashbackToVersion 的 process_write。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">process_read</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">snapshot</span><span class="p">:</span> <span class="n">S</span><span class="p">,</span> <span class="n">statistics</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Statistics</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">ProcessResult</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="k">let</span> <span class="n">next_cmd</span> <span class="o">=</span> <span class="n">FlashbackToVersion</span> <span class="p">{</span>
        <span class="o">...</span>
    <span class="p">}</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="nn">ProcessResult</span><span class="p">::</span><span class="n">NextCommand</span> <span class="p">{</span>
        <span class="n">cmd</span><span class="p">:</span> <span class="nn">Command</span><span class="p">::</span><span class="nf">FlashbackToVersion</span><span class="p">(</span><span class="n">next_cmd</span><span class="p">),</span>
    <span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div>

<p>大致流程按照如此往复读写读写，直到没有读为止。</p>

<p>由于都是属于 Flashback 操作，需要加上「通行证」后才能被 raftstore 执行。</p>

<p>因此也很合理地在 process_write 加上 Write 的通行证。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">process_write</span><span class="p">(</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">snapshot</span><span class="p">:</span> <span class="n">S</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">WriteContext</span><span class="o">&lt;</span><span class="nv">'_</span><span class="p">,</span> <span class="n">L</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">WriteResult</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="n">write_data</span><span class="py">.extra.for_flashback</span> <span class="o">=</span> <span class="k">true</span><span class="p">;</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="n">next_lock_key</span><span class="nf">.is_none</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="n">next_write_key</span><span class="nf">.is_none</span><span class="p">()</span> <span class="p">{</span>    
        <span class="o">...</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">next_cmd</span> <span class="o">=</span> <span class="n">FlashbackToVersionReadPhase</span> <span class="p">{</span>
            <span class="o">...</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>而对于 process_read，由于是从 snapshot 中读取，因此会在读取 snapshot 时加上 Read 的通行证。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">exec_snapshot</span><span class="p">()</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="py">.for_flashback</span> <span class="p">{</span>
        <span class="n">flags</span> <span class="p">|</span><span class="o">=</span> <span class="nn">WriteBatchFlags</span><span class="p">::</span><span class="n">FLASHBACK</span><span class="nf">.bits</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="o">...</span>
    <span class="k">self</span><span class="py">.router</span><span class="nf">.read</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>这也便实现了在「停读停写」后能顺利执行 flashback 相关操作。</p>

<p>具体到往复读写的过程，代码位于此处。为了流程更加清晰，我们标识出当前状态：</p>

<ol>
  <li><strong>RollbackLock</strong>：需要删除所有 start_ts 大于 Flashback version 的锁记录；
    <ul>
      <li>由于 Flashback 会把悲观锁清掉，但是清掉之后事务 commit 还是会成功的，阻止的方法是在 Flashback 删掉锁的时候，原地写 Rollback ；</li>
      <li>Rollback lock ：采用 lock 的 start_ts 写 Rollback 记录，确保时间戳会在 Flashback 之前。</li>
    </ul>
  </li>
  <li><strong>Prewrite</strong>：
    <ul>
      <li>TiDB 请求中会带上一个 start_ts， TiKV 会在需要 Flashback 的 key 中选择第一个 key，以此 start_ts 写入一个锁，以防止 resolved_ts 在我们后续进行 Flashback 前被推进。</li>
    </ul>
  </li>
  <li><strong>FlashbackWrite</strong>：
    <ul>
      <li>采用攒够一整个 batch 的方式扫描一批（256个）的 CF_WRITE；</li>
      <li>为了 Flashback 数据，我们需要从 CF_WRITE 中扫描每一个最新且独特的 key，来获得 Flashback timestamp 所对应的旧 MVCC 写记录。具体代码在此处；</li>
      <li>需要覆写一份 MvccTxn 对象的 Modify 记录，取出读取阶段的数据进行判断：</li>
    </ul>
    <ul>
      <li>如果 key 不存在对应的 version，将放置一个 Delete 标识；</li>
      <li>如果 key 存在对应的 version，且如果「不是采用 short_val，并为 LockType::Put」 ，那么将：
        <ul>
          <li>通过 load_data 获取 old version value，以 start_ts 构建 Modify，放在 CF_DEFAULT 中；</li>
          <li>通过 commit_ts 构建 Modify，放在 CF_WRITE 中。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Commit</strong>：
    <ul>
      <li>当发现已经完成所有 Write 的写入后，进入 Commit 阶段，通过 commit_flashback_key Commit first user key。</li>
    </ul>
  </li>
</ol>

<h3 id="phase2-1-exec--commit">Phase2-1: Exec &amp; Commit</h3>

<p>正如 「停止 resolved _ts 的推进」小节中描述的一样，大致流程如下：</p>

<ol>
  <li>Prepare Flashback 时：
    <ol>
      <li>Scan &amp; Rollback all locks.</li>
      <li>TiDB 请求中会带上一个 start_ts， TiKV 会在需要 Flashback 的 key 中选择第一个 key，以此 start_ts 写入一个锁，以防止 resolved_ts 在我们后续进行 Flashback 前被推进。</li>
    </ol>
  </li>
  <li>执行 Flashback 时：
    <ol>
      <li>Scan &amp; flashback the writes.
        <ul>
          <li>这部分的改动会带上 1PC 的 flag，让 CDC 等工具将其视为一阶段事务的修改</li>
        </ul>
      </li>
      <li>commit 在 1.b 中写入的锁，完成 Flashback</li>
    </ol>
  </li>
</ol>

<p>回到最开始的 future_flashback_to_version 中，也会内部进行 req.into 后走到 FlashbackToVersionReadPhase 和 FlashbackToVersion 进行读写，大致流程在「读写阶段介绍」小节已经详细介绍，就不再赘述。</p>

<h3 id="phase2-2-finish">Phase2-2: Finish</h3>

<p>在执行完成 Flashback 后，最后需要做的便是 unset 掉所有为 Flashback 服务的配置。那么便回到了经典 future_flashback_to_version 函数。</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">future_flashback_to_version</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="k">impl</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">Output</span> <span class="o">=</span> <span class="n">ServerResult</span><span class="o">&lt;</span><span class="n">FlashbackToVersionResponse</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="c1">// 3. notify raftstore the flashback has been finished</span>
    <span class="n">raft_router_clone</span><span class="nf">.significant_send</span><span class="p">(</span><span class="n">region_id</span><span class="p">,</span> <span class="nn">SignificantMsg</span><span class="p">::</span><span class="n">FinishFlashback</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>流程与 Prepare 大致相同，发送 Admin 指令，完成持久态的取缔。</p>

<p>至此，完成整个 Flashback！</p>

<h2 id="appendix">Appendix</h2>

<h3 id="一些踩过的坑">一些踩过的坑</h3>

<p><code class="language-plaintext highlighter-rouge">TODO</code></p>

<h3 id="改进点">改进点</h3>

<p>现有机制在可用性和易用性上有一些不足：</p>

<ul>
  <li>相关操作仅限于数据被 GC 回收之前，这个窗口期可能比较小，一旦 safepoint 更新过了之后就不能用了；</li>
  <li>如果把 GC lifetime 调长，历史数据将占用大量的存储空间；</li>
  <li>GC lifetime 是全局配置，不能针对某些 database 或 table 调整；</li>
</ul>

<h3 id="参考文档">参考文档</h3>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-read">TiKV 源码阅读三部曲（二）读流程 来阅读详细读过程</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-write">TiKV 源码阅读三部曲（三）写流程</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-7">TiKV 源码解析系列文章（七）gRPC Server 的初始化和启动流程</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-12/">TiKV 源码解析系列文章（十二）分布式事务</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-13">TiKV 源码解析系列文章（十三）MVCC 数据读取</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-17">TiKV 源码解析系列文章（十七）raftstore 概览</a></p>

<p><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-18">TiKV 源码解析系列文章（十八）Raft Propose 的 Commit 和 Apply 情景分析</a></p>]]></content><author><name></name></author><category term="distributed" /></entry><entry><title type="html">文件系统总结</title><link href="http://localhost:4000/linux/2020/12/12/FileSystem-Thinking.html" rel="alternate" type="text/html" title="文件系统总结" /><published>2020-12-12T23:32:12+08:00</published><updated>2020-12-12T23:32:12+08:00</updated><id>http://localhost:4000/linux/2020/12/12/FileSystem-Thinking</id><content type="html" xml:base="http://localhost:4000/linux/2020/12/12/FileSystem-Thinking.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#总览" id="markdown-toc-总览">总览</a></li>
  <li><a href="#获取文件属性" id="markdown-toc-获取文件属性">获取文件属性</a></li>
  <li><a href="#inode-与块" id="markdown-toc-inode-与块">inode 与块</a>    <ul>
      <li><a href="#inode-的逻辑结构" id="markdown-toc-inode-的逻辑结构">inode 的逻辑结构</a></li>
      <li><a href="#目录项" id="markdown-toc-目录项">目录项</a></li>
      <li><a href="#硬软链接" id="markdown-toc-硬软链接">硬软链接</a></li>
    </ul>
  </li>
  <li><a href="#文件系统布局" id="markdown-toc-文件系统布局">文件系统布局</a>    <ul>
      <li><a href="#超级块" id="markdown-toc-超级块">超级块</a></li>
      <li><a href="#inode-位图和块位图" id="markdown-toc-inode-位图和块位图">inode 位图和块位图</a></li>
    </ul>
  </li>
  <li><a href="#文件管理" id="markdown-toc-文件管理">文件管理</a>    <ul>
      <li><a href="#文件描述符" id="markdown-toc-文件描述符">文件描述符</a></li>
      <li><a href="#文件表" id="markdown-toc-文件表">文件表</a></li>
    </ul>
  </li>
  <li><a href="#open-打开文件时会发生什么" id="markdown-toc-open-打开文件时会发生什么">open 打开文件时会发生什么</a>    <ul>
      <li><a href="#调用链大致" id="markdown-toc-调用链大致">调用链大致</a></li>
      <li><a href="#深入描述一下" id="markdown-toc-深入描述一下">深入描述一下：</a></li>
    </ul>
  </li>
  <li><a href="#write--read-文件发生什么" id="markdown-toc-write--read-文件发生什么">write &amp; read 文件发生什么</a></li>
  <li><a href="#总结" id="markdown-toc-总结">总结</a></li>
</ul>

<h2 id="总览">总览</h2>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212183906810.png" alt="image-20201212183906810" /></p>

<p>对于每一个进程，打开的文件都有一个文件描述符，在 files_struct  里面会有文件描述符数组。每个一个文件描述符是这个数组的下标，里面的内容指向一个 file 结构，表示打开的文件。这个结构里面有这个文件对应的  inode，最重要的是这个文件对应的操作 file_operation。如果操作这个文件，就看这个 file_operation 里面的定义了。</p>

<p>对于每一个打开的文件，都有一个 dentry 对应，虽然叫作 directory entry，但是不仅仅表示文件夹，也表示文件。它最重要的作用就是指向这个文件对应的 inode。</p>

<p>如果说 file 结构是一个文件打开以后才创建的，dentry 是放在一个 dentry cache 里面的，文件关闭了，他依然存在，因而他可以更长期的维护内存中的文件的表示和硬盘上文件的表示之间的关系。</p>

<p>inode 结构就表示硬盘上的 inode，包括块设备号等。</p>

<p>几乎每一种结构都有自己对应的 operation 结构，里面都是一些方法，因而当后面遇到对于某种结构进行处理的时候，如果不容易找到相应的处理函数，就先找这个 operation 结构，就清楚了。</p>

<p><strong>思考</strong></p>

<p>对于运行的进程来说，内存就像一个纸箱子，仅仅是一个暂存数据的地方，而且空间有限。如果我们想要进程结束之后，数据依然能够保存下来，就不能只保存在内存里，而是应该保存在外部存储中。</p>

<p>我们最常用的外部存储就是硬盘，数据是以文件的形式保存在硬盘上的。为了管理这些文件，我们在规划文件系统的时候，需要考虑到以下几点。</p>

<p><strong>第一点，文件系统要有严格的组织形式，使得文件能够以块为单位进行存储</strong>。</p>

<p><strong>第二点，文件系统中也要有索引区，用来方便查找一个文件分成的多个块都存放在了什么位置</strong>。</p>

<p><strong>第三点，如果文件系统中有的文件是热点文件，近期经常被读取和写入，文件系统应该有缓存层</strong>。</p>

<p><strong>第四点，文件应该用文件夹的形式组织起来，方便管理和查询</strong>。</p>

<p><strong>第五点，Linux 内核要在自己的内存里面维护一套数据结构，来保存哪些文件被哪些进程打开和使用</strong>。</p>

<p>ls -l 的结果的第一位标识位看出来。</p>

<ul>
  <li>- 表示普通文件；</li>
  <li>d 表示文件夹；</li>
  <li>c 表示字符设备文件；</li>
  <li>b 表示块设备文件；</li>
  <li>s 表示套接字 socket 文件；</li>
  <li>l 表示符号链接，也即软链接，就是通过名字指向另外一个文件，例如下面的代码，instance 这个文件就是指向了 /var/lib/cloud/instances 这个文件。</li>
</ul>

<h2 id="获取文件属性">获取文件属性</h2>

<p>对于命令行来讲，通过 ls 可以得到文件的属性，幕后功臣是</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">fstat</span><span class="p">(</span><span class="kt">int</span> <span class="n">fd</span><span class="p">,</span> <span class="k">struct</span> <span class="n">stat</span> <span class="o">*</span><span class="n">statbuf</span><span class="p">);</span>
<span class="kt">int</span> <span class="nf">lstat</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">pathname</span><span class="p">,</span> <span class="k">struct</span> <span class="n">stat</span> <span class="o">*</span><span class="n">statbuf</span><span class="p">);</span>
<span class="kt">int</span> <span class="nf">stat</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">pathname</span><span class="p">,</span> <span class="k">struct</span> <span class="n">stat</span> <span class="o">*</span><span class="n">statbuf</span><span class="p">);</span>
</code></pre></div></div>

<p>函数 stat 和 lstat 返回的是通过文件名查到的状态信息。这两个方法区别在于，stat  没有处理符号链接（软链接）的能力。如果一个文件是符号链接，stat 会直接返回它所指向的文件的属性，而 lstat  返回的就是这个符号链接的内容，fstat 则是通过文件描述符获取文件对应的属性。</p>

<p>上面三个函数，可以返回与打开的文件描述符相关的文件状态信息。这个信息将会写到类型为 struct stat 的 buf 结构中。</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">stat</span> <span class="p">{</span>
	<span class="n">dev_t</span>     <span class="n">st_dev</span><span class="p">;</span>         <span class="cm">/* ID of device containing file */</span>
	<span class="n">ino_t</span>     <span class="n">st_ino</span><span class="p">;</span>         <span class="cm">/* Inode number */</span>
	<span class="n">mode_t</span>    <span class="n">st_mode</span><span class="p">;</span>        <span class="cm">/* File type and mode */</span>
	<span class="n">nlink_t</span>   <span class="n">st_nlink</span><span class="p">;</span>       <span class="cm">/* Number of hard links */</span>
	<span class="n">uid_t</span>     <span class="n">st_uid</span><span class="p">;</span>         <span class="cm">/* User ID of owner */</span>
	<span class="n">gid_t</span>     <span class="n">st_gid</span><span class="p">;</span>         <span class="cm">/* Group ID of owner */</span>
	<span class="n">dev_t</span>     <span class="n">st_rdev</span><span class="p">;</span>        <span class="cm">/* Device ID (if special file) */</span>
	<span class="kt">off_t</span>     <span class="n">st_size</span><span class="p">;</span>        <span class="cm">/* Total size, in bytes */</span>
	<span class="n">blksize_t</span> <span class="n">st_blksize</span><span class="p">;</span>     <span class="cm">/* Block size for filesystem I/O */</span>
	<span class="n">blkcnt_t</span>  <span class="n">st_blocks</span><span class="p">;</span>      <span class="cm">/* Number of 512B blocks allocated */</span>
	<span class="p">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>打开目录</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/stat.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;dirent.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">stat</span> <span class="n">sb</span><span class="p">;</span>
    <span class="kt">DIR</span> <span class="o">*</span><span class="n">dirp</span><span class="p">;</span>

    <span class="k">struct</span> <span class="n">dirent</span> <span class="o">*</span><span class="n">direntp</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">filename</span><span class="p">[</span><span class="mi">260</span><span class="p">];</span>
    <span class="k">if</span><span class="p">((</span><span class="n">dirp</span> <span class="o">=</span> <span class="n">opendir</span><span class="p">(</span><span class="s">"/home/"</span><span class="p">))</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">perror</span><span class="p">(</span><span class="s">"open dir error!"</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">while</span><span class="p">(</span> <span class="p">(</span><span class="n">direntp</span> <span class="o">=</span> <span class="n">readdir</span><span class="p">(</span><span class="n">dirp</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">NULL</span> <span class="p">)</span> <span class="p">{</span>
        <span class="n">sprintf</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s">"/CS/%s"</span><span class="p">,</span> <span class="n">direntp</span><span class="o">-&gt;</span><span class="n">d_name</span><span class="p">);</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">"name : %s, mode : %d, size : %ld, user id : %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">direntp</span><span class="o">-&gt;</span><span class="n">d_name</span><span class="p">,</span> <span class="n">sb</span><span class="p">.</span><span class="n">st_mode</span><span class="p">,</span> <span class="n">sb</span><span class="p">.</span><span class="n">st_size</span><span class="p">,</span> <span class="n">sb</span><span class="p">.</span><span class="n">st_uid</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">closedir</span><span class="p">(</span><span class="n">dirp</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="inode-与块">inode 与块</h2>

<p><a href="http://www.ruanyifeng.com/blog/2011/12/inode.html">阮一峰的 inode 解释</a></p>

<p>文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。</p>

<p>操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个  sector 组成一个 block。</p>

<p>文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做 inode，中文译名为”索引节点”。</p>

<blockquote>
  <p>块是文件系统的读写单位，因此文件至少要占据一个块</p>
</blockquote>

<p>文件还有<strong>元数据</strong>部分，例如名字、权限等，这就需要一个结构<strong>inode</strong>来存放。</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">ext4_inode</span> <span class="p">{</span>
	<span class="n">__le16</span>	<span class="n">i_mode</span><span class="p">;</span>		<span class="cm">/* File mode */</span>
	<span class="n">__le16</span>	<span class="n">i_uid</span><span class="p">;</span>		<span class="cm">/* Low 16 bits of Owner Uid */</span>
	<span class="n">__le32</span>	<span class="n">i_size_lo</span><span class="p">;</span>	<span class="cm">/* Size in bytes */</span>
	<span class="n">__le32</span>	<span class="n">i_atime</span><span class="p">;</span>	<span class="cm">/* Access time */</span>
	<span class="n">__le32</span>	<span class="n">i_ctime</span><span class="p">;</span>	<span class="cm">/* Inode Change time */</span>
	<span class="n">__le32</span>	<span class="n">i_mtime</span><span class="p">;</span>	<span class="cm">/* Modification time */</span>
	<span class="n">__le32</span>	<span class="n">i_dtime</span><span class="p">;</span>	<span class="cm">/* Deletion Time */</span>
	<span class="n">__le16</span>	<span class="n">i_gid</span><span class="p">;</span>		<span class="cm">/* Low 16 bits of Group Id */</span>
	<span class="n">__le16</span>	<span class="n">i_links_count</span><span class="p">;</span>	<span class="cm">/* Links count */</span>
	<span class="n">__le32</span>	<span class="n">i_blocks_lo</span><span class="p">;</span>	<span class="cm">/* Blocks count */</span>
	<span class="n">__le32</span>	<span class="n">i_flags</span><span class="p">;</span>	<span class="cm">/* File flags */</span>
<span class="p">......</span>
	<span class="n">__le32</span>	<span class="n">i_block</span><span class="p">[</span><span class="n">EXT4_N_BLOCKS</span><span class="p">];</span><span class="cm">/* Pointers to blocks */</span>
	<span class="n">__le32</span>	<span class="n">i_generation</span><span class="p">;</span>	<span class="cm">/* File version (for NFS) */</span>
	<span class="n">__le32</span>	<span class="n">i_file_acl_lo</span><span class="p">;</span>	<span class="cm">/* File ACL */</span>
	<span class="n">__le32</span>	<span class="n">i_size_high</span><span class="p">;</span>
<span class="p">......</span>
<span class="p">};</span>
</code></pre></div></div>

<p>从这个数据结构中，我们可以看出，inode 里面有文件的读写权限 i_mode，属于哪个用户 i_uid，哪个组 i_gid，大小是多少  i_size_io，占用多少个块 i_blocks_io。 ls 命令行的时候，列出来的权限、用户、大小这些信息，就是从这里面取出来的。</p>

<p>另外，这里面还有几个与文件相关的时间。i_atime 是 access time，是最近一次访问文件的时间；i_ctime 是 change time，是<strong>最近一次更改 inode</strong>  的时间；i_mtime 是 modify time，是<strong>最近一次更改文件</strong>的时间。</p>

<blockquote>
  <p>需要注意区分几个地方。首先，访问了，不代表修改了，也可能只是打开看看，就会改变 access time。其次，修改 inode，有可能修改的是用户和权限，没有修改数据部分，就会改变 change time。只有数据也修改了，才改变 modify time。</p>
</blockquote>

<h3 id="inode-的逻辑结构">inode 的逻辑结构</h3>

<p>在 ext2 和 ext3 中，其中前 12 项直接保存了块的位置，也就是说，我们可以通过 i_block[0-11]，直接得到保存文件内容的块。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212161507668.png" alt="image-20201212161507668" style="zoom:67%;" /></p>

<p>如果一个文件比较大，12 块放不下。我们可以让 i_block[12] 指向一个块，这个块里面不放数据块，而是放数据块的位置，这个块我们称为<strong>间接块</strong>。</p>

<p>如果文件再大一些，i_block[13] 会指向一个块，我们可以用<strong>二次间接块</strong>。</p>

<p>你应该能够意识到，这里面有一个非常显著的问题，对于大文件来讲，我们要多次读取硬盘才能找到相应的块，这样访问速度就会比较慢。</p>

<p>为了解决这个问题，ext4 做了一定的改变。它引入了一个新的概念，叫作<strong>Extents</strong>。</p>

<p>比方说，一个文件大小为 128M，如果使用 4k 大小的块进行存储，需要 32k 个块。如果按照 ext2 或者 ext3  那样散着放，数量太大了。但是 Extents 可以用于存放连续的块，也就是说，我们可以把 128M 放在一个 Extents  里面。这样的话，对大文件的读写性能提高了，文件碎片也减少了。</p>

<p>Exents 如何来存储呢？它其实会保存成一棵树。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20210915201325669.png" alt="image-20210915201325669" style="zoom:70%;" /></p>

<p>会存在一个 header 来描述 extends</p>

<p>如果文件不大，inode 里面的 i_block 中，可以放得下一个 ext4_extent_header 和 4 项 ext4_extent。所以这个时候，eh_depth 为 0，也即 inode 里面的就是叶子节点，树高度为 0。</p>

<p>如果文件比较大，4 个 extent 放不下，就要分裂成为一棵树，eh_depth&gt;0 的节点就是索引节点，其中根节点深度最大，在 inode 中。最底层 eh_depth=0 的是叶子节点。</p>

<p>除了根节点，其他的节点都保存在一个块 4k 里面，4k 扣除 ext4_extent_header 的 12 个 byte，剩下的能够放 340 项，每个 extent 最大能表示 128MB 的数据，340 个 extent 会使你的表示的文件达到 42.5GB。这已经非常大了，如果再大，我们可以增加树的深度。</p>

<h3 id="目录项">目录项</h3>

<p>inode 中是没有文件名的，因为 inode 是给系统创建使用，而非给用户使用，文件名需要通过查找该文件所在的目录中的目录项。</p>

<blockquote>
  <p>目录本身也是个文件，也有 inode。inode 里面也是指向一些块。和普通文件不同的是，普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。这些信息我们称为 ext4_dir_entry。<strong>即目录项</strong></p>

  <p>每一项都会保存这个目录的下一级的文件的文件名和对应的 inode，通过这个 inode，就能找到真正的文件。第一项是“.”，表示当前目录，第二项是“…”，表示上一级目录，接下来就是一项一项的文件名和 inode。</p>
</blockquote>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">ext4_dir_entry</span> <span class="p">{</span>
	<span class="n">__le32</span>	<span class="n">inode</span><span class="p">;</span>			<span class="cm">/* Inode number */</span>
	<span class="n">__le16</span>	<span class="n">rec_len</span><span class="p">;</span>		<span class="cm">/* Directory entry length */</span>
	<span class="n">__le16</span>	<span class="n">name_len</span><span class="p">;</span>		<span class="cm">/* Name length */</span>
	<span class="kt">char</span>	<span class="n">name</span><span class="p">[</span><span class="n">EXT4_NAME_LEN</span><span class="p">];</span>	<span class="cm">/* File name */</span>
<span class="p">};</span>
</code></pre></div></div>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212164923097.png" alt="image-20201212164923097" /></p>

<p>有了目录项，通过文件名找文件实体数据块的步骤就是：</p>

<ul>
  <li>在目录中找到文件名所在的目录项</li>
  <li>在目录项中获取 inode 编号</li>
  <li>用 inode 编号作为 inode 数组的索引下标，找到 inode</li>
  <li>从该 inode 中获取数据块的地址，读取数据块</li>
</ul>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212165326475.png" alt="image-20201212165326475" style="zoom:60%;" /></p>

<blockquote>
  <p>但是看上去好像是个死循环？</p>

  <p>inode 需要从 目录项中获取，而目录项又是属于一个 inode….</p>

  <p>解决办法很简单！我们有一个固定的目录项——根目录 ‘/’，创建文件系统后，它的位置是固定的。</p>
</blockquote>

<p>而对于 linux 而言，如果一个目录下面的文件太多的时候，我们想在这个目录下找一个文件，按照列表一个个去找，太慢了，于是我们就添加了hash。</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">dx_entry</span>
<span class="p">{</span>
	<span class="n">__le32</span> <span class="n">hash</span><span class="p">;</span>
	<span class="n">__le32</span> <span class="n">block</span><span class="p">;</span>
<span class="p">};</span>
</code></pre></div></div>

<p>如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20210915202415209.png" alt="image-20210915202415209" /></p>

<h3 id="硬软链接">硬软链接</h3>

<p>ln -s 创建的是软链接，不带 -s 创建的是硬链接。它们有什么区别呢？在文件系统里面是怎么保存的呢？</p>

<p>硬链接与原始文件<strong>共用一个 inode</strong> 的，但是 inode 是不跨文件系统的，每个文件系统都有自己的 inode 列表，因而硬链接是没有办法跨文件系统的。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212171115828.png" alt="image-20201212171115828" /></p>

<p>而软链接不同，软链接相当于重新创建了一个文件。这个文件也有独立的 inode，只不过打开这个文件看里面内容的时候，内容指向另外的一个文件。这就很灵活了。我们可以跨文件系统，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212171155273.png" alt="image-20201212171155273" style="zoom:60%;" /></p>

<h2 id="文件系统布局">文件系统布局</h2>

<blockquote>
  <p>挂载分区的实质是：将该分区文件系统的元信息从硬盘中读出来加载到内存中。</p>
</blockquote>

<p><strong>文件系统是针对分区来进行管理的</strong>，inode 代表文件，因此各个分区都有自己的 inode 数组。inode 数组长度是固定的，等于最大文件数。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212170457697.png" alt="image-20201212170457697" style="zoom:70%;" /></p>

<h3 id="超级块">超级块</h3>

<p>需要有一个数据结构，对整个文件系统的情况进行描述，这个就是**超级块 ** ext4_super_block 。这里面有整个文件系统一共有多少 inode，s_inodes_count；一共有多少块，s_blocks_count_lo，每个块组有多少  inode，s_inodes_per_group，每个块组有多少块，s_blocks_per_group 等。这些都是这类的全局信息。</p>

<p>超级块是文件系统的元信息的”配置文件”，被固定在分区的第二个扇区，通常占用一个扇区的大小。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212171615648.png" alt="image-20201212171615648" /></p>

<blockquote>
  <p>这里面还需要重点说一下，超级块和块组描述符表都是全局信息，而且这些数据很重要。如果这些数据丢失了，整个文件系统都打不开了，这比一个文件的一个块损坏更严重。所以，这两部分我们都需要备份，但是采取不同的策略。</p>

  <p>默认情况下，超级块和块组描述符表都有副本保存在每一个块组里面。</p>
</blockquote>

<h3 id="inode-位图和块位图">inode 位图和块位图</h3>

<p>在文件系统里面，我们专门弄了一个块来保存 inode 的位图。在这 4k 里面，每一位对应一个 inode。如果是 1，表示这个 inode 已经被用了；如果是 0，则表示没被用。同样，我们也弄了一个块保存 block 的位图。</p>

<p>inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。</p>

<p>每个 inode 节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。</p>

<p>查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。</p>

<blockquote>
  <p>　　df -i</p>
</blockquote>

<p>由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。</p>

<p><a href="https://blog.csdn.net/wwwlyj123321/article/details/100298377">linux文件管理（inode、文件描述符表、文件表）</a></p>

<h2 id="文件管理">文件管理</h2>

<h3 id="文件描述符">文件描述符</h3>

<p>文件描述符 fd，描述的是对文件的操作，每打开一个文件就生成一个文件结构。</p>

<blockquote>
  <p>Linux 把所有的“文件结构”组织到一起形成数组统一管理，该数组成为<strong>文件表</strong>。</p>
</blockquote>

<p>在每一个进程的 task_struct 中，有一个指针 files，类型是 files_struct。</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">files_struct</span>		<span class="o">*</span><span class="n">files</span><span class="p">;</span>
</code></pre></div></div>

<p>files_struct 里面最重要的是一个文件描述符列表，每打开一个文件，就会在这个列表中分配一项，下标就是文件描述符。</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">files_struct</span><span class="p">{</span>
	<span class="n">atomic_t</span> <span class="n">count</span><span class="p">;</span> <span class="c1">//引用计数   累加</span>
	<span class="k">struct</span> <span class="n">fdtable</span> <span class="o">*</span><span class="n">fdt</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">fdtable</span> <span class="n">fdtab</span><span class="p">;</span>
	<span class="n">spinlock_t</span> <span class="n">file_lock</span> <span class="n">____cacheline_aligned_in_smp</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">next_fd</span><span class="p">;</span> 
	<span class="k">struct</span> <span class="n">embedded_fd_set</span> <span class="n">close_on_exec_init</span><span class="p">;</span> 
	<span class="k">struct</span> <span class="n">embedded_fd_set</span> <span class="n">open_fds_init</span><span class="p">;</span> 
	<span class="k">struct</span> <span class="n">file</span> <span class="o">*</span> <span class="n">fd_array</span><span class="p">[</span><span class="n">NR_OPEN_DEFAULT</span><span class="p">];</span> <span class="c1">//文件描述符数组</span>
<span class="p">};</span>
</code></pre></div></div>

<p>对于任何一个进程，默认情况下，文件描述符 0 表示 stdin 标准输入，文件描述符 1 表示 stdout 标准输出，文件描述符 2 表示 stderr 标准错误输出。另外，再打开的文件，都会从这个列表中找一个空闲位置分配给它。</p>

<h3 id="文件表">文件表</h3>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">file</span>
<span class="p">{</span>
	<span class="n">mode_t</span> <span class="n">f_mode</span><span class="p">;</span><span class="c1">//表示文件是否可读或可写，FMODE_READ或FMODE_WRITE</span>
	<span class="n">dev_</span> <span class="n">t</span>  <span class="n">f_rdev</span> <span class="p">;</span><span class="c1">// 用于/dev/tty</span>
	<span class="kt">off_t</span>  <span class="n">f_ops</span><span class="p">;</span><span class="c1">//当前文件位移</span>
	<span class="kt">unsigned</span> <span class="kt">short</span> <span class="n">f_flags</span><span class="p">;</span><span class="c1">//文件标志，O_RDONLY,O_NONBLOCK和O_SYNC</span>
	<span class="kt">unsigned</span> <span class="kt">short</span> <span class="n">f_count</span><span class="p">;</span><span class="c1">//打开的文件数目</span>
	<span class="kt">unsigned</span> <span class="kt">short</span> <span class="n">f_reada</span><span class="p">;</span>
	<span class="k">struct</span> <span class="nc">inode</span> <span class="o">*</span><span class="n">f_inode</span><span class="p">;</span><span class="c1">//指向inode的结构指针</span>
	<span class="k">struct</span> <span class="nc">file_operations</span> <span class="o">*</span><span class="n">f_op</span><span class="p">;</span><span class="c1">//文件操作索引指针</span>
<span class="p">}</span>
</code></pre></div></div>

<blockquote>
  <p>内核为所有打开文件维护一张文件表项，每个文件表项包含内容可以由以上结构体看出，其中比较重要的内容有：</p>

  <p>a. 文件状态(读 写 添写 同步 非阻塞等)</p>

  <p>b. 当前文件偏移量</p>

  <p>c. 指向该文件i节点(i节点)的指针</p>

  <p>d. 指向该文件操作的指针（file_operations ）</p>
</blockquote>

<p>文件描述符列表的每一项都是一个指向 struct file 的指针，也就是说，每打开一个文件，都会有一个 struct file 对应。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212191341314.png" alt="image-20201212191341314" /></p>

<p>在 PCB 的文件描述符数组中，找到文件结构在文件表的下标，文件表表项中存放 inode 号。</p>

<ul>
  <li>在应用层，进程在进行文件读写操作时，可通过系统调用如 sys_open、sys_read、sys_write 等。</li>
  <li>在内核，每个进程都需要为打开的文件，维护一定的数据结构。</li>
  <li>在内核，整个系统打开的文件，也需要维护一定的数据结构。</li>
  <li>Linux 可以支持多达数十种不同的文件系统。它们的实现各不相同，因此 Linux  内核向用户空间提供了虚拟文件系统这个统一的接口，来对文件系统进行操作。它提供了常见的文件系统对象模型，例如 inode、directory  entry、mount 等，以及操作这些对象的方法，例如 inode operations、directory operations、file  operations 等。</li>
  <li>然后就是对接的是真正的文件系统，例如我们上节讲的 ext4 文件系统。</li>
  <li>为了读写 ext4 文件系统，要通过块设备 I/O 层，也即 BIO 层。这是文件系统层和块设备驱动的接口。</li>
  <li>为了加快块设备的读写效率，我们还有一个缓存层。</li>
  <li>最下层是块设备驱动程序。</li>
</ul>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/index.jpeg" alt="index" style="zoom:30%;" /></p>

<h2 id="open-打开文件时会发生什么">open 打开文件时会发生什么</h2>

<blockquote>
  <p>表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。</p>
</blockquote>

<p>使用ls -i命令，可以看到文件名对应的inode号码：</p>

<p>当使用系统调用 open 打开一个文件时，操作系统会创建一些数据结构来表示这个被打开的文件。在进程中，我们会为这个打开的文件分配一个文件描述符 fd（File Descriptor）。</p>

<h3 id="调用链大致">调用链大致</h3>

<p>` do_sys_open-&gt;  do_filp_open-&gt;path_openat-&gt;do_last-&gt;lookup_open。`</p>

<p>这个调用链的逻辑是，要打开一个文件，先要根据路径找到文件夹。如果发现文件夹下面没有这个文件，同时又设置了 O_CREAT，就说明我们要在这个文件夹下面创建一个文件，那我们就需要一个新的 inode。</p>

<blockquote>
  <p>搜索文件的原理是路径解析，也就是把文件路径按照 ‘/’ 进行分割，每找到一项，就到目录中去找相应的目录项进行 filename对比，要是成了，继续下一个目录，直到路径解析完成，或者中间目录对比失败。</p>
</blockquote>

<p>想要创建新的 inode，我们就要调用 dir_inode，也就是文件夹的 inode 的 create 函数。它的具体定义是这样的：</p>

<p>这里面一个重要的逻辑就是，从文件系统里面读取 inode 位图，然后找到下一个为 0 的 inode，就是空闲的 inode。</p>

<blockquote>
  <p>对于 block 位图，在写入文件的时候，也会有这个过程。</p>
</blockquote>

<p>数据块的位图是放在一个块里面的，共 4k。每位表示一个数据块，共可以表示 4∗1024∗8=215 个数据块。如果每个数据块也是按默认的 4K，最大可以表示空间为 215∗4∗1024=227 个 byte，也就是 128M。</p>

<h3 id="深入描述一下">深入描述一下：</h3>

<p>要打开一个文件，首先要通过 get_unused_fd_flags 得到一个没有用的文件描述符。</p>

<p>在每一个进程的 task_struct 中，有一个指针 files，类型是 files_struct。</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">files_struct</span>	<span class="o">*</span><span class="n">files</span><span class="p">;</span>
</code></pre></div></div>

<p>files_struct 里面最重要的是一个文件描述符列表，每打开一个文件，就会在这个列表中分配一项，下标就是文件描述符。</p>

<p>文件描述符列表的每一项都是一个指向 struct file 的指针，也就是说，每打开一个文件，都会有一个 struct file 对应。</p>

<p>do_sys_open 中调用 do_filp_open，就是创建这个 struct file 结构，然后 fd_install(fd, f) 是将文件描述符和这个结构关联起来。</p>

<p>接下来就调用 path_openat，主要做了以下几件事情：</p>

<ul>
  <li>get_empty_filp 生成一个 struct file 结构；</li>
  <li>path_init 初始化 nameidata，准备开始节点路径查找；</li>
  <li>link_path_walk 对于路径名逐层进行节点路径查找，这里面有一个大的循环，用“/”分隔逐层处理；</li>
  <li>do_last 获取文件对应的 inode 对象，并且初始化 file 对象。</li>
</ul>

<p>在这里面，我们需要先查找文件路径最后一部分对应的 dentry。怎么找？</p>

<p>首先看缓存…(此处省略一万字)</p>

<p>如果缓存中没有找到，就需要真的到文件系统里面去找了，lookup_open 会创建一个新的 dentry，并且调用上一级目录的 Inode 的  inode_operations 的 lookup 函数，对于 ext4 来讲，调用的是  ext4_lookup，去找 inode。</p>

<blockquote>
  <p>搜索文件的原理是路径解析，也就是把文件路径按照 ‘/’ 进行分割，每找到一项，就到目录中去找相应的目录项进行 filename对比，要是成了，继续下一个目录，直到路径解析完成，或者中间目录对比失败。</p>
</blockquote>

<p>调用 vfs_open 真正打开文件。终要做的一件事情是，调用 f_op-&gt;open，也就是调用 ext4_file_open。另外一件重要的事情是将打开文件的所有信息，填写到 struct file 这个结构里面。</p>

<h2 id="write--read-文件发生什么">write &amp; read 文件发生什么</h2>

<p>对于 read 来讲，里面调用 vfs_read-&gt;__vfs_read。对于 write 来讲，里面调用 vfs_write-&gt;__vfs_write。</p>

<p>每一个打开的文件，都有一个 struct file 结构。这里面有一个 struct file_operations  f_op，用于定义对这个文件做的操作。__vfs_read 会调用相应文件系统的 file_operations 里面的 read  操作，__vfs_write 会调用相应文件系统 file_operations 里的 write 操作。</p>

<p><img src="/assets/blog_image/2020-12-12-FileSystem-Thinking/image-20201212191341314.png" alt="image-20201212191341314" /></p>

<p>缓存其实就是内存中的一块空间。因为内存比硬盘快的多，Linux 为了改进性能，有时候会选择不直接操作硬盘，而是将读写都在内存中，然后批量读取或者写入硬盘。一旦能够命中内存，读写效率就会大幅度提高。</p>

<p>因此，根据是否使用内存做缓存，我们可以把文件的 I/O 操作分为两种类型。</p>

<p>第一种类型是<strong>缓存 I/O</strong>。大多数文件系统的默认 I/O 操作都是缓存  I/O。对于读操作来讲，操作系统会先检查，内核的缓冲区有没有需要的数据。如果已经缓存了，那就直接从缓存中返回；否则从磁盘中读取，然后缓存在操作系统的缓存中。对于写操作来讲，操作系统会先将数据从用户空间复制到内核空间的缓存中。这时对用户程序来说，写操作就已经完成。<strong>至于什么时候再写到磁盘中由操作系统决定，除非显式地调用了 sync 同步命令。</strong></p>

<p>第二种类型是<strong>直接 IO</strong>，就是应用程序直接访问磁盘数据，而不经过内核缓冲区，从而减少了在内核缓存和用户程序之间数据复制。</p>

<h2 id="总结">总结</h2>

<p>在系统调用层我们需要仔细学习 read 和 write。在 VFS 层调用的是 vfs_read 和 vfs_write 并且调用  file_operation。在 ext4 层调用的是 ext4_file_read_iter 和 ext4_file_write_iter。</p>

<p>接下来就是分叉。需要知道缓存 I/O 和直接 I/O。直接 I/O 读写的流程是一样的，调用 ext4_direct_IO，再往下就调用块设备层了。缓存 I/O  读写的流程不一样。对于读，从块设备读取到缓存中，然后从缓存中拷贝到用户态。对于写，从用户态拷贝到缓存，<strong>设置缓存页为脏</strong>，然后启动一个线程写入块设备。</p>]]></content><author><name></name></author><category term="Linux" /></entry><entry><title type="html">内存管理（三）虚拟内存与物理内存的映射关系 &amp;amp; pagefault</title><link href="http://localhost:4000/linux/2020/12/05/Memory-03.html" rel="alternate" type="text/html" title="内存管理（三）虚拟内存与物理内存的映射关系 &amp;amp; pagefault" /><published>2020-12-05T16:19:51+08:00</published><updated>2020-12-05T16:19:51+08:00</updated><id>http://localhost:4000/linux/2020/12/05/Memory-03</id><content type="html" xml:base="http://localhost:4000/linux/2020/12/05/Memory-03.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#内存映射" id="markdown-toc-内存映射">内存映射</a>    <ul>
      <li><a href="#用户态内存映射" id="markdown-toc-用户态内存映射">用户态内存映射</a></li>
      <li><a href="#用户态缺页异常" id="markdown-toc-用户态缺页异常">用户态缺页异常</a>        <ul>
          <li><a href="#具体过程如下" id="markdown-toc-具体过程如下">具体过程如下</a></li>
          <li><a href="#如何查看进程发生缺页中断的次数" id="markdown-toc-如何查看进程发生缺页中断的次数">如何查看进程发生缺页中断的次数？</a></li>
        </ul>
      </li>
      <li><a href="#tlb" id="markdown-toc-tlb">TLB</a></li>
      <li><a href="#内核态内存映射" id="markdown-toc-内核态内存映射">内核态内存映射</a></li>
      <li><a href="#内核态缺页异常" id="markdown-toc-内核态缺页异常">内核态缺页异常</a></li>
    </ul>
  </li>
  <li><a href="#内存管理总结" id="markdown-toc-内存管理总结">内存管理总结</a>    <ul>
      <li><a href="#物理地址线性地址虚拟地址逻辑地址" id="markdown-toc-物理地址线性地址虚拟地址逻辑地址">物理地址/线性地址/虚拟地址/逻辑地址</a></li>
    </ul>
  </li>
</ul>

<h1 id="内存映射">内存映射</h1>

<p><a href="https://blog.csdn.net/m0_37962600/article/details/81448553?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control">详解缺页中断—–缺页中断处理（内核、用户）</a></p>

<p>我们既看了虚拟内存空间如何组织的，也看了物理页面如何管理的。现在我们需要一些数据结构，将二者关联起来。</p>

<h2 id="用户态内存映射">用户态内存映射</h2>

<p>无论是内核线程还是用户进程，对于内核来说，无非都是 task_struct 这个数据结构的一个实例而已，task_struct 被称为进程描述符（process descriptor),因为它记录了这个进程所有的context。其中有一个被称为 ‘内存描述符’ （memory descriptor)的数据结构  mm_struct，抽象并描述了Linux视角下管理进程地址空间的所有信息。 每一个进程都有一个列表 vm_area_struct，指向虚拟地址空间的不同的内存块，这个变量的名字叫<strong>mmap</strong>。</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">mm_struct</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">mmap</span><span class="p">;</span>		<span class="cm">/* list of VMAs */</span>
<span class="p">......</span>

<span class="p">}</span>
</code></pre></div></div>

<p><img src="/assets/blog_image/2020-12-05-HuSharp-Memory-03/image-20201207172335213.png" alt="image-20201207172335213" /></p>

<p>1、brk 是将数据段(.data)的最高地址指针_edata往高地址推；</p>

<p>2、mmap 是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。</p>

<p>​    这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。</p>

<p>内存管理并不直接分配物理内存，因为物理内存相对于虚拟地址空间太宝贵了，只有等你真正用的那一刻才会开始分配。</p>

<p>一旦开始访问虚拟内存的某个地址，如果我们发现，并没有对应的物理页，那就触发缺页中断，调用 do_page_fault。</p>

<p>1）通过mm是否存在判断是否是内核线程，对于内核线程，进程描述符的mm总为NULL，一旦成立，说明是在内核态中发生的异常，跳到no_context</p>

<h2 id="用户态缺页异常">用户态缺页异常</h2>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">​</span>           <span class="k">if</span> <span class="p">(</span><span class="n">in_atomic</span><span class="p">()</span> <span class="o">||</span> <span class="o">!</span><span class="n">mm</span><span class="p">)</span>
<span class="err">​</span>                <span class="k">goto</span> <span class="n">no_context</span><span class="p">;</span>
</code></pre></div></div>

<p>在 __do_page_fault 里面，先要判断缺页中断是否发生在内核。如果发生在内核则调用  vmalloc_fault，这就和咱们前面学过的虚拟内存的布局对应上了。在内核里面，vmalloc  区域需要内核页表映射到物理页。咱们这里把内核的这部分放放，接着看用户空间的部分。</p>

<p>接下来在用户空间里面，找到你访问的那个地址所在的区域 vm_area_struct，然后调用 handle_mm_fault 来映射这个区域。</p>

<blockquote>
  <p>当一个进程发生缺页中断的时候，进程会陷入内核态，执行以下操作：</p>

  <ol>
    <li>检查要访问的虚拟地址是否合法</li>
    <li>查找/分配一个物理页</li>
    <li>填充物理页内容（读取磁盘，或者直接置0，或者啥也不干）</li>
    <li>建立映射关系（虚拟地址到物理地址）
 重新执行发生缺页中断的那条指令
 如果第3步，需要读取磁盘，那么这次缺页中断就是majflt，否则就是minflt。</li>
  </ol>
</blockquote>

<p>每个进程都有独立的地址空间，为了这个进程独立完成映射，每个进程都有独立的进程页表，32 位 就位于 cr3</p>

<h3 id="具体过程如下">具体过程如下</h3>

<p>首先从CPU的控制寄存器CR2中读出出错的地址address，然后调用find_vma(),在进程的虚拟地址空间中找出结束地址大于address的第一个区间，如果找不到的话，则说明中断是由地址越界引起的，转到bad_area执行相关错误处理；</p>

<p>确定并非地址越界后，控制转向标号good_area。在这里，代码首先对页面进行例行权限检查，比如当前的操作是否违反该页面的Read,Write,Exec权限等。如果通过检查，则进入虚拟管理例程handle_mm_fault().否则，将与地址越界一样，转到bad_area继续处理。</p>

<p>handle_mm_fault()用于实现页面分配与交换，它分为两个步骤：首先，如果页表不存在或被交换出，则要首先分配页面给页表；然后才真正实施页面的分配，并在页表上做记录。具体如何分配这个页框是通过调用handle_pte_fault()完成的。</p>

<p>handle_pte_fault()函数根据页表项pte所描述的物理页框是否在物理内存中，分为两大类：</p>

<p>（1）请求调页：被访问的页框不在主存中，那么此时必须分配一个页框，分为线性映射、非线性映射、swap情况下映射</p>

<p>（2）写时复制：被访问的页存在，但是该页是只读的，内核需要对该页进行写操作，此时内核将这个已存在的只读页中的数据复制到一个新的页框中</p>

<p>handle_pte_fault()调用pte_non()检查表项是否为空，即全为0；如果为空就说明映射尚未建立，此时调用do_no_page()来建立内存页面与交换文件的映射；反之，如果表项非空，说明页面已经映射，只要调用do_swap_page()将其换入内存即可；</p>

<h3 id="如何查看进程发生缺页中断的次数">如何查看进程发生缺页中断的次数？</h3>

<pre><code class="language-assembly">用ps -o majflt,minflt -C program命令查看。
majflt 代表 major fault，中文名叫大错误，minflt 代表 minor fault，中文名叫小错误。
</code></pre>

<p>这两个数值表示一个进程自启动以来所发生的缺页中断的次数。</p>

<p><strong>发生缺页中断后，执行了那些操作？</strong></p>

<p>当一个进程发生缺页中断的时候，进程会陷入内核态，执行以下操作：</p>

<ol>
  <li>检查要访问的虚拟地址是否合法</li>
  <li>查找/分配一个物理页</li>
  <li>填充物理页内容（读取磁盘，或者直接置0，或者啥也不干）</li>
  <li>建立映射关系（虚拟地址到物理地址）
 重新执行发生缺页中断的那条指令
 如果第3步，需要读取磁盘，那么这次缺页中断就是 majflt，否则就是 minflt。</li>
</ol>

<h2 id="tlb">TLB</h2>

<p>为了提高映射速度，我们引入了<strong>TLB</strong>（Translation Lookaside Buffer），我们经常称为<strong>快表</strong>，专门用来做地址映射的硬件设备。它不在内存中，可存储的数据比较少，但是比内存要快。所以，我们可以想象，TLB 就是页表的 Cache，其中存储了当前最可能被访问到的页表项，其内容是部分页表项的一个副本。</p>

<p>有了 TLB 之后，地址映射的过程就像图中画的。我们先查块表，块表中有映射关系，然后直接转换为物理地址。如果在 TLB 查不到映射关系时，才会到内存中查询页表。</p>

<h2 id="内核态内存映射">内核态内存映射</h2>

<p>在系统初始化的时候，我们就创建内核页表</p>

<p><img src="/assets/blog_image/2020-12-05-HuSharp-Memory-03/image-20201207182152880.png" alt="image-20201207182152880" /></p>

<h2 id="内核态缺页异常">内核态缺页异常</h2>

<p>1）通过mm是否存在判断是否是内核线程，对于内核线程，进程描述符的mm总为NULL，一旦成立，说明是在内核态中发生的异常，跳到no_context</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>           <span class="k">if</span> <span class="p">(</span><span class="n">in_atomic</span><span class="p">()</span> <span class="o">||</span> <span class="o">!</span><span class="n">mm</span><span class="p">)</span>
                <span class="k">goto</span> <span class="n">no_context</span><span class="p">;</span>
</code></pre></div></div>

<p>如果当前执行流程在内核态，不论是在临界区还是内核进程本身（内核的mm为NULL），说明在内核态出了问题，跳到标号no_context进入内核态异常处理，由函数_do_kernel_fault完成；</p>

<p>2）_do_kernel_fault 这个函数首先尽可能的设法解决这个异常，通过查找异常表中和目前的异常对应的解决办法并调用执行；如果无法通过异常表解决，那么内核就要在打印其页表等内容后退出；</p>

<h1 id="内存管理总结">内存管理总结</h1>

<p>物理内存根据 NUMA 架构分节点。每个节点里面再分区域。每个区域里面再分页。</p>

<p>物理页面通过伙伴系统进行分配。分配的物理页面要变成虚拟地址让上层可以访问，kswapd 可以根据物理页面的使用情况对页面进行换入换出。</p>

<p>对于内存的分配需求，可能来自内核态，也可能来自用户态。</p>

<ul>
  <li>
    <p>对于内核态，对于 kmem_cache 以及 kmalloc 分配小内存，则使用 <strong>Slab</strong> 分配器，将伙伴系统分配出来的大块内存切成一小块一小块进行分配。</p>

    <p>vmalloc 分配不连续物理页的时候，直接使用伙伴系统，分配后转换为虚拟地址，访问的时候需要通过内核页表进行映射。</p>

    <p>kmem_cache 和 kmalloc 的部分不会被换出，因为用这两个函数分配的内存多用于保持内核关键的数据结构。内核态中 vmalloc 分配的部分会被换出，因而当访问的时候，发现不在，就会调用 do_page_fault。</p>
  </li>
  <li>
    <p>对于用户态的内存分配，或者直接调用 mmap 系统调用分配，或者调用 malloc。调用 malloc 的时候，如果分配小的内存，就用 <strong>sys_brk</strong>  系统调用；如果分配大的内存，还是用 <strong>sys_mmap</strong> 系统调用。正常情况下，用户态的内存都是可以换出的，因而一旦发现内存中不存在，就会调用  do_page_fault。</p>

    <p>vm_area_struct 是描述进程地址空间的基本管理单元，对于一个进程来说往往需要多个内存区域来描述它的虚拟空间，如何关联这些不同的内存区域呢？大家可能都会想到使用链表，的确vm_area_struct 结构确实是以链表形式链接，不过为了方便查找，内核又以红黑树（以前的内核使用平衡树）的形式组织内存区域，以便降低搜索耗时。并存的两种组织形式，并非冗余：链表用于需要遍历全部节点的时候用，而红黑树适用于在地址空间中定位特定内存区域的时候。内核为了内存区域上的各种不同操作都能获得高性能，所以同时使用了这两种数据结构。</p>
  </li>
</ul>

<p><img src="/assets/blog_image/2020-12-05-HuSharp-Memory-03/image-20201207174552644.png" alt="image-20201207174552644" /></p>

<ul>
  <li>
    <p>在 __do_page_fault 里面，先要判断缺页中断是否发生在内核。</p>

    <p>如果发生在<strong>内核</strong>则调用 vmalloc_fault</p>
  </li>
</ul>

<h2 id="物理地址线性地址虚拟地址逻辑地址">物理地址/线性地址/虚拟地址/逻辑地址</h2>

<p>1）实模式下，”段基址+段内偏移地址”经过段部件的处理，直接输出的就是物理地址，CPU可以直接用此地址访问内存。</p>

<p>2）保护模式下，”段基址+段内偏移地址”经段部件处理后为线性地址。（但此处的段基址不再是真正的地址，而是一个选择子，本质上是个索引，类似于数组下标，通过这个索引便能在GDT中找到相应的段描述符。段描述符记录了该段的起始、大小等信息，这样便得到了段基址。）若没有开启地址分页功能，此线性地址就被当作物理地址来用，可直接访问内存。</p>

<p>3）保护模式+分页机制，若开启了分页功能，线性地址则称为虚拟地址（虚拟地址、线性地址在分页机制下都是一回事）。虚拟地址要经过CPU页部件转换成具体的物理地址，这样CPU才能将其送上地址总线取访问内存。</p>

<p>逻辑地址，无论是在实模式或保护模式下，段内偏移地址又称为有效地址，也称为逻辑地址，这是程序员可见的地址。最终的地址是由段基址和段内偏移地址组合而成。实模式下，段基址在对应的段寄存器中(cs ds es fs gs)；保护模式下，段基址在段选择子寄存器指向的段描述符中。所以，只要给出段内偏移地址就行了，再加上对应的段基址即可。</p>]]></content><author><name></name></author><category term="Linux" /></entry><entry><title type="html">内存管理（二）物理内存管理</title><link href="http://localhost:4000/linux/2020/12/03/Memory-02.html" rel="alternate" type="text/html" title="内存管理（二）物理内存管理" /><published>2020-12-03T13:04:36+08:00</published><updated>2020-12-03T13:04:36+08:00</updated><id>http://localhost:4000/linux/2020/12/03/Memory-02</id><content type="html" xml:base="http://localhost:4000/linux/2020/12/03/Memory-02.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#内存管理" id="markdown-toc-内存管理">内存管理</a>    <ul>
      <li><a href="#husharpos-中的内存管理" id="markdown-toc-husharpos-中的内存管理">HuSharpOS 中的内存管理</a></li>
      <li><a href="#malloc-和-free" id="markdown-toc-malloc-和-free">malloc 和 free</a></li>
    </ul>
  </li>
  <li><a href="#linux-中的内存管理" id="markdown-toc-linux-中的内存管理">Linux 中的内存管理</a>    <ul>
      <li><a href="#物理内存的组织方式" id="markdown-toc-物理内存的组织方式">物理内存的组织方式</a>        <ul>
          <li><a href="#1发展历程" id="markdown-toc-1发展历程">1、发展历程</a></li>
          <li><a href="#2物理内存的组织" id="markdown-toc-2物理内存的组织">2、物理内存的组织</a>            <ul>
              <li><a href="#节点" id="markdown-toc-节点">节点</a></li>
              <li><a href="#区域" id="markdown-toc-区域">区域</a></li>
              <li><a href="#冷热页" id="markdown-toc-冷热页">冷热页</a></li>
              <li><a href="#页" id="markdown-toc-页">页</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#页的分配" id="markdown-toc-页的分配">页的分配</a></li>
      <li><a href="#1用户态的分配" id="markdown-toc-1用户态的分配">1、用户态的分配</a></li>
      <li><a href="#2内核态的分配" id="markdown-toc-2内核态的分配">2、内核态的分配</a>        <ul>
          <li><a href="#伙伴算法" id="markdown-toc-伙伴算法">伙伴算法</a></li>
          <li><a href="#slab算法" id="markdown-toc-slab算法">SLAB算法</a></li>
          <li><a href="#内核非连续内存分配vmalloc" id="markdown-toc-内核非连续内存分配vmalloc">内核非连续内存分配（Vmalloc）</a>            <ul>
              <li><a href="#分片" id="markdown-toc-分片">分片</a></li>
              <li><a href="#vmalloc" id="markdown-toc-vmalloc">vmalloc</a></li>
            </ul>
          </li>
          <li><a href="#总结-kmalloc-和-vmalloc" id="markdown-toc-总结-kmalloc-和-vmalloc">总结 kmalloc 和 vmalloc</a></li>
        </ul>
      </li>
      <li><a href="#页面换出" id="markdown-toc-页面换出">页面换出</a>        <ul>
          <li><a href="#相关页面置换算法" id="markdown-toc-相关页面置换算法">相关页面置换算法</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>接上一篇 Blog</p>

<p>**cat /proc/<pid>/maps**  **查看某个进程占用的内存区域**</pid></p>

<h1 id="内存管理">内存管理</h1>

<h2 id="husharpos-中的内存管理">HuSharpOS 中的内存管理</h2>

<p><img src="/assets/blog_image/2020-12-03-HuSharp-Memory-02/image-20201206185312397.png" alt="image-20201206185312397" /></p>

<p>这里先从指定位置处读取LOADER写入的物理内存大小。本项目中，物理内存的配置为32M(bochs配置文件bochsrc.cfg中”megs:  32”)，减去低端的 1MB 、减去LOADER开启分页机制时创建 PDT 和 PT 占用的1MB（紧邻低端1MB之上），还有30MB，内核和用户内存池各占15M。所以，内核物理内存池的起始地址为 0x20_0000（2MB）。</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">kernel_pool</span><span class="p">.</span><span class="n">phy_addr_begin</span> <span class="o">=</span> <span class="mi">2</span><span class="n">MB</span><span class="p">;</span>     <span class="c1">// 起始地址</span>
    <span class="n">user_pool</span><span class="p">.</span><span class="n">phy_addr_begin</span> <span class="o">=</span> <span class="mi">2</span><span class="n">MB</span><span class="o">+</span><span class="mi">15</span><span class="n">MB</span><span class="p">;</span>
</code></pre></div></div>

<p>4GB 虚拟地址空间中，高 1GB 为内核空间，其中 1GB 之上的 1MB 虚拟空间已在LOADER阶段映射到物理内存的低端1MB。所以，内核虚拟地址池的起始地址为0xc010_0000（1GB+1MB）。</p>

<p>以页(4KB)为单位的内存管理，采用 bitmap (位图) 技术。本项目中，自定义内核物理内存的 bitmap 存放于0xc009_a000 ，自定义内核主线程栈顶为0xc009_f000、内核主线程PCB为0xc009_a000。</p>

<p>所以，本系统最大支持 4 个页框的位图（一个页框大小的位图可表示 128M 内存， 4 个页框即 512M ,虽说是远远大于分配内存，但是任性～），用于内核/用户物理内存池bitmap、内核虚拟地址池bitmap。</p>

<p><img src="/assets/blog_image/2020-12-03-HuSharp-Memory-02/image-20201206185414554.png" alt="img-20201206185414554" style="zoom:75%;" /></p>

<h2 id="malloc-和-free">malloc 和 free</h2>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/* 内存块描述符信息 */</span>
<span class="k">struct</span> <span class="n">mem_block_desc</span><span class="p">{</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">block_size</span><span class="p">;</span>        <span class="c1">// 内存块大小</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">blocks_per_arena</span><span class="p">;</span>  <span class="c1">// 每个arena可容纳此mem_blcok的数量</span>
    <span class="k">struct</span> <span class="n">list</span> <span class="n">free_list</span><span class="p">;</span>          <span class="c1">// 空闲内存块mem_block链表</span>
<span class="p">};</span>

<span class="c1">// 内存块</span>
<span class="k">struct</span> <span class="n">mem_block</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">list_elem</span> <span class="n">free_elem</span><span class="p">;</span>
<span class="p">};</span>

<span class="c1">// arena 的元信息  12个字节</span>
<span class="k">struct</span> <span class="n">arena</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">mem_block_desc</span><span class="o">*</span> <span class="n">desc</span><span class="p">;</span><span class="c1">// arena 关联的指针</span>
    <span class="c1">// large为 ture 时,cnt表示的是页框数。</span>
    <span class="c1">// 否则cnt表示空闲mem_block数量 </span>
    <span class="kt">uint32_t</span> <span class="n">cnt</span><span class="p">;</span>
    <span class="n">bool</span> <span class="n">large</span><span class="p">;</span>
<span class="p">};</span>

<span class="c1">// 内核内存块描述符数组</span>
<span class="c1">// 本系统支持7种规格的内存块: 16 32 64 128 256 512 1024字节</span>
<span class="k">struct</span> <span class="n">mem_block_desc</span> <span class="n">k_block_descs</span><span class="p">[</span><span class="mi">7</span><span class="p">];</span> 
</code></pre></div></div>

<p>基于bitmap，实现了以页为单位的内存管理。 虚拟地址是连续的，但物理地址可能连续，也可能不连续。一次性申请count个虚拟页之后，再依次为每一个虚拟页申请物理页，并在页表中依次添加映射关联。</p>

<p>在以页(4KB)为单位的内存管理基础上，实现小内存块的管理，可满足任意内存大小的分配与释放(malloc/free)。这里采用arena模型。</p>

<p><img src="/assets/blog_image/2020-12-03-HuSharp-Memory-02/image-20201206190645564.png" alt="img-20201206190645564" style="zoom:65%;" /></p>

<p>类似 Linux 的伙伴系统</p>

<h1 id="linux-中的内存管理">Linux 中的内存管理</h1>

<p><a href="https://blog.csdn.net/goodluckwhh/article/details/9970845">linux内核内存管理学习之一（基本概念，分页及初始化）</a></p>

<h2 id="物理内存的组织方式">物理内存的组织方式</h2>

<p><a href="https://blog.csdn.net/yusiguyuan/article/details/12045255"><strong>物理内存分配</strong></a></p>

<h3 id="1发展历程">1、发展历程</h3>

<p><strong>1、平坦内存模型：Flat Memory Model</strong></p>

<p>​我们可以从 0 开始对物理页编号，这样每个物理页都会有个页号。由于物理地址是连续的，页也是连续的，每个页大小也是一样的。因而对于任何一个地址，只要直接除一下每页的大小，很容易直接算出在哪一页。<strong>每个页有一个结构 struct page 表示</strong>，这个结构也是放在一个数组里面，这样根据页号，很容易通过下标找到相应的 struct page 结构。</p>

<p><strong>2、对称多处理器：SMP  Symmetric multiprocessing</strong></p>

<p>当刚出现多处理器时，仍然采用所有的 CPU 访问内存都要过总线，而且距离都是一样的。</p>

<p><img src="/assets/blog_image/2020-12-03-HuSharp-Memory-02/image-20201207100449725.png" alt="image-20201207100449725" /></p>

<p><strong>3、非一致内存访问：NUMA  Non-uniform memory access</strong></p>

<p>在这种模式下，内存不是一整块。每个 CPU 都有自己的本地内存，CPU 访问本地内存不用过总线，因而速度要快很多，每个 CPU  和内存在一起，称为一个 NUMA 节点。但是，在本地内存不足的情况下，每个 CPU 都可以去另外的 NUMA  节点申请内存，这个时候访问延时就会比较长。</p>

<h3 id="2物理内存的组织">2、物理内存的组织</h3>

<h4 id="节点">节点</h4>

<p>typedef struct pglist_data</p>

<p><strong>NUMA 节点：</strong>每个 CPU 都有自己的本地内存，CPU 访问本地内存不用过总线，因而速度要快很多，每个 CPU 和内存在一起，称为一个 NUMA 节点。</p>

<p>但是，在本地内存不足的情况下，每个 CPU 都可以去另外的 NUMA 节点申请内存，这个时候访问延时就会比较长。</p>

<p>内存被分成了多个节点，每个节点再被分成一个一个的页面。由于页需要全局唯一定位，页还是需要有全局唯一的页号的。但是由于物理内存不是连起来的了，页号也就不再连续了。于是内存模型就变成了非连续内存模型，管理起来就复杂一些。</p>

<p>typedef struct pglist_data pg_data_t，它里面有以下的成员变量：</p>

<ul>
  <li>每一个节点都有自己的 ID：node_id；</li>
  <li>node_mem_map 就是这个节点的 struct page 数组，用于描述这个节点里面的所有的页；</li>
  <li>node_start_pfn 是这个节点的起始页号；</li>
  <li>node_spanned_pages 是这个节点中包含不连续的物理内存地址的页面数；</li>
  <li>node_present_pages 是真正可用的物理页面的数目。</li>
  <li><code class="language-plaintext highlighter-rouge">struct zonelist node_zonelists[MAX_ZONELISTS];</code>    每一个节点分成一个个区域 zone，放在数组 node_zones 里面。这个数组的大小为 MAX_NR_ZONES。</li>
</ul>

<blockquote>
  <p>DMA（Direct Memory Access，直接内存存取）的内存。</p>

  <p>DMA  是这样一种机制：要把外设的数据读入内存或把内存的数据传送到外设，原来都要通过 CPU 控制完成，但是这会占用 CPU，影响 CPU  处理其他事情，所以有了 DMA 模式。CPU 只需向 DMA 控制器下达指令，让 DMA 控制器来处理数据的传送，数据传送完毕再把信息反馈给  CPU，这样就可以解放 CPU。</p>
</blockquote>

<h4 id="区域">区域</h4>

<p>struct zone</p>

<p>到这里，我们把内存分成了节点，把节点分成了区域。</p>

<h4 id="冷热页">冷热页</h4>

<p>per_cpu_pageset 用于区分冷热页。什么叫冷热页呢？咱们讲 x86 体系结构的时候讲过，为了让 CPU 快速访问段描述符，在  CPU 里面有段描述符缓存。CPU 访问这个缓存的速度比内存快得多。同样对于页面来讲，也是这样的。<strong>如果一个页被加载到 CPU  高速缓存里面，这就是一个热页</strong>（Hot Page），CPU 读起来速度会快很多，如果没有就是冷页（Cold Page）。由于每个 CPU  都有自己的高速缓存，因而 per_cpu_pageset 也是每个 CPU 一个。</p>

<h4 id="页">页</h4>

<p>struct page</p>

<p>第一种模式，要用就用<strong>一整页</strong>。这一整页的内存，或者直接和虚拟地址空间建立映射关系，我们把这种称为匿名页（Anonymous  Page）。或者用于关联一个文件，然后再和虚拟地址空间建立映射关系，这样的文件，我们称为内存映射文件（Memory-mapped File）。</p>

<p>第二种模式，<strong>仅需分配小块内存</strong>。有时候，我们不需要一下子分配这么多的内存，例如分配一个 task_struct 结构，只需要分配小块的内存，去存储这个进程描述结构的对象。为了满足对这种小内存块的需要，Linux 系统采用了一种被称为<strong>slab allocator</strong>的技术，用于分配称为 slab 的一小块内存。它的基本原理是从内存管理模块申请<strong>一整块页，然后划分成多个小块的存储池</strong>，用复杂的队列来维护这些小块的状态（状态包括：被分配了 / 被放回池子 / 应该被回收）。</p>

<p><img src="/assets/blog_image/2020-12-03-HuSharp-Memory-02/image-20201207171224672.png" alt="image-20201207171224672" /></p>

<h2 id="页的分配">页的分配</h2>

<p><img src="/assets/blog_image/2020-12-03-HuSharp-Memory-02/image-20201207095515857.png" alt="image-20201207095515857" /></p>

<h2 id="1用户态的分配">1、用户态的分配</h2>

<p><a href="https://blog.csdn.net/yusiguyuan/article/details/39496057">进程分配内存的两种方式–brk() 和mmap() </a>  详情见此 Blog</p>

<p>进程分配内存有两种方式，分别由两个系统调用完成：<strong>brk和mmap（不考虑共享内存）。</strong></p>

<p>1、brk是将数据段(.data)的最高地址指针_edata往高地址推；</p>

<p>2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。</p>

<p>​    这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。</p>

<h2 id="2内核态的分配">2、内核态的分配</h2>

<h3 id="伙伴算法">伙伴算法</h3>

<p><a href="http://www.cnblogs.com/cherishui/p/4246133.html">Linux 伙伴算法简介 - 浩天之家 - 博客园</a></p>

<p><a href="https://blog.csdn.net/yusiguyuan/article/details/12041317">页的分配，讲的真的好！</a></p>

<p>对于要分配比较大的内存，例如到分配页级别的，可以使用<strong>伙伴系统</strong>（Buddy System）。</p>

<p><strong>一种物理内存分配和回收的方法，物理内存所有空闲页都记录在BUDDY链表中。</strong></p>

<p>首先，系统建立一个链表，链表中的每个元素代表一类大小的物理内存，分别为2的0次方、1次方、2次方，个页大小，对应4K、8K、16K的内存，每一类大小的内存又有一个链表，表示目前可以分配的物理内存。当向内核请求分配 (2^(i-1)，2^i] 数目的页块时，按照 2^i 页块请求处理。</p>

<blockquote>
  <p>例如现在仅存需要分配8K的物理内存，系统首先从8K那个链表中查询有无可分配的内存，若有直接分配；否则查找16K大小的链表，若有，首先将16K一分为二，将其中一个分配给进程，另一个插入8K的链表中，若无，继续查找32K，若有，首先把32K一分为二，其中一个16K大小的内存插入16K链表中，然后另一个16K继续一分为二，将其中一个插入8K的链表中，另一个分配给进程……..以此类推。当内存释放时，查看相邻内存有无空闲，若存在两个联系的8K的空闲内存，直接合并成一个16K的内存，插入16K链表中。</p>
</blockquote>

<p>每一个 zone，都有伙伴系统维护的各种大小的<strong>队列</strong></p>

<blockquote>
  <p>系统中所有的页面都存储在数组mem_map[]中，可以通过该数组找到系统中的每一页（空闲或非空闲）。而其中的空闲页面则可由上述提到的以伙伴关系组织的空闲页链表（free_area[MAX_ORDER]）来索引。</p>
</blockquote>

<p>缺点：</p>

<ol>
  <li>
    <p>合并的要求太过严格，<strong>只能是满足伙伴关系的块才能合并</strong>，比如第1块和第2块就不能合并。</p>
  </li>
  <li>
    <p>碎片问题：一个连续的内存中仅仅一个页面被占用，导致整块内存区都不具备合并的条件</p>
  </li>
  <li>
    <p>浪费问题：伙伴算法只能分配2的幂次方内存区，当需要8K（2页）时，好说，当需要9K时，那就需要分配16K（4页）的内存空间，但是实际只用到9K空间，多余的7K空间就被浪费掉。</p>
  </li>
  <li>
    <p>算法的效率问题：  伙伴算法涉及了比较多的计算还有链表和位图的操作，开销还是比较大的，如果每次2^n大小的伙伴块就会合并到2^(n+1)的链表队列中，那么2^n大小链表中的块就会因为合并操作而减少，但系统随后立即有可能又有对该大小块的需求，为此必须再从2^(n+1)大小的链表中拆分，这样的合并又立即拆分的过程是无效率的。</p>
  </li>
</ol>

<h3 id="slab算法">SLAB算法</h3>

<p>是一种对伙伴算法的一种补充，对于用户进程的内存分配，伙伴算法已经够好了，但对于内核进程，还需要存在一类很小的数据（字节大小，比如进程描述符、虚拟内存描述符等），若每次给几个字节的数据分配一个4KB的页，实在太浪费，于是就有了SLBA算法，SLAB算法其实就是把一个页用力劈成一小块一小块，然后再分配。</p>

<p>内存片段（小块内存）被看作对象，当被使用完后，并不直接释放而是被缓存到“存储池”里，留做下次使用，这无疑避免了频繁创建与销毁对象所带来的额外负载。</p>

<blockquote>
  <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>root@hjh-Ubuntu:~# more /proc/slabinfo 
slabinfo - version: 2.1
<span class="c"># name &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt; &lt;sharedavail&gt; uvm_tools_event_tracker_t      </span>
 0      0   1128   29    8 : tunables    0    0   0 : slabdata      0      0      0

</code></pre></div>  </div>

  <p>通过 <code class="language-plaintext highlighter-rouge">/proc/slabinfo</code> 查看可以找到内核执行现场使用的各种slab信息统计</p>
</blockquote>

<ul>
  <li><strong>Kmalloc</strong></li>
</ul>

<p>​    Slab分配器不仅仅只用来存放内核专用的结构体，它还被用来处理内核对小块内存的请求。当然鉴于Slab分配器的特点，一般来说内核程序中对小于一页的小块内存的请求才通过Slab分配器提供的接口Kmalloc来完成（虽然它可分配32  到131072字节的内存）。从内核内存分配的角度来讲，kmalloc可被看成是get_free_page（s）的一个有效补充，内存分配粒度更灵活了。</p>

<p><img src="/assets/blog_image/2020-12-03-HuSharp-Memory-02/image-20201207095515857.png" alt="image-20201207095515857" /></p>

<h3 id="内核非连续内存分配vmalloc">内核非连续内存分配（Vmalloc）</h3>

<h4 id="分片">分片</h4>

<p>分片又分为外部分片和内部分片之说，所谓内部分片是说系统为了满足一小段内存区（连续）的需要，不得不分配了一大区域连续内存给它，从而造成了空间浪费；外部分片是指系统虽有足够的内存，但却是分散的碎片，无法满足对大块“连续内存”的需求。无论何种分片都是系统有效利用内存的障碍。</p>

<p>伙伴关系也好、slab技术也好，从内存管理理论角度而言目的基本是一致的，它们都是为了防止“分片”</p>

<ul>
  <li>slab分配器使得一个页面内包含的众多小块内存可独立被分配使用，避免了内部分片，节约了空闲内存。</li>
  <li>伙伴关系把内存块按大小分组管理，一定程度上减轻了外部分片的危害，因为页框分配不在盲目，而是按照大小依次有序进行，不过伙伴关系只是减轻了外部分片，但并未彻底消除。</li>
</ul>

<h4 id="vmalloc">vmalloc</h4>

<p>所以避免外部分片的最终思路还是落到了<strong>如何利用不连续的内存块</strong>组合成“看起来很大的内存块”——这里的情况很类<strong>似于用户空间分配虚拟内存</strong>，内存逻辑上连续，其实映射到并不一定连续的物理内存上。Linux内核借用了这个技术，允许内核程序在内核地址空间中分配虚拟地址，同样也利用页表（内核页表）将虚拟地址映射到分散的内存页上。以此完美地解决了内核内存使用中的外部分片问题。内核提供vmalloc函数分配内核虚拟内存，该函数不同于kmalloc，它可以分配较Kmalloc大得多的内存空间（可远大于128K，但必须是页大小的倍数），但相比Kmalloc来说,Vmalloc需要<strong>对内核虚拟地址进行重映射</strong>，<strong>必须更新内核页表</strong>，因此分配效率上要低一些（用空间换时间）</p>

<p>与用户进程相似,内核也有一个名为init_mm的mm_strcut结构来描述内核地址空间，其中页表项pdg=swapper_pg_dir包含了系统内核空间（3G-4G）的映射关系。</p>

<p>因此vmalloc分配内核虚拟地址必须更新内核页表，而kmalloc或get_free_page由于分配的连续内存，所以不需要更新内核页表。</p>

<h3 id="总结-kmalloc-和-vmalloc">总结 kmalloc 和 vmalloc</h3>

<p><a href="https://www.cnblogs.com/wuchanming/p/4465155.html">Kmalloc和Vmalloc的区别</a></p>

<p>由get_free_page或Kmalloc函数所分配的连续内存都陷于物理映射区域，所以它们返回的内核虚拟地址和实际物理地址仅仅是相差一个偏移量（PAGE_OFFSET），你可以很方便的将其转化为物理内存地址，同时内核也提供了virt_to_phys（）函数将内核虚拟空间中的物理映射区地址转化为物理地址。要知道，物理内存映射区中的地址与内核页表是有序对应的，系统中的每个物理页面都可以找到它对应的内核虚拟地址（在物理内存映射区中的）。</p>

<p>而vmalloc分配的地址则限于vmalloc_start与vmalloc_end之间。每一块vmalloc分配的内核虚拟内存都对应一个vm_struct结构体（可别和vm_area_struct搞混，那可是进程虚拟内存区域的结构），不同的内核虚拟地址被4k大小的空闲区间隔，以防止越界）。与进程虚拟地址的特性一样，这些虚拟地址与物理内存没有简单的位移关系，必须通过内核页表才可转换为物理地址或物理页。它们有可能尚未被映射，在发生缺页时才真正分配物理页面。</p>

<blockquote>
  <p>但是应该注意的是，vmalloc()申请物理内存时是立即分配的，因为内核认为这种内存分配请求是正当而且紧急的；相反，用户态有内存请求时，内核总是尽可能的延后，毕竟用户态跟内核态不在一个特权级。</p>
</blockquote>

<p><img src="/assets/blog_image/2020-12-03-HuSharp-Memory-02/image-20201207110018353.png" alt="img-20201207110018353" style="zoom:60%;" /></p>

<ul>
  <li>物理内存的连续性一般是由于设备驱动的使用，或者DMA.  但是vmalloc申请效率比较低，还会造成TLB抖动. 一般内核里常用kmalloc.</li>
  <li>kmalloc和vmalloc是分配的是内核的内存,malloc分配的是用户的内存</li>
  <li>kmalloc保证分配的内存在物理上是连续的,vmalloc保证的是在虚拟地址空间上的连续</li>
  <li>kmalloc能分配的大小有限,vmalloc和malloc能分配的大小相对较大</li>
</ul>

<h2 id="页面换出">页面换出</h2>

<p><a href="https://www.cnblogs.com/ck1020/p/6768957.html">Linux 页面换入换出解析</a></p>

<p>现代操作系统使用分页机制和虚拟内存，同时为了提高物理页面的利用率，采用了请求调页的机制，即物理内存的分配只有在真正需要的时候才会进行，比如发生了真正的读写操作。</p>

<p><strong>什么情况下会触发页面换出呢？</strong></p>

<p><strong>1、启动一个程序时，</strong>装载器把进程可执行文件映射到进程的虚拟地址空间中，注意是虚拟地址空间，从入口函数开始分配一定数量的物理内存页，让其运行。事实上，某个程序可以使用的物理内存页数量基本是固定的（一般运行过程中），当执行到的代码没有在内存中，就会发生pagefault，进而由内存管理器把相应页面调入到内存，如果进程物理页面没有空间，就考虑换出某些页面。而不止是代码，进程中动态申请的内存也有可能由于内存紧张被换出到外存，在需要的时候再调入到内存中。合理的换入换出机制能够充分发挥现代操作系统多任务的优势，各个任务均能够正常的运行。但是换入换出机制毕竟需要和磁盘打交道，磁盘IO一直以来都是性能的瓶颈所在，所以设计一个良好的换入换出机制显得异常重要。</p>

<p><strong>2、当然还有一种情况</strong>，就是作为内存管理系统应该主动去做的，而不能等真的出了事儿再做，这就是内核线程<strong>kswapd0</strong>。这个内核线程，在系统初始化的时候就被创建。这样它会进入一个无限循环，直到系统停止。在这个循环中，如果内存使用没有那么紧张，那它就可以放心睡大觉；如果内存紧张了，就需要去检查一下内存，看看是否需要换出一些内存页。</p>

<blockquote>
  <p>kswapd0：主要作用是用来回收内存。在kswapd中，有2个阀值，pages_hige和pages_low。当空闲内存页的数量低于pages_low的时候，kswapd进程就会扫描内存并且每次释放出32个 free pages，直到freepage的数量到达pages_high。具体回收内存有如下原则：</p>

  <ol>
    <li>如果页未经更改就将该页放入空闲队列；</li>
    <li>如果页已经更改并且是可备份回文件系统的，就理解将内存页的内容写回磁盘；</li>
    <li>如果页已经更改但是没有任何磁盘上的备份，就将其写入swap分区。</li>
  </ol>
</blockquote>

<p>所有的页面都被挂在 LRU 列表中。LRU 是 Least Recent Use，也就是最近最少使用。也就是说，这个列表里面会按照活跃程度进行排序，这样就容易把不怎么用的内存页拿出来做处理。</p>

<p>内存页总共分两类，一类是<strong>匿名页</strong>，和虚拟地址空间进行关联；一类是<strong>内存映射</strong>，不但和虚拟地址空间关联，还和文件管理关联。</p>

<p>它们每一类都有两个列表，一个是 active，一个是 inactive。顾名思义，active 就是比较活跃的，inactive  就是不怎么活跃的。这两个里面的页会变化，过一段时间，活跃的可能变为不活跃，不活跃的可能变为活跃。如果要换出内存，那就是从不活跃的列表中找出最不活跃的，换出到硬盘上。</p>

<h3 id="相关页面置换算法">相关页面置换算法</h3>

<p><a href="https://www.cnblogs.com/Leophen/p/11397699.html">页面置换算法详解</a></p>]]></content><author><name></name></author><category term="Linux" /></entry><entry><title type="html">内存管理（一）前置知识 &amp;amp; 虚拟地址布局</title><link href="http://localhost:4000/linux/2020/12/01/Memory-01.html" rel="alternate" type="text/html" title="内存管理（一）前置知识 &amp;amp; 虚拟地址布局" /><published>2020-12-01T08:51:14+08:00</published><updated>2020-12-01T08:51:14+08:00</updated><id>http://localhost:4000/linux/2020/12/01/Memory-01</id><content type="html" xml:base="http://localhost:4000/linux/2020/12/01/Memory-01.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#内存管理" id="markdown-toc-内存管理">内存管理</a>    <ul>
      <li><a href="#前置知识" id="markdown-toc-前置知识">前置知识</a>        <ul>
          <li><a href="#首先内存访问为什么要分段" id="markdown-toc-首先内存访问为什么要分段">首先：内存访问为什么要分段？</a></li>
          <li><a href="#其次程序中的分段datatext与内存访问中的分段" id="markdown-toc-其次程序中的分段datatext与内存访问中的分段">其次：程序中的分段（data、text）与内存访问中的分段</a></li>
        </ul>
      </li>
      <li><a href="#为什么要有虚拟地址" id="markdown-toc-为什么要有虚拟地址">为什么要有虚拟地址？</a></li>
      <li><a href="#linux虚拟地址空间布局" id="markdown-toc-linux虚拟地址空间布局">Linux虚拟地址空间布局</a>        <ul>
          <li><a href="#1用户空间详解" id="markdown-toc-1用户空间详解">1、用户空间详解</a></li>
          <li><a href="#2内核空间详解" id="markdown-toc-2内核空间详解">2、内核空间详解</a></li>
        </ul>
      </li>
      <li><a href="#分段机制" id="markdown-toc-分段机制">分段机制</a></li>
      <li><a href="#分页机制" id="markdown-toc-分页机制">分页机制</a></li>
      <li><a href="#物理地址线性地址虚拟地址逻辑地址" id="markdown-toc-物理地址线性地址虚拟地址逻辑地址">物理地址/线性地址/虚拟地址/逻辑地址</a></li>
    </ul>
  </li>
</ul>

<h1 id="内存管理">内存管理</h1>

<p>操作系统的内存管理，主要分为三个方面。</p>

<p>第一，物理内存的管理，相当于会议室管理员管理会议室。</p>

<p>第二，虚拟地址的管理，也即在项目组的视角，会议室的虚拟地址应该如何组织。</p>

<p>第三，虚拟地址和物理地址如何映射，也即会议室管理员如果管理映射表。</p>

<h2 id="前置知识">前置知识</h2>

<h3 id="首先内存访问为什么要分段">首先：内存访问为什么要分段？</h3>

<p>程序分段首先是为了重定位</p>

<p>程序分段又是为了将大内存分成可以访问的小段，通过这样变通的方法便能够访问到所有内存了。</p>

<h3 id="其次程序中的分段datatext与内存访问中的分段">其次：程序中的分段（data、text）与内存访问中的分段</h3>

<p>程序代码中的段（用 section 或 segment 来定义的段，不同汇编编译器提供的关键字有所区别，功能是一样的）和内存访问机制中的段本质上是一回事。在硬件的内存访问机制中，处理器要用硬件——段寄存器，指向软件——程序代码中用section或segment以软件形式所定义的内存段。</p>

<p><strong>程序为何要分段？</strong></p>

<p>为了让程序内指令接连不断地执行，要把指令全部排在一起，形成一片连续的指令区域，这就是代码段。这样 CPU 肯定能接连不断地执行下去。指令是由操作码和操作数组成的，这对于数据也一样，程序运行不仅要有操作码，也得有操作数，操作数就是指程序中的数据。把数据连续地并排在一起存储形成的段落，就称为数据段。</p>

<blockquote>
  <p><strong>将数据和代码分开的好处有三点。</strong></p>

  <p>第一，可以为它们赋予不同的属性。</p>

  <p>例如数据本身是需要修改的，所以数据就需要有可写的属性，不让数据段可写，那程序根本就无法执行啦。程序中的代码是不能被更改的，这样就要求代码段具备只读的属性。真要是在运行过程中程序的下一条指令被修改了，谁知道会产生什么样的灾难。</p>

  <p>第二，为了提高CPU内部缓存的命中率。</p>

  <p>大伙儿知道，缓存起作用的原因是程序的局部性原理。在CPU内部也有缓存机制，将程序中的指令和数据分离，这有利于增强程序的局部性。CPU内部有针对数据和针对指令的两种缓存机制，因此，将数据和代码分开存储将使程序运行得更快。代码指令根据流程依次执行，只需访问一次(当然跳转和递归可能使代码执行多次)；而数据(数据段和BSS段)通常需要访问多次.</p>

  <p>第三，节省内存。</p>

  <p>程序中存在一些只读的部分，比如代码，当一个程序的多个副本同时运行时（比如同时执行多个ls命令时），没必要在内存中同时存在多个相同的代码段，这将浪费有限的物理内存资源，只要把这一个代码段共享就可以了。</p>
</blockquote>

<p>程序中的段只是逻辑上的划分，用于不同数据的归类，但是可以用CPU中的段寄存器直接指向它们，然后用内存分段机制去访问程序中的段，在这一点上看，它们很像相片和相框的关系：程序中的段是内存中的内容，相当于相片，属于被展示的内容，而内存分段机制则是访问内存的手段，相当于相框，有了相框，照片才能有地摆放。</p>

<h2 id="为什么要有虚拟地址">为什么要有虚拟地址？</h2>

<pre><code class="language-assembly">1.在支持多进程的系统中，如果各个进程的镜像文件都使用物理地址，则在加载到同一物理内存空间的时候，可能发生冲突。
2.直接使用物理地址，不便于进行进程地址空间的隔离。
3.物理内存是有限的，在物理内存整体吃紧的时候，可以让多个进程通过分时复用的方法共享一个物理页面（某个进程需要保存的内容可以暂时swap到外部的disk/flash），这有点类似于多线程分时复用共享CPU的方式。
</code></pre>

<p>每个项目的物理地址对于进程不可见，谁也不能直接访问这个物理地址。操作系统会给进程分配一个虚拟地址。所有进程看到的这个地址都是一样的，里面的内存都是从 0 开始编号。</p>

<p>在程序里面，指令写入的地址是虚拟地址。例如，位置为 10M 的内存区域，操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。</p>

<p>当程序要访问虚拟地址的时候，由内核的数据结构进行转换，转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。</p>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206111940363-1607353840723.png" alt="image-20201206111940363" style="zoom:50%;" /></p>

<p>通常<strong>32位Linux内核虚拟</strong>地址空间划分0~3G为用户空间，3~4G为内核空间(注意，内核可以使用的线性地址只有1G)。</p>

<h2 id="linux虚拟地址空间布局">Linux虚拟地址空间布局</h2>

<h3 id="1用户空间详解">1、用户空间详解</h3>

<p><a href="https://www.cnblogs.com/clover-toeic/p/3754433.html">Linux虚拟地址空间布局</a> 详情见此 Blog ！！！</p>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206130503945-1607353840724.png" alt="image-20201206130503945" /></p>

<table>
  <thead>
    <tr>
      <th><strong>名称</strong></th>
      <th><strong>存储内容</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>内核空间</td>
      <td>内核总是驻留在内存中，是操作系统的一部分</td>
    </tr>
    <tr>
      <td>栈</td>
      <td>局部变量、函数参数（栈帧）、返回地址等</td>
    </tr>
    <tr>
      <td>内存映射段</td>
      <td>被用于装载动态共享库，从高地址到低地址增长的</td>
    </tr>
    <tr>
      <td>堆</td>
      <td>动态分配的内存 malloc/free 堆不同于数据结构中的”堆”，其行为类似链表。</td>
    </tr>
    <tr>
      <td>BSS段</td>
      <td>未初始化或初值为0的全局变量和静态局部变量</td>
    </tr>
    <tr>
      <td>数据段</td>
      <td>已初始化且初值非0的全局变量和静态局部变量，未定义且初值不为0的符号</td>
    </tr>
    <tr>
      <td>代码段</td>
      <td>可执行代码、字符串字面值、只读变量</td>
    </tr>
    <tr>
      <td>保留区</td>
      <td>任何对它的引用都是非法的，用于捕捉使用空指针和小整型值指针引用内存的异常情况。</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>运行时数据段和BSS段的整个区段通常称为数据区。某些资料中“数据段”指代数据段 + BSS段 + 堆。</p>
</blockquote>

<p><strong>内存映射段(mmap)</strong></p>

<p>此处，内核将硬盘文件的内容直接映射到内存,  任何应用程序都可通过Linux的mmap()系统调用或Windows的CreateFileMapping()/MapViewOfFile()请求这种映射。内存映射是一种方便高效的文件I/O方式， 因而被用于装载动态共享库。用户也可创建匿名内存映射，该映射没有对应的文件, 可用于存放程序数据。在  Linux中，若通过malloc()请求一大块内存，C运行库将创建一个匿名内存映射，而不使用堆内存。”大块” 意味着比阈值  MMAP_THRESHOLD还大，缺省为128KB，可通过mallopt()调整。</p>

<p>该区域用于映射可执行文件用到的动态链接库。在Linux  2.4版本中，若可执行文件依赖共享库，则系统会为这些动态库在从 0x40000000 开始的地址分配相应空间，并在程序装载时将其载入到该空间。在Linux 2.6内核中，共享库的起始地址被往上移动至更靠近栈区的位置。</p>

<p>从进程地址空间的布局可以看到，在有共享库的情况下，留给堆的可用空间还有两处：一处是从.bss段到0x40000000，约不到1GB的空间；另一处是从共享库到栈之间的空间，约不到2GB。这两块空间大小取决于栈、共享库的大小和数量。这样来看，是否应用程序可申请的最大堆空间只有2GB？事实上，这与Linux内核版本有关。在上面给出的进程地址空间经典布局图中，共享库的装载地址为0x40000000，这实际上是Linux kernel  2.6版本之前的情况了，在2.6版本里，共享库的装载地址已经被挪到靠近栈的位置，即位于0xBFxxxxxx附近，因此，此时的堆范围就不会被共享库分割成2个“碎片”，故kernel 2.6的32位Linux系统中，malloc申请的最大内存理论值在2.9GB左右。</p>

<p><strong>保留区</strong></p>

<p>位于虚拟地址空间的最低部分，未赋予物理地址。任何对它的引用都是非法的，用于捕捉使用空指针和小整型值指针引用内存的异常情况。</p>

<p><strong>它并不是一个单一的内存区域，而是对地址空间中受到操作系统保护而禁止用户进程访问的地址区域的总称。</strong>大多数操作系统中，极小的地址通常都是不允许访问的，如NULL。C语言将无效指针赋值为0也是出于这种考虑，因为0地址上正常情况下不会存放有效的可访问数据。</p>

<blockquote>
  <p>【扩展阅读】<strong>栈和堆的区别</strong></p>

  <p>①<strong>管理方式</strong>：栈由编译器自动管理；堆由程序员控制，使用方便，但易产生内存泄露。</p>

  <p>②<strong>生长方向</strong>：栈向低地址扩展(即”向下生长”)，是连续的内存区域；堆向高地址扩展(即”向上生长”)，是不连续的内存区域。这是由于系统用链表来存储空闲内存地址，自然不连续，而链表从低地址向高地址遍历。</p>

  <p>③<strong>空间大小</strong>：栈顶地址和栈的最大容量由系统预先规定(通常默认2M或10M)；堆的大小则受限于计算机系统中有效的虚拟内存，32位Linux系统中堆内存可达2.9G空间。</p>

  <p>④<strong>存储内容</strong>：栈在函数调用时，首先压入主调函数中下条指令(函数调用语句的下条可执行语句)的地址，然后是函数实参，然后是被调函数的局部变量。本次调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的指令地址，程序由该点继续运行下条可执行语句。堆通常在头部用一个字节存放其大小，堆用于存储生存期与函数调用无关的数据，具体内容由程序员安排。</p>

  <p>⑤<strong>分配方式</strong>：栈可静态分配或动态分配。静态分配由编译器完成，如局部变量的分配。动态分配由alloca函数在栈上申请空间，用完后自动释放。堆只能动态分配且手工释放。</p>

  <p>⑥<strong>分配效率</strong>：栈由计算机底层提供支持：分配专门的寄存器存放栈地址，压栈出栈由专门的指令执行，因此效率较高。堆由函数库提供，机制复杂，效率比栈低得多。Windows系统中VirtualAlloc可直接在进程地址空间中分配一块内存，快速且灵活。</p>

  <p>⑦<strong>分配后系统响应</strong>：只要栈剩余空间大于所申请空间，系统将为程序提供内存，否则报告异常提示栈溢出。</p>

  <p>操作系统为<strong>堆维护一个记录空闲内存地址的链表</strong>。当系统收到程序的内存分配申请时，会遍历该链表寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点空间分配给程序。若无足够大小的空间(可能由于内存碎片太多)，有可能调用系统功能去增加程序数据段的内存空间，以便有机会分到足够大小的内存，然后进行返回。大多数系统会在该内存空间首地址处记录本次分配的内存大小，供后续的释放函数(如free/delete)正确释放本内存空间。</p>

  <p>此外，由于找到的堆结点大小不一定正好等于申请的大小，系统会自动将多余的部分重新放入空闲链表中。</p>

  <p>⑧<strong>碎片问题</strong>：栈不会存在碎片问题，因为栈是先进后出的队列，内存块弹出栈之前，在其上面的后进的栈内容已弹出。而频繁申请释放操作会造成堆内存空间的不连续，从而造成大量碎片，使程序效率降低。</p>

  <p>可见，堆容易造成内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和内核态切换，内存申请的代价更为昂贵。所以栈在程序中应用最广泛，函数调用也利用栈来完成，调用过程中的参数、返回地址、栈基指针和局部变量等都采用栈的方式存放。所以，建议尽量使用栈，仅在分配大量或大块内存空间时使用堆。</p>

  <p>使用栈和堆时应避免越界发生，否则可能程序崩溃或破坏程序堆、栈结构，产生意想不到的后果。</p>
</blockquote>

<h3 id="2内核空间详解">2、内核空间详解</h3>

<p>[<a href="https://www.cnblogs.com/zlcxbb/p/5841417.html">高端内存详解</a>] 详见此 Blog</p>

<p>Linux 操作系统和驱动程序运行在内核空间，应用程序运行在用户空间，两者不能简单地使用指针传递数据，因为Linux使用的虚拟内存机制，用户空间的数据可能被换出，当内核空间使用用户空间指针时，对应的数据可能不在内存中。用户空间的内存映射采用段页式，而内核空间有自己的规则；</p>

<p><strong>现探讨内核空间的地址映射</strong></p>

<p>x86架构中将<strong>内核地址空间</strong>划分三部分：ZONE_DMA、ZONE_NORMAL和 ZONE_HIGHMEM。</p>

<blockquote>
  <p><strong>ZONE_DMA</strong>    内存开始的16MB</p>

  <p><strong>ZONE_NORMAL</strong>    16MB~896MB</p>

  <p><strong>ZONE_HIGHMEM</strong>    896MB ~ 结束（1G）</p>

  <p>0-896 MB 映射到对应物理地址中的 0-896 MB，我们称为<strong>直接映射区</strong>。</p>
</blockquote>

<p>ZONE_HIGHMEM：高端内存 HIGH_MEM 地址空间范围为 0xF8000000 ~ 0xFFFFFFFF（896MB～1024MB），可以访问所有物理内存。</p>

<p>如果不留出这么一段做映射, 内核就只能管理1G的物理内存, 余下部分就只能浪费了.用户空间的内存使用也是内核分配的, 内核当然要有能力控制所有硬件资源.</p>

<p>那么内核是<strong>如何借助128MB高端内存地址空间是如何实现访问所有物理内存</strong>？</p>

<p>当内核想访问高于896MB物理地址内存时，从0xF8000000 ~ 0xFFFFFFFF地址空间范围内找一段相应大小空闲的逻辑地址空间，借用一会。借用这段逻辑地址空间，建立映射到想访问的那段物理内存（即填充内核PTE页面表），<strong>临时用一会，用完后归还</strong>。这样别人也可以借用这段地址空间访问其他物理内存，实现了使用有限的地址空间，访问所有所有物理内存。如下图。</p>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206135558665-1607353840724.png" alt="image-20201206135558665" /></p>

<p>例 如内核想访问2G开始的一段大小为1MB的物理内存，即物理地址范围为0×80000000 ~  0x800FFFFF。访问之前先找到一段1MB大小的空闲地址空间，假设找到的空闲地址空间为0xF8700000 ~  0xF87FFFFF，用这1MB的逻辑地址空间映射到物理地址空间0×80000000 ~ 0x800FFFFF的内存。映射关系如下：</p>

<table>
  <thead>
    <tr>
      <th><strong>逻辑地址</strong></th>
      <th><strong>物理内存地址</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0xF8700000</td>
      <td>0×80000000</td>
    </tr>
    <tr>
      <td>0xF8700001</td>
      <td>0×80000001</td>
    </tr>
    <tr>
      <td>0xF8700002</td>
      <td>0×80000002</td>
    </tr>
    <tr>
      <td>…</td>
      <td>…</td>
    </tr>
    <tr>
      <td>0xF87FFFFF</td>
      <td>0x800FFFFF</td>
    </tr>
  </tbody>
</table>

<p>当内核访问完0×80000000 ~ 0x800FFFFF物理内存后，就将0xF8700000 ~ 0xF87FFFFF内核线性空间释放。这样其他进程或代码也可以使用0xF8700000 ~ 0xF87FFFFF这段地址访问其他物理内存。</p>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206190940636-1607353840724.png" alt="image-20201206190940636" style="zoom:80%;" /></p>

<p>在内核中，除了内存管理模块直接操作物理地址之外，内核的其他模块，仍然要操作虚拟地址，而虚拟地址是需要内存管理模块分配和映射好的。</p>

<p>于是，我们可以将剩下的虚拟内存地址分成下面这几个部分。</p>

<ul>
  <li>在 896M 到 VMALLOC_START 之间有 8M 的空间。物理内存映射区与vmalloc_start 之间还会存在一个8M大小的gap来防止跃界.</li>
  <li>VMALLOC_START 到 VMALLOC_END 之间称为内核动态映射空间，也即内核想像用户态进程一样 malloc  申请内存，在内核里面可以使用 <strong>vmalloc。</strong>假设物理内存里面，896M 到 1.5G  之间已经被用户态进程占用了，并且映射关系放在了进程的页表中，内核 vmalloc 的时候，只能从分配物理内存 1.5G  开始，就需要使用这一段的虚拟地址进行映射，映射关系放在专门给内核自己用的页表里面。</li>
  <li>PKMAP_BASE 到 FIXADDR_START 的空间称为持久内核映射。使用 alloc_pages() 函数的时候，在物理内存的高端内存得到 struct page 结构，可以调用 kmap 将其在映射到这个区域。</li>
  <li>FIXADDR_START 到 FIXADDR_TOP(0xFFFF F000) 的空间，称为固定映射区域，主要用于满足特殊需求。</li>
  <li>在最后一个区域可以通过 kmap_atomic  实现临时内核映射。假设用户态的进程要映射一个文件到内存中，先要映射用户态进程空间的一段虚拟地址到物理内存，然后将文件内容写入这个物理内存供用户态进程访问。给用户态进程分配物理内存页可以通过  alloc_pages()，分配完毕后，按说将用户态进程虚拟地址和物理内存的映射关系放在用户态进程的页表中，就完事大吉了。这个时候，用户态进程可以通过用户态的虚拟地址，也即 0 至 3G  的部分，经过页表映射后访问物理内存，并不需要内核态的虚拟地址里面也划出一块来，映射到这个物理内存页。但是如果要把文件内容写入物理内存，这件事情要内核来干了，这就只好通过 kmap_atomic 做一个临时映射，写入物理内存完毕后，再 kunmap_atomic 来解映射即可。</li>
</ul>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206191820321-1607353840724.png" alt="image-20201206191820321" /></p>

<p>64位系统不使用高端内存，这是因为64位的系统理论上可寻址的地址空间远大于实际的物理内存（至少现在是如此），因而就不必借助“高端内存”了。而对于用户进程来说，由于它的所有内存访问都通过页表进行，不会直接进行，因而对用户进程来说也不存在高端内存之说。
 高端内存由32位架构的内核使用，在32位架构的内核中，要使用高端内存必须首先使用kmap将高端内存映射进内核的虚拟地址空间。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>查看进程内存空间的布局

<span class="nb">cat</span> /proc/<span class="nv">$pid</span>/maps
</code></pre></div></div>

<h2 id="分段机制">分段机制</h2>

<p>分段机制下的虚拟地址由两部分组成，<strong>段选择子</strong>和<strong>段内偏移量</strong>。段选择子就保存在咱们前面讲过的段寄存器里面。段选择子里面最重要的是<strong>段号</strong>，用作段表的索引。段表里面保存的是这个段的<strong>基地址</strong>、<strong>段的界限</strong>和<strong>特权等级</strong>等。虚拟地址中的段内偏移量应该位于 0 和段界限之间。如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。</p>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206162424133-1607353840724.png" alt="image-20201206162424133" /></p>

<p>段选择子就保存在段寄存器里面，段内偏移量应该位于 0 和段界限之间。</p>

<p>在 Linux 操作系统中，并没有使用到全部的分段功能。那分段是不是完全没有用处呢？分段可以做权限审核，例如用户态 DPL 是 3，内核态 DPL 是 0。当用户态试图访问内核态的时候，会因为权限不足而报错。</p>

<p>其实 Linux 倾向于另外一种从虚拟地址到物理地址的转换方式，称为<strong>分页</strong>（Paging）。</p>

<h2 id="分页机制">分页机制</h2>

<p>对于物理内存，操作系统把它分成一块一块大小相同的页，这样更方便管理，例如有的内存页面长时间不用了，可以暂时写到硬盘上，称为<strong>换出</strong>。一旦需要的时候，再加载进来，叫作<strong>换入</strong>。这样可以扩大可用物理内存的大小，提高物理内存的利用率。</p>

<p>这个换入和换出都是以页为单位的。<strong>页面的大小一般为 4KB</strong>。为了能够定位和访问每个页，需要有个页表，保存每个页的起始地址，再加上在页内的偏移量，组成线性地址，就能对于内存中的每个位置进行访问了。</p>

<p>首先需要明白，分页是建立在分段上的</p>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206163819229-1607353840725.png" alt="image-20201206163819229" style="zoom:70%;" /></p>

<p>虚拟地址分为两部分，<strong>页号</strong>和<strong>页内偏移</strong>。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址。这个基地址与页内偏移的组合就形成了物理内存地址。</p>

<blockquote>
  <p>为什么 32 位要采用二级页表？</p>

  <p>32 位环境下，虚拟地址空间共 4GB。如果分成 4KB 一个页，那就是 1M 个页。<strong>每个页表项需要 4 个字节来存储</strong>，那么整个 4GB  空间的映射就需要 4MB 的内存来存储映射表。如果每个进程都有自己的映射表，100 个进程就需要 400MB 的内存。对于内核来讲，有点大了 。</p>

  <p>我们现在需要解决为：不用一次性建立完所有的页表，而是动态建立。</p>

  <p>二级页表与一级页表的区别：</p>

  <p><strong>假设只给这个进程分配了一个数据页。</strong>如果只使用页表，也需要完整的 1M 个页表项共 4M 的内存，但是如果使用了页目录，页目录需要 1K  个全部分配，占用内存 4K，但是里面只有一项使用了。到了页表项，只需要分配能够管理那个数据页的页表项页就可以了，也就是说，最多  4K，这样内存就节省多了。</p>
</blockquote>

<p>主要采用二级页表来实现虚拟地址转换为物理地址</p>

<p>页表中所有页表项必须提前建好，并且要求是连续的。如果不连续，就没有办法通过虚拟地址里面的页号找到对应的页表项了。</p>

<blockquote>
  <p>每项 4 个字节</p>

  <p>页目录有 1K 项，用 10 位就可以表示访问页目录的哪一项。这一项其实对应的是一整页的页表项，也即 4K 的页表项。每个页表项也是 4  个字节，因而一整页的页表项是 1K 个。再用 10  位就可以表示访问页表项的哪一项，页表项中的一项对应的就是一个页，是存放数据的页，这个页的大小是 4K，用 12  位可以定位这个页内的任何一个位置。</p>

  <p>如下图所示</p>
</blockquote>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206164409505-1607353840725.png" alt="image-20201206164409505" /></p>

<blockquote>
  <p>地址转换，是由处理器和操作系统共同协作完成的，处理器在硬件上提供地址转换部件，操作系统提供转换过程中所需要的页表。</p>
</blockquote>

<p>当然对于 64 位的系统，两级肯定不够了，就变成了四级目录，分别是全局页目录项 PGD（Page Global  Directory）、上层页目录项 PUD（Page Upper Directory）、中间页目录项 PMD（Page Middle  Directory）和页表项 PTE（Page Table Entry）。</p>

<p><img src="/assets/blog_image/2020-12-01-HuSharp-Memory-01/image-20201206171308852-1607353840725.png" alt="image-20201206171308852" /></p>

<h2 id="物理地址线性地址虚拟地址逻辑地址">物理地址/线性地址/虚拟地址/逻辑地址</h2>

<p>1）实模式下，”段基址+段内偏移地址”经过段部件的处理，直接输出的就是物理地址，CPU可以直接用此地址访问内存。</p>

<p>2）保护模式下，”段基址+段内偏移地址”经段部件处理后为线性地址。（但此处的段基址不再是真正的地址，而是一个选择子，本质上是个索引，类似于数组下标，通过这个索引便能在GDT中找到相应的段描述符。段描述符记录了该段的起始、大小等信息，这样便得到了段基址。）若没有开启地址分页功能，此线性地址就被当作物理地址来用，可直接访问内存。</p>

<p>3）保护模式+分页机制，若开启了分页功能，线性地址则称为虚拟地址（虚拟地址、线性地址在分页机制下都是一回事）。虚拟地址要经过CPU页部件转换成具体的物理地址，这样CPU才能将其送上地址总线取访问内存。</p>

<p>4）逻辑地址，无论是在实模式或保护模式下，段内偏移地址又称为有效地址，也称为逻辑地址，这是程序员可见的地址。最终的地址是由段基址和段内偏移地址组合而成。实模式下，段基址在对应的段寄存器中(cs ds es fs gs)；保护模式下，段基址在段选择子寄存器指向的段描述符中。所以，只要给出段内偏移地址就行了，再加上对应的段基址即可。</p>]]></content><author><name></name></author><category term="Linux" /></entry><entry><title type="html">回车与换行的探究</title><link href="http://localhost:4000/linux/2020/11/20/nAndr.html" rel="alternate" type="text/html" title="回车与换行的探究" /><published>2020-11-20T09:19:01+08:00</published><updated>2020-11-20T09:19:01+08:00</updated><id>http://localhost:4000/linux/2020/11/20/nAndr</id><content type="html" xml:base="http://localhost:4000/linux/2020/11/20/nAndr.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#1-由来" id="markdown-toc-1-由来">1. 由来</a></li>
  <li><a href="#2demo-探究" id="markdown-toc-2demo-探究">2.demo 探究</a></li>
</ul>

<p><a href="https://blog.csdn.net/fanwenbo/article/details/54848429">回车与换行的区别</a></p>

<h3 id="1-由来">1. 由来</h3>

<p>在计算机还没有出现之前，有一种叫做电传打字机（Teletype Model  33）的机械打字机，每秒钟可以打10个字符。但是它有一个问题，就是打完一行换行的时候，要用去0.2秒，正好可以打两个字符。要是在这0.2秒里面，又有新的字符传过来，那么这个字符将丢失。</p>

<p>于是，研制人员想了个办法解决这个问题，就是在每行后面加两个表示结束的字符。一个叫做“回车”，告诉打字机把打印头定位在左边界，不卷动滚筒；另一个叫做“换行”，告诉打字机把滚筒卷一格，不改变水平位置。</p>

<p>这就是“换行”和“回车”的由来。</p>

<h3 id="2demo-探究">2.demo 探究</h3>

<p>Linux 中输入 enter 到底是什么键</p>

<p>首先通过一个程序</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">c</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">while</span><span class="p">((</span><span class="n">c</span> <span class="o">=</span> <span class="n">getchar</span><span class="p">())</span> <span class="o">!=</span> <span class="sc">'Q'</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"char %3d is %c code %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">n</span><span class="o">++</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// output</span>
<span class="n">hello</span>
<span class="kt">char</span>   <span class="mi">0</span> <span class="n">is</span> <span class="n">h</span> <span class="n">code</span> <span class="mi">104</span>
<span class="kt">char</span>   <span class="mi">1</span> <span class="n">is</span> <span class="n">e</span> <span class="n">code</span> <span class="mi">101</span>
<span class="kt">char</span>   <span class="mi">2</span> <span class="n">is</span> <span class="n">l</span> <span class="n">code</span> <span class="mi">108</span>
<span class="kt">char</span>   <span class="mi">3</span> <span class="n">is</span> <span class="n">l</span> <span class="n">code</span> <span class="mi">108</span>
<span class="kt">char</span>   <span class="mi">4</span> <span class="n">is</span> <span class="n">o</span> <span class="n">code</span> <span class="mi">111</span>
<span class="kt">char</span>   <span class="mi">5</span> <span class="n">is</span> 
 <span class="n">code</span> <span class="mi">10</span>
<span class="n">Q</span>
</code></pre></div></div>

<p>发现，当输入 enter 时， Unix 读入 \n</p>

<blockquote>
  <p>linux系统中的等价关系：</p>

  <p><strong>用enter换行 &lt;====&gt; 程序写\n &lt;====&gt; 真正朝文件中写\n(0x0a)  &lt;====&gt; 程序真正读取的是\n</strong>）</p>

  <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span><span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span>
<span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">ch</span><span class="p">;</span>
    <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">ch</span> <span class="o">=</span> <span class="n">fgetc</span><span class="p">(</span><span class="n">stdin</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">ch</span> <span class="o">==</span> <span class="mi">10</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stdout</span><span class="p">,</span> <span class="s">"You have pressed the enter key</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>  </div>
</blockquote>]]></content><author><name></name></author><category term="Linux" /></entry><entry><title type="html">自己动手画 CPU《计算机组织与结构实验》（四）</title><link href="http://localhost:4000/principle/2020/11/13/hust-cpu-study_4.html" rel="alternate" type="text/html" title="自己动手画 CPU《计算机组织与结构实验》（四）" /><published>2020-11-13T18:00:52+08:00</published><updated>2020-11-13T18:00:52+08:00</updated><id>http://localhost:4000/principle/2020/11/13/hust-cpu-study_4</id><content type="html" xml:base="http://localhost:4000/principle/2020/11/13/hust-cpu-study_4.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#四处理器设计实验" id="markdown-toc-四处理器设计实验">四、处理器设计实验</a>    <ul>
      <li><a href="#前置背景知识" id="markdown-toc-前置背景知识">前置背景知识</a>        <ul>
          <li><a href="#介绍单总线双总线三总线数据通路" id="markdown-toc-介绍单总线双总线三总线数据通路">介绍单总线、双总线、三总线数据通路</a></li>
          <li><a href="#数据通路-与-cpu-结构之间的关系" id="markdown-toc-数据通路-与-cpu-结构之间的关系">数据通路 与 CPU 结构之间的关系</a></li>
        </ul>
      </li>
      <li><a href="#一单周期-mips-cpu设计" id="markdown-toc-一单周期-mips-cpu设计">一、单周期 MIPS CPU设计</a>        <ul>
          <li><a href="#1r-型" id="markdown-toc-1r-型">1、R 型</a></li>
          <li><a href="#2i-型" id="markdown-toc-2i-型">2、I 型</a></li>
          <li><a href="#3syscall" id="markdown-toc-3syscall">3、Syscall</a></li>
        </ul>
      </li>
      <li><a href="#二单周期硬布线控制器" id="markdown-toc-二单周期硬布线控制器">二、单周期硬布线控制器</a></li>
      <li><a href="#三mips-微程序-cpu-设计" id="markdown-toc-三mips-微程序-cpu-设计">三、MIPS 微程序 CPU 设计</a></li>
    </ul>
  </li>
</ul>

<p><a href="https://www.icourse163.org/course/HUST-1205809816">配套慕课</a></p>

<h2 id="四处理器设计实验">四、处理器设计实验</h2>

<h3 id="前置背景知识">前置背景知识</h3>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114110538633.png" alt="image-20201114110538633" /></p>

<p>首先介绍<strong>数据通路</strong></p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114104952804.png" alt="image-20201114104952804" /></p>

<p><strong>现代 CPU 多采用 专用通路</strong></p>

<ul>
  <li>共享通路(总线型)
主要部件都连接在公共总线上,各部件间通过总线进行数据传输
结构简单，实现容易 ,但并发性较差,需分时使用总线,效率低</li>
  <li>专用通路
并发度高，性能佳,设计复杂,成本高
可以看作多总线结构</li>
</ul>

<h4 id="介绍单总线双总线三总线数据通路">介绍单总线、双总线、三总线数据通路</h4>

<p>对指令</p>

<pre><code class="language-assembly">ADD R0,R1
(R0)+(R1) -&gt; R0
</code></pre>

<p>单总线</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114105521293.png" alt="image-20201114105521293" /></p>

<p>双总线</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114105706866.png" alt="image-20201114105706866" /></p>

<p>三总线 并发写入</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114105835266.png" alt="image-20201114105835266" /></p>

<h4 id="数据通路-与-cpu-结构之间的关系">数据通路 与 CPU 结构之间的关系</h4>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114110109759.png" alt="image-20201114110109759" /></p>

<p>左下角是互斥的控制信号，因此可见冲突性较大，并发度小</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114110033962.png" alt="image-20201114110033962" /></p>

<p>多总线将 ALU 与 取指令 逻辑分开，因此可以并发执行。</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114110308476.png" alt="image-20201114110308476" /></p>

<p>单周期 MIPS 要求一条指令需要在一个时钟周期内完成。</p>

<table>
  <thead>
    <tr>
      <th>REGISTER</th>
      <th>NAME</th>
      <th>USAGE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$0</td>
      <td>$zero</td>
      <td>常量0(constant value 0)</td>
    </tr>
    <tr>
      <td>$1</td>
      <td>$at</td>
      <td>保留给汇编器(Reserved for assembler)</td>
    </tr>
    <tr>
      <td>$2-$3</td>
      <td>$v0-$v1</td>
      <td>函数调用返回值(values for results and expression evaluation)</td>
    </tr>
    <tr>
      <td>$4-$7</td>
      <td>$a0-$a3</td>
      <td>函数调用参数(arguments)</td>
    </tr>
    <tr>
      <td>$8-$15</td>
      <td>$t0-$t7</td>
      <td>暂时的(或随便用的)</td>
    </tr>
    <tr>
      <td>$16-$23</td>
      <td>$s0-$s7</td>
      <td>保存的(或如果用，需要SAVE/RESTORE的)(saved)</td>
    </tr>
    <tr>
      <td>$24-$25</td>
      <td>$t8-$t9</td>
      <td>暂时的(或随便用的)</td>
    </tr>
    <tr>
      <td>$28</td>
      <td>$gp</td>
      <td>全局指针(Global Pointer)</td>
    </tr>
    <tr>
      <td>$29</td>
      <td>$sp</td>
      <td>堆栈指针(Stack Pointer)</td>
    </tr>
    <tr>
      <td>$30</td>
      <td>$fp</td>
      <td>帧指针(Frame Pointer)</td>
    </tr>
    <tr>
      <td>$31</td>
      <td>$ra</td>
      <td>返回地址(return address)</td>
    </tr>
  </tbody>
</table>

<h3 id="一单周期-mips-cpu设计">一、单周期 MIPS CPU设计</h3>

<p>实验内容</p>

<p>利用运算器实验，存储系统实验中构建的运算器、寄存器文件、存储系统等部件以及 Logisim 中其它功能部件，构建一个32位 MIPS CPU 单周期处理器。数据通路如下图所示：</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201113180337561.png" alt="image-20201113180337561" /></p>

<blockquote>
  <p>1) 立即数寻址（immediate addressing），操作数是位于指令自身中的常数。</p>

  <p>2) 寄存器寻址（register addressing），操作数是寄存器。</p>

  <p>3) 基址寻址(base addressing)或偏移寻址( displacement addressing），操作数在内存中，其地址是指令中基址寄存器和常数的和。</p>

  <p>4) PC相对寻址（PC-relative addressing），地址是PC和指令中常数的和。</p>

  <p>5) 伪直接寻址（pseudodirect addressing），跳转地址由指令中26位字段和PC高位相连而成。116硬件/软件接口　虽然我们把MIPS系统结构按32位地址描述，但是几乎所有的微处理器(包括MIPS)都能进行64位地址扩展(见附录E和2.18节)。这些扩展主要是针对大型程序的需要。指令集的扩展使得体系结构发展的同时，保持软件和下一代体系结构的向上兼容性。</p>
</blockquote>

<p>要求支持8条 MIPS 核心指令，最终设计实现的 MIPS 处理器能运行实验包中的冒泡排序测试程序 sort.asm，该程序自动在数据存储器0~15号字单元中写入16个数据，然后利用冒泡排序将数据升序排序，要求统计指令条数与 MARS 中的指令统计数目进行对比。</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201113180401322.png" alt="image-20201113180401322" /></p>

<p><strong>电路框架</strong></p>

<table>
  <thead>
    <tr>
      <th>信号</th>
      <th>输入/输出</th>
      <th>位宽</th>
      <th>功能描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CLK</td>
      <td>输入</td>
      <td>1</td>
      <td>时钟信号</td>
    </tr>
    <tr>
      <td>PC</td>
      <td>输出</td>
      <td>32</td>
      <td>程序寄存器的值</td>
    </tr>
    <tr>
      <td>IR</td>
      <td>输出</td>
      <td>32</td>
      <td>当前指令字</td>
    </tr>
    <tr>
      <td>RegWrite</td>
      <td>输出</td>
      <td>1</td>
      <td>寄存器文件写使能控制信号</td>
    </tr>
    <tr>
      <td>RDin</td>
      <td>输出</td>
      <td>32</td>
      <td>寄存器文件写入端口的数据</td>
    </tr>
    <tr>
      <td>MemWrite</td>
      <td>输出</td>
      <td>1</td>
      <td>存储器写使能控制信号</td>
    </tr>
    <tr>
      <td>MDin</td>
      <td>输出</td>
      <td>32</td>
      <td>存储器写入端口的数据|</td>
    </tr>
  </tbody>
</table>

<p>完成设计后，加载 sort.hex 程序，测试排序功能。</p>

<p>Mem[PC++] -&gt; IR 即 PC++ 是每次加上一条指令的长度。32 位，因此此处为 PC + 4。</p>

<p>1、首先完成 PC 的 +4。是由于 32 位 MIPS 机中所有指令字长均为 4 字节，每条指令在存储器中占用 4 字节的存储单元。而 <strong>PC 中存放的地址是 字节地址</strong>（PC为 32 位，即存放一个表明 一个字节 的地址）。</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201114104004327.png" alt="image-20201114104004327" /></p>

<p>而<strong>指令存储器存放的是 字地址</strong>。因此要取出低两位。而长度为 10 位（ROM 定下的），因此取 2-11 位。</p>

<p>R型（Register）指的是寄存器型，I型（Immediate）指的是立即数型，J型（Jump）指的是无条件转移型。</p>

<p>现在对于各个指令进行分析</p>

<h4 id="1r-型">1、R 型</h4>

<p><strong>1、add 指令</strong></p>

<ul>
  <li><strong>无间址周期</strong></li>
</ul>

<p><img src="https://lyxf2000-1259802619.cos.ap-beijing.myqcloud.com/20200210124601.png" alt="无间址周期" /></p>

<p>为 R 型指令， 建立过程如下</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116160122062.png" alt="image-20201116160122062" /></p>

<p><strong>2、SLT指令</strong></p>

<p>如果R2的值小于R3，那么设置R1的值为1，否则设置R1的值为0  SLT R1,R2,R3</p>

<p><img src="https://lyxf2000-1259802619.cos.ap-beijing.myqcloud.com/20200210124531.png" alt="SLT指令" /></p>

<p>若为 STL， 那么会在 ALU 进行运算，由于 单周期控制器的 MemToReg（写入寄存器的数据来自存储器即 LW 指令特有） 会为 0 ，因此选择 ALU 判断后的结果，写入到 Din，即 R[rd] 中</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116162636099.png" alt="image-20201116162636099" /></p>

<h4 id="2i-型">2、I 型</h4>

<p><strong>1、addi 指令</strong></p>

<p>ADDI  把一个寄存器的内容加上一个立即数  ADDI R1,R2,#3</p>

<ul>
  <li><strong>无间址周期</strong></li>
</ul>

<p><img src="https://lyxf2000-1259802619.cos.ap-beijing.myqcloud.com/20200210124545.png" alt="无间址周期" /></p>

<p>为 I 型指令，而立即数为 16 位，因此需要扩展</p>

<p><strong>扩展选择符号扩展</strong></p>

<p>addi $s1, $s2, 100 —-»&gt;  $s1 = $s2 + 100</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116163736464.png" alt="image-20201116163736464" /></p>

<p><strong>2、LW</strong></p>

<p><strong>从存储器中</strong>读取一个字的数据到寄存器中  LW R1, 0(R2)</p>

<p>MIPS 的仿存指令属于 I 型指令，访存地址 等于 变址寄存器 $rs 的值 加上 16 位立即数。</p>

<ul>
  <li><strong>基址寻址</strong></li>
</ul>

<p><img src="https://lyxf2000-1259802619.cos.ap-beijing.myqcloud.com/20200210124413.png" alt="基址寻址" /></p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116163812207.png" alt="image-20201116163812207" /></p>

<p>而 MemToReg 用于选择是否是从存储器中读出。</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116162636099.png" alt="image-20201116162636099" /></p>

<p><strong>3、SW</strong></p>

<p>把一个字的数据从寄存器存储到存储器中  SW R1, 0(R2)</p>

<ul>
  <li><strong>基址寻址</strong></li>
</ul>

<p><img src="https://lyxf2000-1259802619.cos.ap-beijing.myqcloud.com/20200210124423.png" alt="" /></p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116164109047.png" alt="image-20201116164109047" /></p>

<p>实现如图</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116164516605.png" alt="image-20201116164516605" /></p>

<p><strong>3、Beq</strong></p>

<p>数据跳转指令，标志寄存器中Z标志位等于零时, 跳转到BEQ后标签处</p>

<ul>
  <li><strong>PC相对寻址</strong></li>
</ul>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116165002779.png" alt="image-20201116165002779" /></p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116165011352.png" alt="image-20201116165011352" /></p>

<blockquote>
  <p>Q:  此处为何要移位？</p>

  <p>A:  立即数中的地址表示是<strong>按字来算</strong>的，对于按字节编址的存储器来说（1字-&gt;4字节）需要乘4
 当然如果你的存储器是按字编址就不需要乘4或左移2位了</p>
</blockquote>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116175812867.png" alt="image-20201116175812867" /></p>

<p><strong>4、bne</strong></p>

<p>数据跳转指令，标志寄存器中Z标志位不等于零时, 跳转到BNE后标签处</p>

<p><img src="https://lyxf2000-1259802619.cos.ap-beijing.myqcloud.com/20200210124522.png" alt="" /></p>

<p><strong>5、Bne</strong></p>

<p>同理，取反就行</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116170235192.png" alt="image-20201116170235192" /></p>

<h4 id="3syscall">3、Syscall</h4>

<ul>
  <li><strong>无间址周期</strong></li>
</ul>

<p><img src="https://lyxf2000-1259802619.cos.ap-beijing.myqcloud.com/20200210124633.png" alt="" /></p>

<p>由于此处作用为 <strong>停机信号</strong>，且 <strong>单周期布线控制器</strong> 专门有一个引脚为 Halt，因此直接调用即可，连接至 PC 的使能信号处。</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116170819620.png" alt="image-20201116170819620" /></p>

<p>补充一点，这里的停机是靠位于左上方的计数器，计算周期数。在计数器中设置最大值为224，当周期达到224时即可停机。</p>

<p>电路实现如下</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116183929700.png" alt="image-20201116183929700" /></p>

<p>一定要记住！！！！</p>

<ul>
  <li>16-&gt;32 扩展选择符号扩展</li>
  <li>将上面的 PC、IR…啥的进行连接，方便检测。</li>
</ul>

<h3 id="二单周期硬布线控制器">二、单周期硬布线控制器</h3>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116162940783.png" alt="image-20201116162940783" /></p>

<p>该实验只涉及 8 条核心的 MIPS 指令。而这 8 条MIPS指令的指令字段已经在附件中给出（关于MIPS指令字段可参考我另一篇关于单总线定长&amp;变长的博客   <a href="http://husharp.today/2020/10/19/hust-cpu-study_3/#2mips-ram%E8%AE%BE%E8%AE%A1">biubiu传送门</a>  ），并且电路底部文字也给出了关于<em>SYSCALL</em>的提示，因此，这部分只需根据相应的<em>OP</em>和<em>FUNC</em>字段进行简单地逻辑比较就可实现。</p>

<p>电路实现如下</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116174057681.png" alt="image-20201116174057681" /></p>

<p>且打开存储器，发现完成排序</p>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201116232156005.png" alt="image-20201116232156005" /></p>

<p>MIPS 寄存器文件中 0 号寄存器的值恒零</p>

<p><a href="http://husharp.today/2020/10/19/hust-cpu-study_3/#2mips-ram%E8%AE%BE%E8%AE%A1">寄存器看这篇文章</a></p>

<h3 id="三mips-微程序-cpu-设计">三、MIPS 微程序 CPU 设计</h3>

<p><img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201118195644099.png" alt="image-20201118195644099" />
<img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201118195630789.png" alt="image-20201118195630789" />
<img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201118200536417.png" alt="image-20201118200536417" />
<img src="/assets/blog_image/2020-11-13-hust-cpu-study_4/image-20201118200046464.png" alt="image-20201118200046464" /></p>]]></content><author><name></name></author><category term="principle" /></entry><entry><title type="html">自己动手画 CPU《计算机组织与结构实验》（三）</title><link href="http://localhost:4000/principle/2020/10/19/hust-cpu-study_3.html" rel="alternate" type="text/html" title="自己动手画 CPU《计算机组织与结构实验》（三）" /><published>2020-10-19T10:58:32+08:00</published><updated>2020-10-19T10:58:32+08:00</updated><id>http://localhost:4000/principle/2020/10/19/hust-cpu-study_3</id><content type="html" xml:base="http://localhost:4000/principle/2020/10/19/hust-cpu-study_3.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#三存储系统设计" id="markdown-toc-三存储系统设计">三、存储系统设计</a>    <ul>
      <li><a href="#1汉字字库存储芯片扩展实验" id="markdown-toc-1汉字字库存储芯片扩展实验">1、汉字字库存储芯片扩展实验</a>        <ul>
          <li><a href="#综合举例" id="markdown-toc-综合举例">综合举例</a></li>
        </ul>
      </li>
      <li><a href="#2mips-ram-设计" id="markdown-toc-2mips-ram-设计">2、MIPS RAM 设计</a>        <ul>
          <li><a href="#1load" id="markdown-toc-1load">1、load</a></li>
          <li><a href="#2写入-store" id="markdown-toc-2写入-store">2、写入 store</a>            <ul>
              <li><a href="#1wi-是否选择该组件" id="markdown-toc-1wi-是否选择该组件">1、wi 是否选择该组件</a></li>
              <li><a href="#2di-表示此时选择该组件输入时写入的数据" id="markdown-toc-2di-表示此时选择该组件输入时写入的数据">2、di 表示此时选择该组件输入时写入的数据</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#3mips-寄存器文件设计" id="markdown-toc-3mips-寄存器文件设计">3、MIPS 寄存器文件设计</a></li>
      <li><a href="#4直接相联-cache-设计" id="markdown-toc-4直接相联-cache-设计">4、直接相联 Cache 设计</a>        <ul>
          <li><a href="#1直接相联介绍" id="markdown-toc-1直接相联介绍">1.直接相联介绍</a></li>
          <li><a href="#2实验步骤" id="markdown-toc-2实验步骤">2.实验步骤</a></li>
          <li><a href="#3直接相联特点" id="markdown-toc-3直接相联特点">3.直接相联特点</a></li>
        </ul>
      </li>
      <li><a href="#5全相联-cache-设计" id="markdown-toc-5全相联-cache-设计">5、全相联 Cache 设计</a>        <ul>
          <li><a href="#1全相联介绍" id="markdown-toc-1全相联介绍">1.全相联介绍</a></li>
          <li><a href="#2实验步骤-1" id="markdown-toc-2实验步骤-1">2.实验步骤</a></li>
          <li><a href="#3全相联特点" id="markdown-toc-3全相联特点">3.全相联特点</a></li>
        </ul>
      </li>
      <li><a href="#64-路组相联-cache-设计" id="markdown-toc-64-路组相联-cache-设计">6、4 路组相联 Cache 设计</a>        <ul>
          <li><a href="#1组相联介绍" id="markdown-toc-1组相联介绍">1.组相联介绍</a></li>
          <li><a href="#2实验步骤-2" id="markdown-toc-2实验步骤-2">2.实验步骤</a></li>
        </ul>
      </li>
      <li><a href="#72-路组相联-cache-设计" id="markdown-toc-72-路组相联-cache-设计">7、2 路组相联 Cache 设计</a>        <ul>
          <li><a href="#2实验步骤-3" id="markdown-toc-2实验步骤-3">2.实验步骤</a></li>
          <li><a href="#3组相联特点" id="markdown-toc-3组相联特点">3.组相联特点</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><a href="https://www.icourse163.org/course/HUST-1205809816">配套慕课</a></p>

<h2 id="三存储系统设计">三、存储系统设计</h2>

<h3 id="1汉字字库存储芯片扩展实验">1、汉字字库存储芯片扩展实验</h3>

<p><strong>实验目的</strong></p>

<p>理解存储系统进行位扩展、字扩展的基本原理，能利用相关原理解决实验中汉字字库的存储扩展问题，并能够使用正确的字库数据填充。</p>

<p><strong>电路引脚</strong></p>

<table>
  <thead>
    <tr>
      <th>信号</th>
      <th>输入/输出</th>
      <th>位宽</th>
      <th>说明</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>区号Qu</td>
      <td>输入</td>
      <td>7 位</td>
      <td>汉字区位码的区号</td>
    </tr>
    <tr>
      <td>位号Wei</td>
      <td>输入</td>
      <td>7 位</td>
      <td>汉字区位码的位号</td>
    </tr>
    <tr>
      <td>Di</td>
      <td>输出</td>
      <td>32 位</td>
      <td>汉字点阵信息</td>
    </tr>
  </tbody>
</table>

<p>汉字点阵为16*16位。需要8片16K32位ROM来存储点阵信息。</p>

<p>我们需要用 4 片 4 K 32 位 ROM代替其中一片 16 K 32 位ROM。</p>

<p>4K需要12根地址线，16K需要14根地址线。所以高位多余的两位作为片选信号。</p>

<p>我们需要一个数据选择器，来进行选择输出那一片ROM中的数据。</p>

<p>再根据数据进行分析，数据的最后两位是选片区的。所以将最后两位直接输入到选择器选择短。</p>

<p>最后将数据对应连接，及可得到电路。</p>

<p>参考字库采用 8 片 16 K 32 位 ROM 来存储点阵信息。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201025214905314.png" alt="image-20201025214905314" /></p>

<p>主要扩展方法：<strong>字扩展、位扩展、字位扩展</strong></p>

<p>设存储空间为 M <strong>*** N 位，M 表示 M 根地址线，N 表示 N 根数据线。现有存储芯片是 m **</strong>* n 位。</p>

<p>若 M=m ，N&gt;n，需要对芯片进行 位扩展。（数据线扩展，字长扩展）</p>

<p>若 M&gt;m，N=n，需要对芯片进行 字扩展。 （地址线扩展， 字数扩展)</p>

<p>若 M&gt;m，N&gt;n，需要对芯片进行 字位扩展。</p>

<p>1、位扩展时：当 CPU 给出一个地址访问存储系统时，该地址被送入到所有的存储芯片中，所有芯片并发的工作，并提供各自的 2 位信息。</p>

<p>2、字扩展时：当 CPU 给出一个地址访问存储系统时，只有一个存储芯片工作，具体哪个芯片工作由存储系统地址高 2 位来决定。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026000344201.png" alt="image-20201026000344201" /></p>

<p>由于此处是 4 片 4 K 32 位 ROM 代替其中 1 片 16 K 32 位ROM，因此需要采用字扩展。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201025215007703.png" alt="image-20201025215007703" /></p>

<p>4 个 4K 变为 1 个 16K，需要的是串行输出某个指定的 ROM，因此通过一个多路选择器，来进行选择输出那一片ROM中的数据。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026000446620.png" alt="字扩展图示" /></p>

<p>下图易发现，片选选择相应的 ROM。其余 12 位都输入一样的结果。在 7 片位扩展的 ROM 组中，并行计算，各自给出自身 ROM 中的相应数值，再拼凑起来。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201025223205311.png" alt="image-20201025223205311" /></p>

<p>组合好电路之后，将示例中的 ROM 中的数据分别放到指定位置。值得注意的是：</p>

<p>0000-0ff0</p>

<p>1000-1ff0</p>

<p>2000-2ff0</p>

<p>3000-3ff0</p>

<p>分别为第一片 ROM 到 第四片的数据，依次复制到对应ROM中，即可展开测试。</p>

<h4 id="综合举例">综合举例</h4>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026001646966.png" alt="image-20201026001646966" /></p>

<p>因此由主存地址可知：</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026001706790.png" alt="image-20201026001706790" /></p>

<p>下面对几个情况进行图示：</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026002044431.png" alt="image-20201026002044431" /></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026002057406.png" alt="image-20201026002057406" /></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026002105891.png" alt="image-20201026002105891" /></p>

<h3 id="2mips-ram-设计">2、MIPS RAM 设计</h3>

<p><strong>实验内容</strong></p>

<p>Logisim 中 RAM 组件只能提供固定的地址位宽，数据输出也只能提供固定的数据位宽，访问时无法同时支持字节/半字/字三种访问模式，实验要求利用4个8位的 RAM 组件进行扩展，设计完成既能按照8位、也能按16位、也能按照32位进行读写访问的32位存储器，最终存储器引脚定义如下表。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201114103508715.png" alt="image-20201114103508715" /></p>

<p><strong>电路引脚</strong></p>

<table>
  <thead>
    <tr>
      <th>信号</th>
      <th>输入/输出</th>
      <th>位宽</th>
      <th>功能描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Addr</td>
      <td>输入</td>
      <td>12</td>
      <td>字节地址输入（字访问时忽略最低两位，半字访问时忽略最低位，倒数第二位片选，字节访问时，低两位进行片选）</td>
    </tr>
    <tr>
      <td>Din</td>
      <td>输入</td>
      <td>32</td>
      <td>写入数据 （不同访问模式有效数据均存放在最低位，高位忽略</td>
    </tr>
    <tr>
      <td>Mode</td>
      <td>输入</td>
      <td>2</td>
      <td>访问模式控制位（00 表示字访问，01 表示 1 字节访问，10 表示 2 字节访问）</td>
    </tr>
    <tr>
      <td>WE</td>
      <td>输入</td>
      <td>1</td>
      <td>写使能，1 表示写入，0 表示读出</td>
    </tr>
    <tr>
      <td>Dout</td>
      <td>输出</td>
      <td>32</td>
      <td>读出数据 （不同访问模式有效数据均存放在最低位，高位补零）；</td>
    </tr>
  </tbody>
</table>

<p>该实验需要完成既能按照8位、也能按16位、也能按照32位进行读写访问的32位存储器。如下图在不同要求时进行不同 byte 的选择。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201025233636222.png" alt="image-20201025233636222" /></p>

<p>现在开始实验的分析</p>

<ul>
  <li>字地址，也就是 32 位地址，由 4 个字节组成，因此按字节编址的话，地址末尾一定是00。而半字地址，末尾一定是0。本实验的输入没有做严格限定，要求我们相应MODE下对地址进行对齐。</li>
  <li>load 信号一直有效，而写信号只有当 WE=1时才有效。</li>
  <li>32位数据由 四片 RAM 并行工作给出，16位选高两片或低两片，8位则只需1片 RAM 工作。</li>
  <li>给出的地址是字节地址，因此为了选中相应的 RAM ，需要取出后两位判断；为了取出相应的半字，需要对第二低位进行判断。</li>
  <li>送入写入端的数据，根据 MODE 和 Din 的相关位生成</li>
</ul>

<p>首先实现大框架展示</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027160104632.png" alt="image-20201027160104632" /></p>

<p>str信号由各 RAM 的 WE 信号 和 wi 信号 相与给出，表示仅当写模式下，且该 RAM 需要参与写时才有效。输入数据和输出数据分别由相应的通道给出，方便后续控制。</p>

<p>wi 表示此时是否选择该组件写入。di 表示此时选择该组件输入时写入的数据。</p>

<p>sel 为0 禁用组件，因此置为 1 或者 悬空都可。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026163742613.png" alt="image-20201026163742613" /></p>

<h4 id="1load">1、load</h4>

<p>首先说明当为 load 时，如何读出。</p>

<p>最简单的就是字读出，当模式为字读出时，直接输出全部数据即可。</p>

<p>半字读出时，我们由<strong>字节地址第二低位</strong>来决定输出哪个半字。</p>

<p>字节读出时，我们由<strong>字节地址低两位</strong>来决定输出哪个字节。0 表示 01 位、1 表示 23 位。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027155851848.png" alt="image-20201027155851848" /></p>

<h4 id="2写入-store">2、写入 store</h4>

<p>由之前的框架图</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027160104632.png" alt="image-20201027160104632" /></p>

<p>可知：</p>

<ul>
  <li>str 信号由各 RAM 的 WE 信号 和 wi 信号 相与给出，表示仅当写模式下，且该 RAM 需要参与写时才有效。输入数据和输出数据分别由相应的通道给出，方便后续控制。</li>
  <li>wi 表示此时是否选择该组件写入。di 表示此时选择该组件输入时写入的数据。</li>
</ul>

<h5 id="1wi-是否选择该组件">1、wi 是否选择该组件</h5>

<p>考虑一下什么情况下这个 RAM 需要写入数据。</p>

<ul>
  <li>字 00 写入时肯定所有 RAM  都要写入；</li>
  <li>半字 10 写入时，只有当前片被选中才需要写入；</li>
  <li>单字节 01 写入时，只有指定了当前片才需要写入。</li>
  <li>现在通过 mode 的译码器，作为 模式 的选择
<img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027163328146.png" alt="image-20201027163328146" /></li>
</ul>

<p>于是可以构造以下的电路：</p>

<p>当 mode = 00 时，<strong>所有片选信号都要为真</strong>，进行写入</p>

<p>当 mode = 01 时，字节地址最低两位 和 所选择的 RAM 编号相一致时，进行写入。</p>

<p>当 mode = 10 时，字节地址的倒数第二低的一位来决定选择哪两片。<strong>当这一位等于0，应该选择01号组合，否则选择23号组合。</strong></p>

<ul>
  <li>因此值得注意的是，在mode 为 10 时，在 RAM 编号为 0、1时需要取反。（理由如上）</li>
</ul>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027162434784.png" alt="image-20201027162434784" /></p>

<h5 id="2di-表示此时选择该组件输入时写入的数据">2、di 表示此时选择该组件输入时写入的数据</h5>

<p>di 的输入取决于 mode 的输入，然后对 Din 值进行选择。</p>

<p>如果 mode 为 字 写入（00），从 d0-d3 分别输入 0-7,8-15,16-23,24-31 位数据。</p>

<p>如果 mode 为 字节 写入（01），会写入 Din 的 0-7 位数据，所以我们将 d0-d3 都输入 0-7 位数据。至于选哪片RAM 写入，由写的片选信号决定。</p>

<p>如果 mode 位 半字 写入（10），会写入 Din 的 0-15 位数据，<strong>因为我们必须实现对齐，所以无论是01号组合，还是23号组合，较低编号一定存放低位数据，反之存放高位数据，所以d0，d2输入0-7位数据，d1，d3输入8-15位数据。</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027141838567.png" alt="image-20201027141838567" /></p>

<p>注意 可结合大端小端进行深入思考</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201026164004881.png" alt="image-20201026164004881" /></p>

<p>但是无论大端小端，每个系统的内部是一致的，但在系统间进行通信时，会发生问题。因此需要进行顺序的转换。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027163740120.png" alt="image-20201027163740120" /></p>

<p>最终电路实现如下</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027163433379.png" alt="image-20201027163433379" /></p>

<h3 id="3mips-寄存器文件设计">3、MIPS 寄存器文件设计</h3>

<p><strong>实验目的</strong></p>

<p>利用 Logisim 平台构建一个简化的 MIPS 寄存器文件，内部包含4个32位寄存器，其具体引脚与功能描述如下表。</p>

<p><strong>引脚介绍</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027164339797.png" alt="image-20201027164339797" /></p>

<table>
  <thead>
    <tr>
      <th>信号</th>
      <th>输入/输出</th>
      <th>位宽</th>
      <th>功能描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>R1#</td>
      <td>输入</td>
      <td>5</td>
      <td>第 1 个读寄存器的编号</td>
    </tr>
    <tr>
      <td>R2#</td>
      <td>输入</td>
      <td>5</td>
      <td>第 2 个读寄存器的编号</td>
    </tr>
    <tr>
      <td>W#</td>
      <td>输入</td>
      <td>5</td>
      <td>写入寄存器编号</td>
    </tr>
    <tr>
      <td>Din</td>
      <td>输入</td>
      <td>32</td>
      <td>写入数据</td>
    </tr>
    <tr>
      <td>WE</td>
      <td>输入</td>
      <td>1</td>
      <td>写使能信号，为 1 时在 CLK 上跳沿将 Din 数据写入W#寄存器</td>
    </tr>
    <tr>
      <td>CLK</td>
      <td>输入</td>
      <td>1</td>
      <td>时钟信号，上跳沿有效</td>
    </tr>
    <tr>
      <td>RD1</td>
      <td>输出</td>
      <td>32</td>
      <td>R1# 寄存器的值，MIPS 寄存器文件中 0 号寄存器的值恒零</td>
    </tr>
    <tr>
      <td>RD2</td>
      <td>输出</td>
      <td>32</td>
      <td>R2# 寄存器的值，MIPS 寄存器文件中 0 号寄存器的值恒零</td>
    </tr>
  </tbody>
</table>

<p>注意R1#R2#W#，为了简化，只有 2 位位宽，这样便可以在 0-3 号寄存器中选择。其中 0 号寄存器的值恒零。</p>

<p>首先实现读逻辑。</p>

<p>R1# 和 R2# 为两位位宽，设置数据选择器的位宽为两位。这样就可以通过 R1# 和 R2# 决定 RD1 和 RD2 取指定编号寄存器中的值。</p>

<p>如：R1#：10 表示 2 号寄存器</p>

<p>每个寄存器连接上对应输出，把输出接到上面的两个数据选择器的数据输入端即可。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027171000230.png" alt="image-20201027171000230" /></p>

<p>接下来实现写逻辑。</p>

<p>一共有 4 个寄存器，所以通过译码器，将 W# 转换为4个片选信号。分别表示 0-3 号寄存器。</p>

<p>当 WE 为1时，表示可以写入数据。所以将片选信号和 WE 用与门连接。</p>

<p>最后将数据输入对应，即可得到电路。</p>

<p>另外，要注意0号寄存器要保持恒零，所以数据输入也要为零。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201027171429856.png" alt="image-20201027171429856" /></p>

<p><strong>直接相联、组相联、全相联直观区别：</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030200000923.png" alt="image-20201030200000923" /></p>

<h3 id="4直接相联-cache-设计">4、直接相联 Cache 设计</h3>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201028193911150.png" alt="image-20201028193911150" /></p>

<p>上图给出了一个在 Logisim 中设计完成的 cache 系统自动测试电路，为简化实验设计，这里所有 cache 模块均为只读  cache（类似指令 cache），无写入机制。电路左侧计数器与存储器部分会在时钟驱动下逐一生成地址访问序列给 cache  模块。计数器模块的使能端受命中信号驱动，缺失时使能端无效，计数器不计数，等待系统将待请求数据所在块从二级存储器中调度到 cache  后才能继续计数。cache 与二级存储器之间通过块交换逻辑实现数据块交换，由于二级存储器相比 cache  慢很多，所以一次块交换需要多个时钟周期才能完成，cache 模块判断数据块准备好的逻辑是 blkready  信号有效，该信号有效且时钟到来时，cache 将块数据从 BlkDin 端口一次性载入到对应 cache 行缓冲区中，此时 cache  数据命中，直接输出请求数据，解锁计数器使能端，继续访问下一个地址。</p>

<p>电路引脚</p>

<table>
  <thead>
    <tr>
      <th>信号</th>
      <th>输入/输出</th>
      <th>位宽</th>
      <th>功能描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Addr</td>
      <td>输入</td>
      <td>16</td>
      <td>主存地址</td>
    </tr>
    <tr>
      <td>BlkDataIn</td>
      <td>输入</td>
      <td>32</td>
      <td>块数据输入</td>
    </tr>
    <tr>
      <td>BlkDataReady</td>
      <td>输入</td>
      <td>1</td>
      <td>块数据准备就绪</td>
    </tr>
    <tr>
      <td>CLK</td>
      <td>输入</td>
      <td>1</td>
      <td>时钟输入</td>
    </tr>
    <tr>
      <td>Miss</td>
      <td>输出</td>
      <td>1</td>
      <td>1：数据缺失；0：数据命中</td>
    </tr>
    <tr>
      <td>DataOut</td>
      <td>输出</td>
      <td>8</td>
      <td>数据输出</td>
    </tr>
  </tbody>
</table>

<h4 id="1直接相联介绍">1.直接相联介绍</h4>

<p>块映射速度快 ，一对映射 一对映射 ，无须查表 无须查表</p>

<ul>
  <li>利用索引字段直接对比相应标记位即可</li>
  <li>查找表可以和副本一起存放 ，无需相联存储器</li>
</ul>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029200915836.png" alt="image-20201029200915836" /></p>

<p>如下图所示：</p>

<p>直接相联只用设计：字节地址和cache槽的设计、写入和写出设计、比较设计。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029200933511.png" alt="image-20201029200933511" /></p>

<h4 id="2实验步骤">2.实验步骤</h4>

<p><strong>1、字节地址设计</strong></p>

<p>由下图可知，输入到 直接相联映射的 Cache 槽前半部分（主存地址）为 16 位，直接映射分为 块 + 行 + 块内字节偏移</p>

<p>而 共要设计 8 块 Cache 槽，2^3 = 8，即  行占 3 位</p>

<p>又因为块数据输入为 32 位 即 4 字节，而由于输出 Dataout 为 8 位，即按照 字节 进行输出，因此 行内字节偏移 在 Cache  槽中占 2 位。</p>

<p>其余 11 位全部作为区号 tag</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029203316538.png" alt="image-20201029203316538" /></p>

<p>先将主存地址进行分割，作为 Cache 槽的前半部分。</p>

<p><strong>2、Cache槽的设计</strong></p>

<p>现在开始设计 Cache 槽。<em>cache</em>  主要包含四部分：Valid标志、主存 Tag 标记位、淘汰计数标记、数据副本。而我们需要考虑的是前三部分（直接相联没有淘汰计数，直接覆盖之前的 mod 数据），并且这三部分和之后的设计息息相关。</p>

<ul>
  <li>当中 valid 位有效位，判断该 cache 槽是否被命中过，存入了数据；</li>
  <li>Tag 位是存入的主存标记位；</li>
</ul>

<blockquote>
  <p>注意：三态门</p>

  <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029210052306.png" alt="image-20201029210052306" /><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029210032827.png" alt="image-20201029205946214" /><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029205954527.png" alt="image-20201029205954527" /><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029210008479.png" alt="image-20201029210008479" /></p>
</blockquote>

<p><strong>3、Cache 槽号译码器选择相应行</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029212251678.png" alt="image-20201029212251678" /></p>

<p><strong>4、首先完成判断是否命中</strong></p>

<p>通过有效位的判断 和 标志位（即此处的区号）判断，来进行 HIT 和 MISS 的判断。也就是说，只有当前组（块映射的Cache槽组） 和 当前行 同时被选中时，才能判断 HIT。</p>

<p>值得注意的是，<strong>此处三态门全部由 行选信号进行判断。</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029212547531.png" alt="image-20201029212547531" /></p>

<p><strong>5、若未命中，需要进行读入数据</strong></p>

<p>写入设计则要当 <em>BlkReady</em> 数据准备完成时（测试电路中的数据准备）选择具体的 cache 行进行写入，而写入的前提是该行为空，即 <em>Miss</em> 信号有效，才能写入数据。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029215138264.png" alt="image-20201029215138264" /></p>

<p><strong>6、选择 Cache 槽中数据行对应字节</strong></p>

<p>最后选择 SlotData 的 数据行中，根据行中偏移地址 offset 选出4 个字节中所需的一个。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029220202056.png" alt="image-20201029220202056" /></p>

<p>HIT 作为 命中判断，若没有命中，就不会选出。</p>

<p><strong>遇到问题</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201029232824036.png" alt="image-20201029232824036" />
预期和我的实际输出不同在于，缺失后，从二级存储器载入数据后，本来此时 blkok 信号应该为0，但是现在为什么还是显示 块数据 blkok为 1啊？</p>

<p><strong>经过 8 小时的探寻，终于找到问题!!!</strong></p>

<p>寄存器的触发方式分为上升沿、下降沿、高电平、低电平。</p>

<ul>
  <li>上升沿 ： 当时钟信号从 0 到 1 变化时，寄存器更新其值</li>
  <li>下降沿 ： 当时钟信号从 1 到 0 变化时，寄存器更新其值</li>
  <li>高电平：当时钟信号为 1 时，寄存器不断更新其值</li>
  <li>低电平：当时钟信号为 0 时，寄存器不断更新其值</li>
</ul>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030194518157-1604071290959.png" alt="image-20201030194518157" /></p>

<p>而由于此处的自动测试电路中，所有的计数器、寄存器全为 上升沿，因此应当将 直接相联 中的 寄存器也改为 上升沿！</p>

<p><strong>最终完成电路</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030205604127.png" alt="image-20201030205604127" /></p>

<p>最终成果展示</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031130225746.png" alt="image-20201031130225746" /></p>

<h4 id="3直接相联特点">3.直接相联特点</h4>

<ul>
  <li>块映射速度快 ，一对一映射， 无须查表
    <ul>
      <li>利用索引字段直接对比相应标记位即可</li>
      <li>查找表可以和副本一起存放 ，无需相联存储器</li>
    </ul>
  </li>
  <li>cache 容易冲突 ，cache利用率低</li>
  <li>淘汰算法简单</li>
  <li>命中率低 ，适合大容量 cache</li>
</ul>

<h3 id="5全相联-cache-设计">5、全相联 Cache 设计</h3>

<h4 id="1全相联介绍">1.全相联介绍</h4>

<p>全相联映射是主存地址随机存储在<strong>任意的<em>cache</em>行</strong>，也就是只要是空行就可以进行存储，没有选择。然后通过标记位地址与8个<em>cache</em>槽中的标记位进行比较，判断是否命中，选择具体的1个<em>cache</em>槽；再通字内偏移地址，选择该<em>cache</em>槽中的单个字节来进行写入和写出的操作。</p>

<p>全相联映射需要做好淘汰算法。此处采用 LRU ：数据淘汰时，应采用 LRU 计数器值最大的 Cache 行 进行淘汰。为提升速度，需要若干个比较器并发比较。</p>

<p>Cache 分为 CAM 和 SRAM 两部分。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030195520348.png" alt="image-20201030195520348" /></p>

<p>字节地址和cache槽的设计、写入和写出设计、比较设计、淘汰算法设计。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030200919012.png" alt="image-20201030200919012" /></p>

<h4 id="2实验步骤-1">2.实验步骤</h4>

<p><strong>1、字节地址设计</strong></p>

<p>由下图可知，输入到 全相联映射的 Cache 槽前半部分（主存地址）为 16 位，直接映射分为 标志位 + 块内字节偏移</p>

<p>因为块数据输入为 32 位 即 4 字节，而由于输出 Dataout 为 8 位，即按照 字节 进行输出，因此 行内字节偏移 在 Cache  槽中占 2 位。</p>

<p>其余 14 位全部作为区号 tag</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030202249341.png" alt="image-20201030202249341" /></p>

<p>先将主存地址进行分割，作为 Cache 槽的前半部分。</p>

<p><strong>2、Cache槽的设计</strong></p>

<p>现在开始设计 Cache 槽。<em>cache</em>  主要包含四部分：Valid标志、主存 Tag 标记位、淘汰计数标记、数据副本。而我们需要考虑的主要是前三部分，并且这三部分和之后的设计息息相关。</p>

<ul>
  <li>当中 valid 位有效位，判断该 cache 槽是否被命中过，存入了数据；</li>
  <li>Tag 位是存入的主存标记位；</li>
  <li><strong>淘汰计数是一个计数器</strong>，初值为0，若行命中标志 Li 有效时，读入数据 0，达到清零的效果，若Li无效，则随着时钟频率一直进行计数。（与后面的淘汰算法密切相关）。而数据副本通过三态门缓冲器连接到总结上，这里三态门缓冲器的作用是当Li行有效时，将数据副本中输出的数据进行缓存，也就是使8个chche槽中的数据都可以缓存到1个Solt，这里就实现了总线的作用，十分优化。 这里给出了一个cache槽，其余的进行类似的复制。</li>
</ul>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124014056.png" alt="image-20201031124014056" /></p>

<p><strong>值得注意的是：</strong></p>

<ol>
  <li>
    <p>为什么直接相联映射采用 L0 控制 V0、T0 的三态门，全相联直接输出？</p>

    <p>因为此时 L0 由 V0 和 T0 决定 ，而之前采用的是 Cache 选择控制（直接相联由 字节地址中的 第 2-4 位直接选择 Lx，而全相联需要并发比较各个标志位进行选择），此处为避免死循环，就不采用三态门。</p>
  </li>
  <li>
    <p>计数器的清空设置：</p>

    <p>如下图，当选择该行时，需要将计数器重置。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124750585.png" alt="image-20201031124750585" /></p>
  </li>
</ol>

<p><strong>3、写入和写出设计</strong></p>

<ol>
  <li>
    <p>写出设计即通过字内偏移地址 <em>Offset</em> 进行选择总线 <em>Slot</em> 上的某一字节进行输出。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124922703.png" alt="image-20201031124922703" /></p>
  </li>
  <li>
    <p>写入设计则要当 <em>BlkReady</em> 数据准备完成时（测试电路中的数据准备）选择具体的cache行进行写入，而写入的前提是<strong>该行为空，</strong>即 <em>Miss</em> 信号有效，才能写入数据。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124953354.png" alt="image-20201031124953354" /></p>
  </li>
  <li>
    <p>写入行的判断</p>
    <ul>
      <li>若存在空行，即 <em>FULL</em> 信号无效，则选择相应的空行进行写入；</li>
      <li>若<em>FULL</em>信号有效，则<strong>选择淘汰的行</strong>进行写入。两种情况都为之后的淘汰算法中选出的行号。</li>
    </ul>
  </li>
</ol>

<p><strong>4、判断是否命中。————即比较设计</strong></p>

<p>对于第 3 点的写入写出需要进行判断，即比较设计来判断是否命中。</p>

<p>不同的映射模式最大的区别就在于比较设计上。全相联因为是随机选取的 <em>cache</em> 行进行写入，因此没有行地址（索引），因此直接进行 8 个 <em>cache</em> 槽的<strong>并发比较</strong>，得到命中的<em>cache</em>行<em>Li</em>，并给出<em>Miss</em>和<em>Hit</em>信号。比较方法如图所示。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031125151050.png" alt="image-20201031125151050" /></p>

<p><strong>若命中，那么 HIT 信号为 1 ，则开始上文提到的 SlotData 输出显示。</strong></p>

<p><strong>若没有命中，那么 Miss 变为 1 ，开始进行淘汰算法，来选出相应的行。</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124922703.png" alt="image-20201031124922703" /></p>

<p><strong>5、淘汰算法</strong></p>

<p>淘汰算法分为两个部分，</p>

<ul>
  <li>一个是当存在 cache 槽为空，空行的选择；</li>
  <li>一个是当 cache 槽满时，淘汰行的选择</li>
</ul>

<ol>
  <li>
    <p><strong>槽存在空</strong></p>

    <p>在空行的选择中，通过优先比较器来实现，优先比较器通过比较，<strong>输出的是索引较大的非 0 行</strong>，因此先对所有行的标志位取反，取反后，若为1，则表示该行为空；若为0，则表示该行已经存在数据。若所有行都存在数据则 <em>FULL</em> 行满信号有效。</p>
  </li>
</ol>

<blockquote>
  <p>优先编码器</p>

  <ul>
    <li>当多个引脚同时为 1 时，输出最大的那个编号</li>
    <li>当使能端为</li>
  </ul>

  <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030232110636.png" alt="image-20201030232110636" /></p>

  <p>优先编码器组件还包含一个 使能输入端 和 使能输出端 。</p>

  <ul>
    <li>只要 使能输入端 为 0 ,则该组件处于关闭状态,输出为不确定值。</li>
    <li>当使能输入端为1,且输入引脚都不是1,则使能输出为 1 。
      <ul>
        <li>因此，可以串联两个优先编码器，使第一个编码器的使能输出端连接到第二个编码器的使能输入端。</li>
        <li>如果第一个编码器有任意一个输入引脚值为1,则第二个优先编码器将会被关闭，输出为不确定值。</li>
        <li>当第一个编码器没有引脚输入为1时，其输出为不确定值，此时第二个编
码器将会被开启，并输出最高优先级请求(输入为1)的编号。</li>
        <li>优先编码器的这种设计，可以方便地将多个优先编码器串联起来使用以达到扩充输入的目的。</li>
        <li><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030233136105.png" alt="image-20201030233136105" /></li>
      </ul>
    </li>
    <li>优先级编码器的另外一个输出（右下角）表示优先编码器有输入请求，当优先编码器使能输入为 1 ，且输入引脚中有 1 时，其输出为1。当多个优先编码器串联在一起使用时，这个输出可以用于判断哪个优先编码器被触发。</li>
    <li><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030233127124.png" alt="image-20201030233127124" /></li>
  </ul>
</blockquote>

<p>通过优先编码器选出索引值最大空Cache槽，或者输出 FULL</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031123143625.png" alt="image-20201031123143625" /></p>

<ol>
  <li>
    <p><strong>槽满时</strong></p>

    <p>​在淘汰行的选择中，主要运用到LRU淘汰算法（即最近最少使用淘汰算法），由于我们在 cache 槽设计中的计数器是当行选中时清零，行为选中时随时钟频率进行计数，因此这里计数的最大值即为最少使用的cache槽。 而我们用文件中附带的归并算法，这里的归并算法是输出两个值中较大的一位的数据和索引，最后得到相应的淘汰行。</p>

    <p>​由于是要输出 三位编码，因此选择 MAX3，其内部电路如图所示</p>

    <p>​其中 Y# 是指明 三位长度（12字节）的编号。只是为了后面的译码器根据选出的 三位长度 地址进行位号选择。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201030234059000.png" alt="image-20201030234059000" /></p>

    <p>且由于此处提供的 MAX3 进行比较的数值（ cnt 时钟计数）为 16 字节长度。因此计时器记录为 16位长度。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031123709802.png" alt="image-20201031123709802" /></p>

    <p><strong>并发淘汰比较如下</strong></p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031123157656.png" alt="image-20201031123157656" /></p>
  </li>
</ol>

<p>最终电路实现如下</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031125848931.png" alt="image-20201031125848931" /></p>

<p>最终成果展示</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031130154424.png" alt="image-20201031130154424" /></p>

<h4 id="3全相联特点">3.全相联特点</h4>

<ul>
  <li>块映射灵活 ，一对多映射</li>
  <li>cache全部装满后才会出现块冲突</li>
  <li>块冲突的概率低 ，cache 利用率高</li>
  <li>淘汰算法复杂</li>
  <li>命中率高。</li>
</ul>

<h3 id="64-路组相联-cache-设计">6、4 路组相联 Cache 设计</h3>

<h4 id="1组相联介绍">1.组相联介绍</h4>

<p>​组相联映射是直接相联映射和全相联映射的折中，或者说后两者是前者的特例。Cache 仍然分为 相联存储器CAM 和 SRAM两部分，其中 CAM 用于存放标记信息， SRAM 存放数据副本。 Cache 划分成若干组，每组若干 Cache 行。
   ​主存地址被划分为Tag、index、offset 三部分，由索引字段 index 经过组索引译码器产生组选中译码信号（选组是采用直接映射），CAM 中对应组有效位 和 标记信息 传输到多路并发比较器，每组多少行就需要设置多少个比较器（即组内可以全选）。例如，当前组某行的标记位与主存地址中的标记位相同且有效位为 1 时，则Cache命中。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101211653700.png" alt="image-20201101211653700" /></p>

<p>选组是直接映射，选组内的行是全映射。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101205708957.png" alt="image-20201101205708957" /></p>

<p>将多路并发比较结果信号与组索引译码输出信号分别进行逻辑与后得到 Cache 行选择信号（如下图） 2 路并发比较信号与 4 根组索引译码输出信号分别进行逻辑与后得到 8 根行选择信号。Cache 行选中后,读写逻辑和其他映射方式基本一致。数据淘汰时,应该在指定的组内寻找 LRU 计数器值最大的 Cache 行进行淘汰。组相联映射与全相联映射相比，其多路比较器的复杂度更低。</p>

<p>当每组只有一个Cache行时,只需要一个比较器,电路演变成直接相联映射。当整个Cache只有二组时,无须组索引译码器,电路演变成全相联映射。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101205807648.png" alt="image-20201101205807648" /></p>

<p>现在来说说 4 路组相联。k 路取决于每一组中有多少行。此处便是一组中有四行。</p>

<h4 id="2实验步骤-2">2.实验步骤</h4>

<p><strong>1、字节地址设计</strong></p>

<p>由下图可知，输入到 4 路组相联映射的 Cache 槽前半部分（主存地址）为 16 位，主存地址被划分为Tag、index、offset 三部分。</p>

<p>因为块数据输入为 32 位 即 4 字节，而由于输出 Dataout 为 8 位，即按照 字节 进行输出，因此 行内字节偏移即 offset 在 Cache  槽中占 2 位。</p>

<p>index 指示直接映射的组号，一组中有 4 行，共有 2 组，因此为 1 位。</p>

<p>其余 13 位全部作为区号 tag</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101233859611.png" alt="image-20201101233859611" /></p>

<p>先将主存地址进行分割，作为 Cache 槽的前半部分。</p>

<p><strong>2、Cache槽的设计</strong></p>

<p>现在开始设计 Cache 槽。<em>cache</em>  主要包含四部分：Valid标志、主存 Tag 标记位、淘汰计数标记、数据副本。而我们需要考虑的主要是前三部分，并且这三部分和之后的设计息息相关。</p>

<ul>
  <li>当中 valid 位有效位，判断该 cache 槽是否被命中过，存入了数据；</li>
  <li>Tag 位是存入的主存标记位；</li>
  <li><strong>淘汰计数是一个计数器</strong>，初值为0，若行命中标志 Li 有效时，读入数据 0，达到清零的效果，若Li无效，则随着时钟频率一直进行计数。（与后面的淘汰算法密切相关）。而数据副本通过三态门缓冲器连接到总结上，这里三态门缓冲器的作用是当Li行有效时，将数据副本中输出的数据进行缓存，也就是使 8 个chche槽中的数据都可以缓存到1个Solt，这里就实现了总线的作用，十分优化。 这里给出了一个cache槽，其余的进行类似的复制。</li>
</ul>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124014056.png" alt="image-20201031124014056" /></p>

<p><strong>值得注意的是：</strong></p>

<ol>
  <li>
    <p>为什么直接相联映射采用 L0 控制 V0、T0 的三态门，全相联直接输出？</p>

    <p>因为此时 L0 由 V0 和 T0 决定 ，而之前采用的是 Cache 选择控制（直接相联由 字节地址中的 第 2-4 位直接选择 Lx，而全相联需要并发比较各个标志位进行选择），此处为避免死循环，就不采用三态门。</p>
  </li>
  <li>
    <p>计数器的清空设置：</p>

    <p>如下图，当选择该行时，需要将计数器重置。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124750585.png" alt="image-20201031124750585" /></p>
  </li>
</ol>

<p><strong>3、写入和写出设计</strong></p>

<ol>
  <li>
    <p>写出设计即通过字内偏移地址 <em>Offset</em> 进行选择总线 <em>Slot</em> 上的某一字节进行输出。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124922703.png" alt="image-20201031124922703" /></p>
  </li>
  <li>
    <p>写入设计则要当 <em>BlkReady</em> 数据准备完成时（测试电路中的数据准备）选择具体的cache行进行写入，而写入的前提是<strong>该行为空，</strong>即 <em>Miss</em> 信号有效，才能写入数据。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101230536977.png" alt="image-20201101230536977" /></p>
  </li>
  <li>
    <p>写入行的判断：</p>

    <ul>
      <li>若存在空行，即 <em>FULL</em> 信号无效，则选择相应的空行进行写入；</li>
      <li>若<em>FULL</em>信号有效，则<strong>选择淘汰的行</strong>进行写入。两种情况都为之后的淘汰算法中选出的行号。</li>
    </ul>
  </li>
</ol>

<p><strong>4、判断是否命中。————即比较设计</strong></p>

<p>​  对于第 3 点的写入写出需要进行判断，即比较设计来判断是否命中。</p>

<p>​  不同的映射模式最大的区别就在于比较设计上。4 路组相联因为是随机选取的 <em>cache</em> 行进行写入，因此没有行地址（索引），因此直接进行 4 个 <em>cache</em> 槽的<strong>并发比较</strong>，得到命中的 <em>Cache</em> 行<em>Li</em>，并给出 <em>Miss</em> 和 <em>Hit</em> 信号。</p>

<p>​  4 行进行比较，通过 index 进行选择哪一组进行并行输出。两组中，只要有一组成功，那么 HIT。</p>

<p>比较方法如图所示。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101230941941.png" alt="image-20201101230941941" /></p>

<p><strong>若命中，那么 HIT 信号为 1 ，则开始上文提到的 SlotData 输出显示。</strong></p>

<p><strong>若没有命中，那么 Miss 变为 1 ，开始进行淘汰算法，来选出相应的行。</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124922703.png" alt="image-20201031124922703" /></p>

<p><strong>5、淘汰算法</strong></p>

<p>淘汰算法分为两个部分，</p>

<ul>
  <li>一个是当存在 cache 槽为空，空行的选择</li>
  <li>一个是当 cache 槽满时，淘汰行的选择</li>
</ul>

<ol>
  <li>
    <p><strong>槽存在空</strong></p>

    <p>在空行的选择中，通过优先比较器来实现，优先比较器通过比较，<strong>输出的是索引较大的非 0 行</strong>，因此先对所有行的标志位取反，取反后，若为1，则表示该行为空；若为0，则表示该行已经存在数据。若所有行都存在数据则 <em>FULL</em> 行满信号有效。</p>
  </li>
</ol>

<p>通过优先编码器选出索引值最大空 Cache 槽，或者输出 FULL</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101230926431.png" alt="image-20201101230926431" /></p>

<ol>
  <li>
    <p><strong>槽满时</strong></p>

    <p>在淘汰行的选择中，主要运用到LRU淘汰算法（即最近最少使用淘汰算法），由于我们在 cache 槽设计中的计数器是当行选中时清零，行为选中时随时钟频率进行计数，因此这里计数的最大值即为最少使用的cache槽。 而我们用文件中附带的归并算法，这里的归并算法是输出两个值中较大的一位的数据和索引，最后得到相应的淘汰行。</p>

    <p>由于是要输出 二位编码，因此选择 MAX2，其内部电路如图所示</p>

    <p>其中 Y# 是指明 二位长度（ 表示 4 个）的编号。只是为了后面的译码器根据选出的 二位长度 地址进行位号选择。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101230739467.png" alt="image-20201101230739467" /></p>

    <p>且由于此处提供的 MAX2 进行比较的数值（ cnt 时钟计数）为 16 字节长度。因此计时器记录为 16位长度。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031123709802.png" alt="image-20201031123709802" /></p>

    <p><strong>并发淘汰比较如下</strong></p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101230638298.png" alt="image-20201101230638298" /></p>
  </li>
</ol>

<p>最终电路实现如下</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101231426289.png" alt="image-20201101231426289" /></p>

<p>最终成果展示</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101231441398.png" alt="image-20201101231441398" /></p>

<h3 id="72-路组相联-cache-设计">7、2 路组相联 Cache 设计</h3>

<p>现在来说说 2 路组相联。k 路取决于每一组中有多少行。此处便是一组中有二行。</p>

<h4 id="2实验步骤-3">2.实验步骤</h4>

<p><strong>1、字节地址设计</strong></p>

<p>由下图可知，输入到 4 路组相联映射的 Cache 槽前半部分（主存地址）为 16 位，主存地址被划分为Tag、index、offset 三部分。</p>

<p>因为块数据输入为 32 位 即 4 字节，而由于输出 Dataout 为 8 位，即按照 字节 进行输出，因此 行内字节偏移即 offset 在 Cache  槽中占 2 位。</p>

<p>index 指示直接映射的组号，一组中有 4 行，共有 2 组，因此为 1 位。</p>

<p>其余 13 位全部作为区号 tag</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201101233846009.png" alt="image-20201101233846009" /></p>

<p>先将主存地址进行分割，作为 Cache 槽的前半部分。</p>

<p><strong>2、Cache槽的设计</strong></p>

<p>现在开始设计 Cache 槽。<em>cache</em>  主要包含四部分：Valid标志、主存 Tag 标记位、淘汰计数标记、数据副本。而我们需要考虑的主要是前三部分，并且这三部分和之后的设计息息相关。</p>

<ul>
  <li>当中 valid 位有效位，判断该 cache 槽是否被命中过，存入了数据；</li>
  <li>Tag 位是存入的主存标记位；</li>
  <li><strong>淘汰计数是一个计数器</strong>，初值为0，若行命中标志 Li 有效时，读入数据 0，达到清零的效果，若Li无效，则随着时钟频率一直进行计数。（与后面的淘汰算法密切相关）。而数据副本通过三态门缓冲器连接到总结上，这里三态门缓冲器的作用是当Li行有效时，将数据副本中输出的数据进行缓存，也就是使 8 个chche槽中的数据都可以缓存到1个Solt，这里就实现了总线的作用，十分优化。 这里给出了一个cache槽，其余的进行类似的复制。</li>
</ul>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201102003247656.png" alt="image-20201102003247656" /></p>

<p><strong>值得注意的是：</strong></p>

<ol>
  <li>
    <p>为什么直接相联映射采用 L0 控制 V0、T0 的三态门，全相联直接输出？</p>

    <p>因为此时 L0 由 V0 和 T0 决定 ，而之前采用的是 Cache 选择控制（直接相联由 字节地址中的 第 2-4 位直接选择 Lx，而全相联需要并发比较各个标志位进行选择），此处为避免死循环，就不采用三态门。</p>
  </li>
  <li>
    <p>计数器的清空设置：</p>

    <p>如下图，当选择该行时，需要将计数器重置。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124750585.png" alt="image-20201031124750585" /></p>
  </li>
  <li>
    <p>此处<strong>清零中的毛刺问题解决：</strong> 清零动作改成同步清零，具体可以增加一个D触发器，将清零信号接输入，输出接异步清零，另外D触发器时钟触发方式请修改为上跳沿。</p>
  </li>
</ol>

<p><strong>3、写入和写出设计</strong></p>

<ol>
  <li>
    <p>写出设计即通过字内偏移地址 <em>Offset</em> 进行选择总线 <em>Slot</em> 上的某一字节进行输出。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124922703.png" alt="image-20201031124922703" /></p>
  </li>
  <li>
    <p>写入设计则要当 <em>BlkReady</em> 数据准备完成时（测试电路中的数据准备）选择具体的cache行进行写入，而写入的前提是<strong>该行为空，</strong>即 <em>Miss</em> 信号有效，才能写入数据。</p>
  </li>
  <li>
    <p>写入行的判断：</p>

    <ul>
      <li>
        <p>若存在空行，即 <em>FULL</em> 信号无效，则选择相应的空行进行写入；</p>
      </li>
      <li>
        <p>若<em>FULL</em>信号有效，则<strong>选择淘汰的行</strong>进行写入。两种情况都为之后的淘汰算法中选出的行号。</p>
      </li>
    </ul>
  </li>
</ol>

<p><strong>4、判断是否命中。————即比较设计</strong></p>

<p>​  对于第 3 点的写入写出需要进行判断，即比较设计来判断是否命中。</p>

<p>​  不同的映射模式最大的区别就在于比较设计上。2 路组相联因为是随机选取的 <em>cache</em> 行进行写入，因此没有行地址（索引），因此直接进行 2 个 <em>cache</em> 槽的<strong>并发比较</strong>，得到命中的 <em>Cache</em> 行<em>Li</em>，并给出 <em>Miss</em> 和 <em>Hit</em> 信号。</p>

<p>​  4 行进行比较，通过 index 进行选择哪一组进行并行输出。两组中，只要有一组成功，那么 HIT。</p>

<p>比较方法如图所示。</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201102004314424.png" alt="image-20201102004314424" /></p>

<p><strong>若命中，那么 HIT 信号为 1 ，则开始上文提到的 SlotData 输出显示。</strong></p>

<p><strong>若没有命中，那么 Miss 变为 1 ，开始进行淘汰算法，来选出相应的行。</strong></p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031124922703.png" alt="image-20201031124922703" /></p>

<p><strong>5、淘汰算法</strong></p>

<p>淘汰算法分为两个部分，</p>

<ul>
  <li>一个是当存在 cache 槽为空，空行的选择</li>
  <li>一个是当 cache 槽满时，淘汰行的选择</li>
</ul>

<ol>
  <li>
    <p><strong>槽存在空</strong></p>

    <p>在空行的选择中，通过优先比较器来实现，优先比较器通过比较，<strong>输出的是索引较大的非 0 行</strong>，因此先对所有行的标志位取反，取反后，若为1，则表示该行为空；若为0，则表示该行已经存在数据。若所有行都存在数据则 <em>FULL</em> 行满信号有效。</p>
  </li>
</ol>

<p>通过优先编码器选出索引值最大空 Cache 槽，或者输出 FULL</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201102004250871.png" alt="image-20201102004250871" /></p>

<ol>
  <li>
    <p><strong>槽满时</strong></p>

    <p>在淘汰行的选择中，主要运用到LRU淘汰算法（即最近最少使用淘汰算法），由于我们在 cache 槽设计中的计数器是当行选中时清零，行为选中时随时钟频率进行计数，因此这里计数的最大值即为最少使用的cache槽。 而我们用文件中附带的归并算法，这里的归并算法是输出两个值中较大的一位的数据和索引，最后得到相应的淘汰行。</p>

    <p>由于是要输出 二位编码，因此选择 MAX2，其内部电路如图所示</p>

    <p>其中 Y# 是指明 二位长度（ 表示 4 个）的编号。只是为了后面的译码器根据选出的 二位长度 地址进行位号选择。</p>

    <p>MAX1 实则是对 MAX2 进行 X#、Y# 字节的更改。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201102004207591.png" alt="image-20201102004207591" /></p>

    <p>且由于此处提供的 MAX2 进行比较的数值（ cnt 时钟计数）为 16 字节长度。因此计时器记录为 16位长度。</p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201031123709802.png" alt="image-20201031123709802" /></p>

    <p><strong>并发淘汰比较如下</strong></p>

    <p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201102004226750.png" alt="image-20201102004226750" /></p>
  </li>
</ol>

<p>最终电路实现</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201102004513904.png" alt="image-20201102004513904" /></p>

<p>测试电路</p>

<p><img src="/assets/blog_image/2020-10-19-hust-cpu-study_3/image-20201102004536562.png" alt="image-20201102004536562" /></p>

<h4 id="3组相联特点">3.组相联特点</h4>

<p>组相联应用场合</p>

<ul>
  <li>容量小的 cache 可采用全相联映射 或组相联映射
    <ul>
      <li>Pentium CPU L1 L2 cache</li>
    </ul>
  </li>
  <li>容量大的可采用直接映射方式
    <ul>
      <li>查找速度快 ，命中率相对低</li>
      <li>但cache 容量大可提高命中率</li>
      <li>块设备缓存</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="principle" /></entry><entry><title type="html">自己动手画 CPU《计算机组织与结构实验》（二）</title><link href="http://localhost:4000/principle/2020/10/05/hust-cpu-study_2.html" rel="alternate" type="text/html" title="自己动手画 CPU《计算机组织与结构实验》（二）" /><published>2020-10-05T07:16:34+08:00</published><updated>2020-10-05T07:16:34+08:00</updated><id>http://localhost:4000/principle/2020/10/05/hust-cpu-study_2</id><content type="html" xml:base="http://localhost:4000/principle/2020/10/05/hust-cpu-study_2.html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#二运算器组成实验" id="markdown-toc-二运算器组成实验">二、运算器组成实验</a>    <ul>
      <li><a href="#1-可控加减法电路设计实验" id="markdown-toc-1-可控加减法电路设计实验">1. 可控加减法电路设计实验</a></li>
      <li><a href="#2-4-位先行进位74182" id="markdown-toc-2-4-位先行进位74182">2. 4 位先行进位74182</a></li>
      <li><a href="#3-4-位快速加法器设计" id="markdown-toc-3-4-位快速加法器设计">3. 4 位快速加法器设计</a></li>
      <li><a href="#4-16-位快速加法器设计" id="markdown-toc-4-16-位快速加法器设计">4. 16 位快速加法器设计</a></li>
      <li><a href="#5--32-位快速加法器设计" id="markdown-toc-5--32-位快速加法器设计">5.  32 位快速加法器设计</a></li>
      <li><a href="#6-32-位-alu设计实验" id="markdown-toc-6-32-位-alu设计实验">6. 32 位 ALU设计实验</a></li>
      <li><a href="#7-5-位阵列乘法器" id="markdown-toc-7-5-位阵列乘法器">7. 5 位阵列乘法器</a>        <ul>
          <li><a href="#1前置背景" id="markdown-toc-1前置背景">1）前置背景</a></li>
          <li><a href="#2横向进位阵列乘法器" id="markdown-toc-2横向进位阵列乘法器">2）横向进位阵列乘法器</a></li>
          <li><a href="#3斜向进位阵列乘法器" id="markdown-toc-3斜向进位阵列乘法器">3）斜向进位阵列乘法器</a></li>
        </ul>
      </li>
      <li><a href="#8-6-位补码阵列乘法器" id="markdown-toc-8-6-位补码阵列乘法器">8. 6 位补码阵列乘法器</a></li>
      <li><a href="#9-5-位无符号乘法流水线" id="markdown-toc-9-5-位无符号乘法流水线">9. 5 位无符号乘法流水线</a></li>
      <li><a href="#10原码-1-位乘法器设计实验" id="markdown-toc-10原码-1-位乘法器设计实验">10.原码 1 位乘法器设计实验</a></li>
      <li><a href="#11补码-1-位乘法器设计实验" id="markdown-toc-11补码-1-位乘法器设计实验">11.补码 1 位乘法器设计实验</a></li>
    </ul>
  </li>
</ul>

<p><a href="https://www.icourse163.org/course/HUST-1205809816">配套慕课</a></p>

<h2 id="二运算器组成实验">二、运算器组成实验</h2>

<h3 id="1-可控加减法电路设计实验">1. 可控加减法电路设计实验</h3>

<p>1、背景知识</p>

<p>0）一位加法逻辑电路实现</p>

<ul>
  <li>0＋1=1  1＋0=1</li>
  <li>1＋1=0  0＋0=0</li>
  <li>因此：一个异或门即可实现 <strong>自动</strong> 一位加法</li>
</ul>

<p><strong>1）一位全加器的实现。</strong></p>

<p>一位全加器的表达式如下：</p>

<ol>
  <li>
    <p>Si = Xi ⊕ Yi ⊕ Cin</p>
  </li>
  <li>
    <p>Cout = XiYi + （Xi ⊕ Yi）Cin</p>
  </li>
</ol>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/20200501112325459.png" alt="20200501112325459" /></p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201012162421462.png" alt="image-20201012162421462" style="zoom:67%;" /></p>

<p><strong>2）多位串行加法器</strong></p>

<p>判断溢出方式为：</p>

<ol>
  <li>
    <p>无符号数溢出判断：其实很简单，就一句话：</p>

    <p><em>当最高为向更高位有进位（或借位）时产生溢出</em></p>
  </li>
</ol>

<p>由于无符号数通常代表内存地址，这种情况下的溢出可以忽略。</p>

<ol>
  <li>
    <p>溢出只可能符号数溢出的情况，包括[X]补与[Y]补，[X]补与[-Y]补同号。</p>

    <p><strong>方法一</strong>：对操作数和运算结果的符号位进行检测，如果不相同则发生了溢出。</p>

    <p>设X0，Y0为运算数的符号位，S0为运算结果的符号位。</p>

    <p>逻辑表达式为：<strong>OF = X0Y0~S0 + ~X0~Y0S0</strong></p>

    <p>当OF = 1时发生溢出。</p>

    <p><strong>方法二</strong>：对<strong>最高数据位进位</strong>和<strong>符号位进位</strong>进行检测。</p>

    <p>设最高数据位产生的进位为C1，符号位产生的进位为C0.</p>

    <p>两个正数相加，此时C0 = 0，若C1 = 1，则改变了结果符号位。发生溢出。</p>

    <p>两个负数相加，此时C0 = 1， 若C1 = 0，则改变了结果符号位。发生溢出。</p>

    <p>逻辑表达式为：<strong>OF = C0⊕C1</strong></p>

    <p><strong>方法三</strong>：使用变形补码，给数据加上两位符号位，正常情况，符号位应该相同，如果运算后的结果两位符号位不同，则发生溢出。</p>
  </li>
</ol>

<p>电路图中的<strong>第一位全加器的低位进位</strong>默认是<strong>没有进位</strong>的，只有输入位。</p>

<p>本实验采用方法二，对于 <strong>最高数据位进位</strong> 和 <strong>符号位进位</strong> 两个位数进行异或检测</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201012162856622.png" alt="image-20201012162856622" /></p>

<p>3）8位可控加减法器</p>

<p>原理：</p>

<p>[X]补 - [Y]补 = [X - Y]补 = [X]补 + [-Y]补</p>

<p>[-Y]补 = [[Y]补]补</p>

<p>进行减法时，根据减法运算，需要把  [Y]补  转换为  [-Y]补 。转换规则与原码转补码相同，所以直接取反加一即可。</p>

<p>eg：[Y]补 = 10011    [-Y]补 = 01101</p>

<p>设计思路：加上一个 Sub 控制信号输入，输入数 Y 的所有位 Yi 均与 Sub 位进行<strong>异或</strong>后送入 全加器 中。</p>

<ul>
  <li>当 Sub = 0 时，送入为 Y 本身；</li>
  <li>当 Sub = 1 时，送入为 Y 的反码；且 Sub 位也连在加法器上，因此 Sub 为 1 时，直接取反码后再加上 1，而 Sub 为 0 时，进位 0 不影响加法结果</li>
</ul>

<p>最终实现如下</p>

<p>此时 Sub 位 为 0 ，表示加法（下侧运算指示由 LED 点阵表示）</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201012182232160.png" alt="image-20201012182232160" /></p>

<p>此时 Sub 位 为 1 ，表示减法</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201012182207063.png" alt="image-20201012182207063" /></p>

<h3 id="2-4-位先行进位74182">2. 4 位先行进位74182</h3>

<p>由于全加器公式如下，即高位运算取决于低位运算的输入 Ci-1。因此不能进行并行运算</p>

<ol>
  <li>Si = Xi ⊕ Yi ⊕ Cin</li>
  <li>Cout = XiYi + （Xi ⊕ Yi）Cin     /    Cout = XiYi + （Xi + Yi）Cin</li>
</ol>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201012233340803.png" alt="image-20201012233340803" /></p>

<p>即如上图可知，一般采用 4 位一组的先行进位方法。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/v2-8a9142067020bc11d7a679b03c323b70_b.jpg" alt="v2-8a9142067020bc11d7a679b03c323b70_b" /></p>

<p>设 进位生成函数 Gi = XiYi， Pi = Xi  ⊕  Yi</p>

<p>由上图我们可以提取出以下公式</p>

<p>Ci = Gi + Pi*Ci-1</p>

<p>则</p>

<p><strong>C1 = G1 + P1*C0</strong></p>

<p>C2 = G2 + P2*C1</p>

<p>C3 = G3 + P3*C2</p>

<p>C4 = G4 + P4*C3</p>

<p>逐步带入可得</p>

<p><strong>C2 =</strong> G2 + P2*（ G1 + P1 * C0）</p>

<p>= <strong>G2 + P2G1 + P2P1C0</strong></p>

<p><strong>C3 =</strong> G3 + P3 *（G2 + P2G1 + P2P1C0）</p>

<p>= <strong>G3 + P3G2 + P3P2G1 + P3P2P1C0</strong></p>

<p><strong>C4 =</strong> G4 + P4*（G3 + P3G2 + P3P2G1 + P3P2P1C0）</p>

<p>= <strong>G4 + P4G3 + P4P3G2 + P4P3P2G1 + P4P3P2P1C0</strong></p>

<p><strong>这里可以发现各级的进位与其他进位无关</strong></p>

<p>而 所有的 P、G输入后需要 2T 的时间延迟；</p>

<p>又因为P、G输入需要一级门电路延迟，因此总输入为 3T 延迟。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013164402039.png" alt="image-20201013164402039" /></p>

<p>构造电路图如下</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013163358078.png" alt="image-20201013163358078" /></p>

<p>现在已经得到 4 位的加速加法器，若想得到更多位宽电路，如 16 位加法器，最简单的方法便是将 4 个<strong>加法器进位链</strong> 进行串联，但是这样的话只能实现 4 位组内并行计算，组间还是串行。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013164415683.png" alt="image-20201013164415683" /></p>

<p>因此现在希望提高性能：</p>

<p>成组进位生成函数：<strong>G* = G4 + P4G3 + P4P3G2 + P4P3P2G1</strong></p>

<p>成组进位传递函数：<strong>P* = P4P3P2P1</strong></p>

<p>我们发现：<strong>C4 =</strong> <strong>G4 + P4G3 + P4P3G2 + P4P3P2G1 + P4P3P2P1C0</strong> <strong>= G* + P* C0</strong></p>

<p>即与之前提到的先行进位中的 <strong>C1 = G1 + P1*C0</strong> 形式完全一样！即只要提前得到  <strong>成组进位生成函数</strong>  和  <strong>成组进位传递函数</strong>，再复用 4 位先行进位电路即可。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013164443705.png" alt="image-20201013164443705" /></p>

<p>生成电路如下：</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013163050767.png" alt="image-20201013163050767" /></p>

<h3 id="3-4-位快速加法器设计">3. 4 位快速加法器设计</h3>

<p>按照下图 74182 4 位加法器</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013164443705.png" alt="image-20201013164443705" /></p>

<p>通过此处的与门异或门电路得到相应输入值，再输入即可</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013184220192.png" alt="image-20201013184220192" /></p>

<p>实现电路如下</p>

<p>注意 ：C3 只是一个输出位。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013184345847.png" alt="image-20201013184345847" /></p>

<h3 id="4-16-位快速加法器设计">4. 16 位快速加法器设计</h3>

<p>主要思想便为：组内并行，组间并行。</p>

<p>设计思路较为简单，由上层 CLA74182 产生下层所需要的 C4、C8、C12，再并行运算得到各个进位，再输回4位快速加法器,得到 Cout 。</p>

<p>具体步骤是：底层加速加法器首先生成所有 P，G（时间延迟为 1T），接着产生 P*、G*（即输入进CLA的电路端，时间延迟为 2T），上层先行电路 CLA 通过 P、G、C0得到 C4、C8、C12 信号（时间延迟为 2T），此时下层加法器的所有输入信号都已经待续，经过内部的 C0 与其他信号的与门异或门（2T) 以及 S 的求和运算（P 与 C的异或，时间延迟为 1T），因此最终延迟为 8T。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013234414926.png" alt="image-20201013234414926" /></p>

<h3 id="5--32-位快速加法器设计">5.  32 位快速加法器设计</h3>

<p>思路与上面大致一样，不再赘述。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201013235344233.png" alt="image-20201013235344233" /></p>

<h3 id="6-32-位-alu设计实验">6. 32 位 ALU设计实验</h3>

<p>【目标】</p>

<p>​利用前面实验封装好的32位加法器以及 Logisim 平台中现有运算部件，构建一个32位算术逻辑运算单元（禁用 Logisim  系统自带的加法器，减法器），可支持算术加、减、乘、除，逻辑与、或、非、异或运算、逻辑左移、逻辑右移、算术右移运算，支持常用程序状态标志（有符号溢出 OF 、无符号溢出 UOF ，结果相等 Equal ），ALU 功能以及输入输出引脚见下图。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201014223905904.png" alt="image-20201014223905904" /></p>

<p>ALU 功能</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/v2-801bb6008e475f4e2a7fd3280c0e04a9_720w.jpg" alt="v2-801bb6008e475f4e2a7fd3280c0e04a9_720w" /></p>

<p>实现电路如下：</p>

<p>主要注意以下几处：</p>

<ol>
  <li>移位器采用分线器来得到 Y 的低五位</li>
  <li>减法的运用 32 位加法器时，需直接判断 X 是否 无符号大于 Y 即可。</li>
  <li>再就是 <strong>比较器</strong> 的设置！！！</li>
</ol>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201016202114284.png" alt="image-20201016202114284" /></p>

<p>选择器的运用</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201016195044233.png" alt="image-20201016195044233" /></p>

<p>折磨我一个小时的问题！！！！</p>

<p>比较器无符号的比较！！！</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201016194805245.png" alt="image-20201016194805245" /></p>

<p>最终测试结果</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201016193638163.png" alt="image-20201016193638163" /></p>

<h3 id="7-5-位阵列乘法器">7. 5 位阵列乘法器</h3>

<h4 id="1前置背景">1）前置背景</h4>

<p><strong>乘法实现</strong>类似于现实生活中的乘法方法(如下图)</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018192345643.png" alt="image-20201018192345643" /></p>

<p>而相加数的得到需要考虑一位乘法的实现：</p>

<pre><code class="language-assembly">1×1=1
1×0=0
0×1=0
0x0=0
</code></pre>

<p>即类似与门</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018192949489.png" alt="image-20201018192949489" /></p>

<p>由上图与门得到相加数，采用 25 个与门并发产生。————一级门延迟</p>

<h4 id="2横向进位阵列乘法器">2）横向进位阵列乘法器</h4>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018192840020.png" alt="image-20201018192840020" /></p>

<p>易知延迟如上图（+T 表示与门的延迟时间）</p>

<p>实现电路如下</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018193105942.png" alt="image-20201018193105942" /></p>

<p>其中加法器的各个接口如下：</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018173828600.png" alt="image-20201018173828600" /></p>

<h4 id="3斜向进位阵列乘法器">3）斜向进位阵列乘法器</h4>

<p>我们发现横向进位加法器过于依赖进位，若改为斜向进位，那么只有最后一行需要依赖横向进位，能较好的提升乘法器性能。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018193220982.png" alt="image-20201018193220982" /></p>

<p>易知延迟如上图（+T 表示与门的延迟时间）</p>

<p>最终电路实现如下：</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018193706273.png" alt="image-20201018193706273" /></p>

<p><code class="language-plaintext highlighter-rouge">注：目前主流CPU 采用更多硬件：利用 Booth 两位乘法 + 华莱士树 的方式构建乘法器</code></p>

<h3 id="8-6-位补码阵列乘法器">8. 6 位补码阵列乘法器</h3>

<p>补码想法便是利用之前的 5 位阵列乘法器。先对 乘数 进行补码（利用求补器和多路选择器），最后对结果进行再次求补后，再加上符号。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018200138792.png" alt="image-20201018200138792" /></p>

<p>至于图中的 -32 * 1 不能得出正确结果。由探针很容易明白原因。</p>

<h3 id="9-5-位无符号乘法流水线">9. 5 位无符号乘法流水线</h3>

<p>1.首先回忆之前的 <strong>五段流水线模拟</strong></p>

<p>同步清零，气泡，高电平有效</p>

<p>使能端，低电平有效，stall，高电平有效</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201005162854350.png" alt="image-20201005162854350" /></p>

<p>观察乘法线流水接口</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018205020703.png" alt="image-20201018205020703" /></p>

<p>阵列乘法器流水线优化</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018212238547.png" alt="image-20201018212238547" /></p>

<p>放大来看其中一个公式的实现，采用扩展器+加法器+移位器</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018212150048.png" alt="image-20201018212150048" /></p>

<p>实现电路如下</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018212034287.png" alt="image-20201018212034287" /></p>

<h3 id="10原码-1-位乘法器设计实验">10.原码 1 位乘法器设计实验</h3>

<p>原理</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201020223010992.png" alt="image-20201020223010992" /></p>

<p>提示：无符号1位乘法自动运算可分解为如下步骤。</p>

<ol>
  <li>
    <p>初始化时寄存器、X、Y值全为0，电路默认状态就是0；</p>
  </li>
  <li>
    <p>将引脚中的两个乘数X、Y分别载入对应的寄存器，X、Y的值应送到对应寄存器的数据输入端Xa、Ya，由于寄存器的数据载入需要时钟驱动，所以在第一个时钟到来时应该将X、Y的值分别载入对应的寄存器中，此部分逻辑属于时序逻辑。</p>
  </li>
  <li>
    <p>计算部分积<img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018230520622.png" alt="image-20201018230520622" style="zoom:67%;" />其中，是寄存器乏的输出，Adder.
Result 为加法器的运算结果输出，此部分核心电路是加法器，属于组合逻辑。</p>
  </li>
  <li>
    <p>加法器运算结果Adder.Result 逻辑右移1位送za，同时Adder.Result的最后1位加上寄存器Y的输出Yo.逻辑右移1位送 Yin，由于固定1位移位操作，所以不需要使用移位器，可直接使用Logisim平合中的分线器将对应数据分出，并且在高位补零即可实现逻辑右移，此部分逻辑属于组合逻辑。</p>

    <p>​需要注意的是（即如下图），Yin 在步骤（2）中接入的是Y引脚的值，所以Ya应该增加一个多路选择器进行数据输入选择，同时引入选择控制信号，具体实现时可利用计数器的值生成该选择控制信号，当计数器初始值为0时则多路选择器选择引脚Y的值送入Yin，不为0时则选择移位数据输入。</p>

    <p>​即需要注意 X Y 是分情况载入的。</p>

    <p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018230358332.png" alt="image-20201018230358332" /></p>
  </li>
  <li>
    <p>将移位后的数据载入 E、Y寄存器以便进行下一次运算，载入过程受时钟控制，属时序逻辑。</p>
  </li>
  <li>
    <p>根据时钟计数器的值判断运算是否结束，并生成停机信号（低电平有效），停机信号应用于控制所有寄存器的使能端，使得寄存器忽略时钟输入，保持结果值不变。需要注意的是，切勿采用将时钟信号与停机信号进行逻辑与的方式控制系统停机，对时钟进行任何门级操作都会带来意想不到的潜在错误，这是后续所有实验必须遵守的原则。</p>
  </li>
</ol>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018225523447.png" alt="image-20201018225523447" /></p>

<p>移位可采用下面这种方式</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018230724413.png" alt="image-20201018230724413" /></p>

<p>需要注意的是！！！</p>

<p>1、下图将 E 的最后一位移入到 Y’ 中。是有下列两个原因：</p>

<ol>
  <li>最后是两个寄存器保存最终 2n 长的值（类比 axdx）</li>
  <li>Y’ 的移位之后，高位不影响结果，因此可以放在高部。</li>
</ol>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018230744726.png" alt="image-20201018230744726" /></p>

<p>2、Y的最后一位采用分线器读入。</p>

<p>3、引入一个计数器，ct 连接点与寄存器大致相同。</p>

<p>4、停机信号应用于控制所有寄存器的使能端，使得寄存器忽略时钟输入，保持结果值不变。切勿采用将时钟信号与停机信号进行逻辑与的方式控制系统停机，对时钟进行任何门级操作都会带来意想不到的潜在错误，这是后续所有实验必须遵守的原则。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019180227668.png" alt="image-20201019180227668" /></p>

<p>最终电路实现如下。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201018224932971.png" alt="image-20201018224932971" /></p>

<h3 id="11补码-1-位乘法器设计实验">11.补码 1 位乘法器设计实验</h3>

<p>原理的推导</p>

<p>首先探讨补码的一位乘</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201020223010992.png" alt="image-20201020223010992" /></p>

<p>1、X 乘上 正数</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019174715802.png" alt="image-20201019174715802" /></p>

<p>由于 Y 为正，所以 [Y]补 = Y</p>

<p>2、X 乘上 负数</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201020221531307.png" alt="image-20201020221531307" /></p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201020221751091.png" alt="image-20201020221751091" /></p>

<p>现在思考这样一个定理： 一个数向左移动一位后（2倍）  –  自身  =  自身</p>

<p>引入一位 Yn+1，<strong>那么 Yn+1 初始值设为 0</strong>。可以得到下面式子转换。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201020222123786.png" alt="image-20201020222123786" /></p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201020221736106.png" alt="image-20201020221736106" style="zoom:80%;" /></p>

<p>现在将  2位  看作一个整体，即 YnYn+1、Yn-1Yn、… 1 2。</p>

<p>即   Yn+1-Yn –&gt;  Yn  、Yn-Yn-1 –&gt; Yn-1 …… 那么可以得到以下式子：</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201020222333818.png" alt="image-20201020222333818" style="zoom:80%;" /></p>

<p>再由于 当 Y 为 正数 时，符号位则为 0，即可以代入下图 Y0，然后将两个情况统一。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201020223924682.png" alt="image-20201020223924682" /></p>

<p><strong>因此 这也可以解释为什么Booth里末两位为 10 时，要加[-X]补。 为什么 Y(n+1) - Yn = 1 (末两位01)的时候 要加[X]补。</strong></p>

<p>易知以下推导公式（ booth 一位乘法）</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019174838295.png" alt="image-20201019174838295" /></p>

<p>与原码1位乘法不同，booth1位乘法中乘数采用<strong>双符号位</strong>参加运算，符号位也参与运算。利用 ∑ 存放部分积，i 为循环计数器，初始值为零，部分积累加公式为 ∑ =  ∑ +（Yn+1 - Yn ）[x]补，<strong>根据 Yn+1 与 Yn 的差值</strong>决定累加运算的参数是 0 还是 [X]补 或者是 [-X]补，<strong>注意最开始 Yn+1=0</strong>。运算完毕后，先判断循环次数是否达到，如未达到则部分积 ∑ 右移1位，Y 右移 1 位，然后继续循环累加，当乘数符号位参与运算后，运算结束，得到的乘积存放在 ∑ 和 Y 中，<strong>无须单独计算符号位</strong>。如果数值部分为 n 位，需要进行 n+1 次加法运算 和 n 次移位操作。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019175729836.png" alt="image-20201019175729836" /></p>

<p>​补码1位乘法的硬件逻辑结构如上图所示，图中寄存器 R0 存放部分积 ∑ ，寄存器 R1 存放乘数 Yn 以及扩展位 Yn+1（初始值为零），YnYn+1 为判断位(<strong>最低两位</strong>)；寄存器R2：存放被乘数X的补码；加法器实现部分积的累加，运算逻辑为</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019175758692.png" alt="image-20201019175758692" style="zoom: 80%;" /></p>

<p>其中，一个操作数为  ∑ ，另一个操作数由判断位 YnYn+1 对多路选择器进行选择控制； 控制电路负责移位控制和循环计数。受时钟驱动，每运算一次，加法器运算结果与寄存器 R1 的值一起算术右移 1 位后产生的新值载入 R0 和 R1 寄存器中，当运算结束时，乘积的高 n 位数据在 R0 中，低 n 位在 R1 中， R1 中原来的乘数在右移过程中逐位移出寄存器。</p>

<ul>
  <li>乘数 x 取双符号位参与运算，部分积的初始值为0；</li>
  <li>乘数 y 取单符号位参与运算。</li>
</ul>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019180208264.png" alt="image-20201019180208264" /></p>

<p>注意事项如下：</p>

<p>1、Yn+1 初始值为 0 。</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019225303449.png" alt="image-20201019225303449" /></p>

<p>2、最高位与次高位一致</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019225506071.png" alt="image-20201019225506071" /></p>

<p>3、负数取补 = 取反 + 1</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019225543626.png" alt="image-20201019225543626" /></p>

<p>最终电路实现如下：（思路大致与原码 1 位一样）</p>

<p><img src="/assets/blog_image/2020-10-05-hust-cpu-study_2/image-20201019224823463.png" alt="image-20201019224823463" /></p>]]></content><author><name></name></author><category term="principle" /></entry></feed>